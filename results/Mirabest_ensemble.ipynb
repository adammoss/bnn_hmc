{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/bnn_hmc/blob/main/results/Mirabest_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ri22BCCzR-QP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nruns = 10"
      ],
      "metadata": {
        "id": "EyQ70K9atPhp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe0MKiBxsHYy",
        "outputId": "7436ddee-9e3c-4e42-b461-732c846426a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 18 09:00:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMtVSagkaf-h",
        "outputId": "de01170a-b3dd-4ffc-ae99-3f7deec6e0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting astro-datasets\n",
            "  Downloading astro_datasets-0.0.10.tar.gz (12 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (2.9.1)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (4.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astro-datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astro-datasets) (2022.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->astro-datasets) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (4.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.26.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->astro-datasets) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->astro-datasets) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->astro-datasets) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow->astro-datasets) (3.0.9)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (1.9.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (5.9.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (0.3.5.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (0.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (2.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (4.64.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets->astro-datasets) (1.56.4)\n",
            "Building wheels for collected packages: astro-datasets\n",
            "  Building wheel for astro-datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for astro-datasets: filename=astro_datasets-0.0.10-py3-none-any.whl size=15992 sha256=6aae98d257bb23515cdbf4a1785598bcd2438b34600f747137b90f8bf997fd04\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/b2/9d/97c264f6addbd178fe1c8ff119617e1515cb8c0d0f220605cf\n",
            "Successfully built astro-datasets\n",
            "Installing collected packages: astro-datasets\n",
            "Successfully installed astro-datasets-0.0.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.9.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.21.6)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.9.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.64.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow_datasets) (3.8.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install astro-datasets --upgrade\n",
        "!pip install tensorflow_datasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1owru02sSDCw"
      },
      "outputs": [],
      "source": [
        "shutil.rmtree('bnn_hmc', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dWpM70rSF6J",
        "outputId": "735a0fe1-e4f6-4616-ed64-4ad0352b8bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bnn_hmc'...\n",
            "remote: Enumerating objects: 324, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 324 (delta 17), reused 15 (delta 8), pack-reused 288\u001b[K\n",
            "Receiving objects: 100% (324/324), 770.89 KiB | 7.01 MiB/s, done.\n",
            "Resolving deltas: 100% (211/211), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adammoss/bnn_hmc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD2r5bldto0q",
        "outputId": "3b6826fe-1f70-403b-9539-e4223dca12b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaxlib==0.1.65+cuda111\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.65+cuda111-cp37-none-manylinux2010_x86_64.whl (189.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 189.4 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.7.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.12)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.14+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.14+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.14+cuda11.cudnn805\n",
            "Successfully installed jaxlib-0.1.65+cuda111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jax==0.2.12\n",
            "  Downloading jax-0.2.12.tar.gz (590 kB)\n",
            "\u001b[K     |████████████████████████████████| 590 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.2.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (3.3.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.12-py3-none-any.whl size=682487 sha256=a8f07aed17e7529f4f80e6a2131913c3cf9775c908cffdb178d1c72bcad63c71\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/4d/e5/73eec5070b77f25664c67bd793d4eb97f41bbf9be7afafd15e\n",
            "Successfully built jax\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.14\n",
            "    Uninstalling jax-0.3.14:\n",
            "      Successfully uninstalled jax-0.3.14\n",
            "Successfully installed jax-0.2.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku==0.0.5.dev0\n",
            "  Downloading dm_haiku-0.0.5.dev0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 14.6 MB/s \n",
            "\u001b[?25hCollecting optax==0.0.6\n",
            "  Downloading optax-0.0.6-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting chex==0.0.6\n",
            "  Downloading chex-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 654 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (1.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.8.10)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.6) (0.1.65+cuda111)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.6) (0.2.12)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.6) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.6) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax==0.0.6) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax==0.0.6) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax==0.0.6) (1.7.3)\n",
            "Installing collected packages: chex, optax, dm-haiku\n",
            "Successfully installed chex-0.0.6 dm-haiku-0.0.5.dev0 optax-0.0.6\n"
          ]
        }
      ],
      "source": [
        "# https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install --upgrade https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.65+cuda111-cp37-none-manylinux2010_x86_64.whl\n",
        "!pip install jax==0.2.12\n",
        "!pip install dm-haiku==0.0.5.dev0 optax==0.0.6 chex==0.0.6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nruns):\n",
        " base_cmd = ['python3', 'bnn_hmc/scripts/run_sgd.py', '--seed=%s' % i, '--weight_decay=10', '--dir=runs/sgd/mirabestc/lenet/%s/' % i, \n",
        " '--dataset_name=mirabest/confident', '--model_name=lenet', '--init_step_size=3e-7', '--num_epochs=100', \n",
        " '--eval_freq=5', '--batch_size=53', '--save_freq=5', '--optimizer=SGD']\n",
        " train_cmd = base_cmd + ['--train_split=train[:80%]', '--test_split=train[80%:]']\n",
        " eval_cmd = base_cmd + ['--eval_split=test']\n",
        " print(' '.join(train_cmd))\n",
        " p = subprocess.run(train_cmd, capture_output=True)\n",
        " print(p.stdout.decode('utf8'))\n",
        " p = subprocess.run(eval_cmd, capture_output=True)\n",
        " print(p.stdout.decode('utf8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eDStfdhVOSh",
        "outputId": "ade09306-21ff-4ce9-ccd0-cf4055e328d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3 bnn_hmc/scripts/run_sgd.py --seed=0 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/0/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~/tensorflow_datasets/mirabest/confident/1.0.0...\u001b[0m\n",
            "\u001b[1mDataset mirabest downloaded and prepared to ~/tensorflow_datasets/mirabest/confident/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    3.1971            0.7221           0.6712      0.6539                                                         0.0000\n",
            "  1    0.0731                                                                                                        0.0000\n",
            "  2    0.0737                                                                                                        0.0000\n",
            "  3    0.0736                                                                                                        0.0000\n",
            "  4    0.0695                                                                                                        0.0000\n",
            "  5    0.0689            0.8662           0.7877      0.5011                                                         0.0000\n",
            "  6    0.0681                                                                                                        0.0000\n",
            "  7    0.0679                                                                                                        0.0000\n",
            "  8    0.0677                                                                                                        0.0000\n",
            "  9    0.0673                                                                                                        0.0000\n",
            " 10    0.0681            0.9280           0.8425      0.4214                                                         0.0000\n",
            " 11    0.0679                                                                                                        0.0000\n",
            " 12    0.0668                                                                                                        0.0000\n",
            " 13    0.0671                                                                                                        0.0000\n",
            " 14    0.0673                                                                                                        0.0000\n",
            " 15    0.0671            0.8285           0.7123      0.5896                                                         0.0000\n",
            " 16    0.0684                                                                                                        0.0000\n",
            " 17    0.0679                                                                                                        0.0000\n",
            " 18    0.0679                                                                                                        0.0000\n",
            " 19    0.0684                                                                                                        0.0000\n",
            " 20    0.0682            0.9314           0.8288      0.4084                                                         0.0000\n",
            " 21    0.0858                                                                                                        0.0000\n",
            " 22    0.0680                                                                                                        0.0000\n",
            " 23    0.0678                                                                                                        0.0000\n",
            " 24    0.0681                                                                                                        0.0000\n",
            " 25    0.0672            0.9262           0.8288      0.4410                                                         0.0000\n",
            " 26    0.0680                                                                                                        0.0000\n",
            " 27    0.0671                                                                                                        0.0000\n",
            " 28    0.0675                                                                                                        0.0000\n",
            " 29    0.0674                                                                                                        0.0000\n",
            " 30    0.0675            0.9794           0.8767      0.3527                                                         0.0000\n",
            " 31    0.0689                                                                                                        0.0000\n",
            " 32    0.0684                                                                                                        0.0000\n",
            " 33    0.0673                                                                                                        0.0000\n",
            " 34    0.0673                                                                                                        0.0000\n",
            " 35    0.0676            0.9708           0.8630      0.3567                                                         0.0000\n",
            " 36    0.0679                                                                                                        0.0000\n",
            " 37    0.0671                                                                                                        0.0000\n",
            " 38    0.0670                                                                                                        0.0000\n",
            " 39    0.0670                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0671            0.9846           0.8699      0.3529                                                         0.0000\n",
            " 41    0.0672                                                                                                        0.0000\n",
            " 42    0.0681                                                                                                        0.0000\n",
            " 43    0.0668                                                                                                        0.0000\n",
            " 44    0.0666                                                                                                        0.0000\n",
            " 45    0.0669            0.9811           0.8767      0.3590                                                         0.0000\n",
            " 46    0.0674                                                                                                        0.0000\n",
            " 47    0.0676                                                                                                        0.0000\n",
            " 48    0.0676                                                                                                        0.0000\n",
            " 49    0.0675                                                                                                        0.0000\n",
            " 50    0.0683            0.9794           0.8767      0.3727                                                         0.0000\n",
            " 51    0.0718                                                                                                        0.0000\n",
            " 52    0.0676                                                                                                        0.0000\n",
            " 53    0.0678                                                                                                        0.0000\n",
            " 54    0.0682                                                                                                        0.0000\n",
            " 55    0.0673            0.9897           0.8699      0.3608                                                         0.0000\n",
            " 56    0.0686                                                                                                        0.0000\n",
            " 57    0.0681                                                                                                        0.0000\n",
            " 58    0.0678                                                                                                        0.0000\n",
            " 59    0.0683                                                                                                        0.0000\n",
            " 60    0.0672            0.9897           0.8767      0.3604                                                         0.0000\n",
            " 61    0.0676                                                                                                        0.0000\n",
            " 62    0.0671                                                                                                        0.0000\n",
            " 63    0.0678                                                                                                        0.0000\n",
            " 64    0.0682                                                                                                        0.0000\n",
            " 65    0.0696            0.9897           0.8767      0.3712                                                         0.0000\n",
            " 66    0.0680                                                                                                        0.0000\n",
            " 67    0.0671                                                                                                        0.0000\n",
            " 68    0.0674                                                                                                        0.0000\n",
            " 69    0.0672                                                                                                        0.0000\n",
            " 70    0.0673            0.9931           0.8699      0.3677                                                         0.0000\n",
            " 71    0.0685                                                                                                        0.0000\n",
            " 72    0.0683                                                                                                        0.0000\n",
            " 73    0.0675                                                                                                        0.0000\n",
            " 74    0.0682                                                                                                        0.0000\n",
            " 75    0.0681            0.9897           0.8699      0.3742                                                         0.0000\n",
            " 76    0.0679                                                                                                        0.0000\n",
            " 77    0.0680                                                                                                        0.0000\n",
            " 78    0.0674                                                                                                        0.0000\n",
            " 79    0.0682                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0688            0.9931           0.8699      0.3698                                                         0.0000\n",
            " 81    0.0698                                                                                                        0.0000\n",
            " 82    0.0683                                                                                                        0.0000\n",
            " 83    0.0676                                                                                                        0.0000\n",
            " 84    0.0676                                                                                                        0.0000\n",
            " 85    0.0674            0.9931           0.8699      0.3703                                                         0.0000\n",
            " 86    0.0687                                                                                                        0.0000\n",
            " 87    0.0675                                                                                                        0.0000\n",
            " 88    0.0676                                                                                                        0.0000\n",
            " 89    0.0673                                                                                                        0.0000\n",
            " 90    0.0671            0.9931           0.8699      0.3684                                                         0.0000\n",
            " 91    0.0679                                                                                                        0.0000\n",
            " 92    0.0679                                                                                                        0.0000\n",
            " 93    0.0674                                                                                                        0.0000\n",
            " 94    0.0670                                                                                                        0.0000\n",
            " 95    0.0688            0.9931           0.8699      0.3689                                                         0.0000\n",
            " 96    0.0682                                                                                                        0.0000\n",
            " 97    0.0679                                                                                                        0.0000\n",
            " 98    0.0673                                                                                                        0.0000\n",
            " 99    0.0898            0.9931           0.8699      0.3691                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.91346157, dtype=float32), 'nll': 0.27257225, 'ece': DeviceArray(0.03434834, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=1 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/1/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.4149            0.6467           0.6096      0.6843                                                         0.0000\n",
            "  1    0.0674                                                                                                        0.0000\n",
            "  2    0.0668                                                                                                        0.0000\n",
            "  3    0.0674                                                                                                        0.0000\n",
            "  4    0.0665                                                                                                        0.0000\n",
            "  5    0.0663            0.7444           0.6849      0.5992                                                         0.0000\n",
            "  6    0.0665                                                                                                        0.0000\n",
            "  7    0.0662                                                                                                        0.0000\n",
            "  8    0.0662                                                                                                        0.0000\n",
            "  9    0.0663                                                                                                        0.0000\n",
            " 10    0.0669            0.8696           0.7603      0.5137                                                         0.0000\n",
            " 11    0.0663                                                                                                        0.0000\n",
            " 12    0.0662                                                                                                        0.0000\n",
            " 13    0.0661                                                                                                        0.0000\n",
            " 14    0.0666                                                                                                        0.0000\n",
            " 15    0.0667            0.8971           0.7945      0.4669                                                         0.0000\n",
            " 16    0.0669                                                                                                        0.0000\n",
            " 17    0.0665                                                                                                        0.0000\n",
            " 18    0.0667                                                                                                        0.0000\n",
            " 19    0.0665                                                                                                        0.0000\n",
            " 20    0.0665            0.8491           0.7260      0.5631                                                         0.0000\n",
            " 21    0.0693                                                                                                        0.0000\n",
            " 22    0.0664                                                                                                        0.0000\n",
            " 23    0.0659                                                                                                        0.0000\n",
            " 24    0.0662                                                                                                        0.0000\n",
            " 25    0.0665            0.8799           0.7603      0.5133                                                         0.0000\n",
            " 26    0.0664                                                                                                        0.0000\n",
            " 27    0.0663                                                                                                        0.0000\n",
            " 28    0.0663                                                                                                        0.0000\n",
            " 29    0.0658                                                                                                        0.0000\n",
            " 30    0.0662            0.9503           0.8014      0.4055                                                         0.0000\n",
            " 31    0.0679                                                                                                        0.0000\n",
            " 32    0.0663                                                                                                        0.0000\n",
            " 33    0.0667                                                                                                        0.0000\n",
            " 34    0.0662                                                                                                        0.0000\n",
            " 35    0.0663            0.9434           0.7808      0.4238                                                         0.0000\n",
            " 36    0.0663                                                                                                        0.0000\n",
            " 37    0.0662                                                                                                        0.0000\n",
            " 38    0.0662                                                                                                        0.0000\n",
            " 39    0.0666                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0663            0.9640           0.8082      0.3919                                                         0.0000\n",
            " 41    0.0661                                                                                                        0.0000\n",
            " 42    0.0662                                                                                                        0.0000\n",
            " 43    0.0664                                                                                                        0.0000\n",
            " 44    0.0661                                                                                                        0.0000\n",
            " 45    0.0665            0.9623           0.8630      0.3748                                                         0.0000\n",
            " 46    0.0710                                                                                                        0.0000\n",
            " 47    0.0677                                                                                                        0.0000\n",
            " 48    0.0664                                                                                                        0.0000\n",
            " 49    0.0666                                                                                                        0.0000\n",
            " 50    0.0673            0.9503           0.7808      0.4225                                                         0.0000\n",
            " 51    0.0666                                                                                                        0.0000\n",
            " 52    0.0659                                                                                                        0.0000\n",
            " 53    0.0659                                                                                                        0.0000\n",
            " 54    0.0663                                                                                                        0.0000\n",
            " 55    0.0660            0.9726           0.8219      0.3709                                                         0.0000\n",
            " 56    0.0675                                                                                                        0.0000\n",
            " 57    0.0666                                                                                                        0.0000\n",
            " 58    0.0665                                                                                                        0.0000\n",
            " 59    0.0670                                                                                                        0.0000\n",
            " 60    0.0662            0.9691           0.8014      0.3922                                                         0.0000\n",
            " 61    0.0660                                                                                                        0.0000\n",
            " 62    0.0664                                                                                                        0.0000\n",
            " 63    0.0663                                                                                                        0.0000\n",
            " 64    0.0662                                                                                                        0.0000\n",
            " 65    0.0659            0.9743           0.8151      0.3800                                                         0.0000\n",
            " 66    0.0746                                                                                                        0.0000\n",
            " 67    0.0668                                                                                                        0.0000\n",
            " 68    0.0663                                                                                                        0.0000\n",
            " 69    0.0669                                                                                                        0.0000\n",
            " 70    0.0674            0.9760           0.8082      0.3799                                                         0.0000\n",
            " 71    0.0667                                                                                                        0.0000\n",
            " 72    0.0664                                                                                                        0.0000\n",
            " 73    0.0669                                                                                                        0.0000\n",
            " 74    0.0667                                                                                                        0.0000\n",
            " 75    0.0667            0.9691           0.8014      0.3964                                                         0.0000\n",
            " 76    0.0675                                                                                                        0.0000\n",
            " 77    0.0668                                                                                                        0.0000\n",
            " 78    0.0670                                                                                                        0.0000\n",
            " 79    0.0670                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0674            0.9777           0.8082      0.3797                                                         0.0000\n",
            " 81    0.0662                                                                                                        0.0000\n",
            " 82    0.0663                                                                                                        0.0000\n",
            " 83    0.0665                                                                                                        0.0000\n",
            " 84    0.0672                                                                                                        0.0000\n",
            " 85    0.0667            0.9760           0.8151      0.3766                                                         0.0000\n",
            " 86    0.0733                                                                                                        0.0000\n",
            " 87    0.0669                                                                                                        0.0000\n",
            " 88    0.0671                                                                                                        0.0000\n",
            " 89    0.0664                                                                                                        0.0000\n",
            " 90    0.0667            0.9777           0.8151      0.3790                                                         0.0000\n",
            " 91    0.0684                                                                                                        0.0000\n",
            " 92    0.0667                                                                                                        0.0000\n",
            " 93    0.0665                                                                                                        0.0000\n",
            " 94    0.0663                                                                                                        0.0000\n",
            " 95    0.0661            0.9760           0.8151      0.3773                                                         0.0000\n",
            " 96    0.0665                                                                                                        0.0000\n",
            " 97    0.0669                                                                                                        0.0000\n",
            " 98    0.0700                                                                                                        0.0000\n",
            " 99    0.0670            0.9777           0.8151      0.3776                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.86538464, dtype=float32), 'nll': 0.29467046, 'ece': DeviceArray(0.09038395, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=2 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/2/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.3871            0.5626           0.5685      0.6889                                                         0.0000\n",
            "  1    0.0666                                                                                                        0.0000\n",
            "  2    0.0665                                                                                                        0.0000\n",
            "  3    0.0680                                                                                                        0.0000\n",
            "  4    0.0661                                                                                                        0.0000\n",
            "  5    0.0662            0.8525           0.7260      0.5799                                                         0.0000\n",
            "  6    0.0667                                                                                                        0.0000\n",
            "  7    0.0665                                                                                                        0.0000\n",
            "  8    0.0661                                                                                                        0.0000\n",
            "  9    0.0663                                                                                                        0.0000\n",
            " 10    0.0673            0.8816           0.7877      0.5220                                                         0.0000\n",
            " 11    0.0676                                                                                                        0.0000\n",
            " 12    0.0664                                                                                                        0.0000\n",
            " 13    0.0673                                                                                                        0.0000\n",
            " 14    0.0666                                                                                                        0.0000\n",
            " 15    0.0677            0.8662           0.7329      0.5284                                                         0.0000\n",
            " 16    0.0670                                                                                                        0.0000\n",
            " 17    0.0661                                                                                                        0.0000\n",
            " 18    0.0660                                                                                                        0.0000\n",
            " 19    0.0664                                                                                                        0.0000\n",
            " 20    0.0659            0.8988           0.7603      0.4966                                                         0.0000\n",
            " 21    0.0801                                                                                                        0.0000\n",
            " 22    0.0666                                                                                                        0.0000\n",
            " 23    0.0663                                                                                                        0.0000\n",
            " 24    0.0659                                                                                                        0.0000\n",
            " 25    0.0660            0.9485           0.8493      0.4131                                                         0.0000\n",
            " 26    0.0666                                                                                                        0.0000\n",
            " 27    0.0663                                                                                                        0.0000\n",
            " 28    0.0681                                                                                                        0.0000\n",
            " 29    0.0669                                                                                                        0.0000\n",
            " 30    0.0674            0.9245           0.8014      0.4610                                                         0.0000\n",
            " 31    0.0676                                                                                                        0.0000\n",
            " 32    0.0659                                                                                                        0.0000\n",
            " 33    0.0660                                                                                                        0.0000\n",
            " 34    0.0661                                                                                                        0.0000\n",
            " 35    0.0670            0.9383           0.8082      0.4261                                                         0.0000\n",
            " 36    0.0667                                                                                                        0.0000\n",
            " 37    0.0666                                                                                                        0.0000\n",
            " 38    0.0661                                                                                                        0.0000\n",
            " 39    0.0665                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0664            0.9640           0.8425      0.4064                                                         0.0000\n",
            " 41    0.0666                                                                                                        0.0000\n",
            " 42    0.0661                                                                                                        0.0000\n",
            " 43    0.0672                                                                                                        0.0000\n",
            " 44    0.0671                                                                                                        0.0000\n",
            " 45    0.0671            0.9760           0.8493      0.4059                                                         0.0000\n",
            " 46    0.0667                                                                                                        0.0000\n",
            " 47    0.0664                                                                                                        0.0000\n",
            " 48    0.0670                                                                                                        0.0000\n",
            " 49    0.0665                                                                                                        0.0000\n",
            " 50    0.0666            0.9811           0.8425      0.4058                                                         0.0000\n",
            " 51    0.0726                                                                                                        0.0000\n",
            " 52    0.0687                                                                                                        0.0000\n",
            " 53    0.0669                                                                                                        0.0000\n",
            " 54    0.0667                                                                                                        0.0000\n",
            " 55    0.0658            0.9794           0.8493      0.4109                                                         0.0000\n",
            " 56    0.0669                                                                                                        0.0000\n",
            " 57    0.0663                                                                                                        0.0000\n",
            " 58    0.0679                                                                                                        0.0000\n",
            " 59    0.0667                                                                                                        0.0000\n",
            " 60    0.0662            0.9863           0.8493      0.4085                                                         0.0000\n",
            " 61    0.0664                                                                                                        0.0000\n",
            " 62    0.0670                                                                                                        0.0000\n",
            " 63    0.0658                                                                                                        0.0000\n",
            " 64    0.0660                                                                                                        0.0000\n",
            " 65    0.0665            0.9863           0.8493      0.4112                                                         0.0000\n",
            " 66    0.0668                                                                                                        0.0000\n",
            " 67    0.0668                                                                                                        0.0000\n",
            " 68    0.0669                                                                                                        0.0000\n",
            " 69    0.0662                                                                                                        0.0000\n",
            " 70    0.0674            0.9880           0.8493      0.4119                                                         0.0000\n",
            " 71    0.0668                                                                                                        0.0000\n",
            " 72    0.0661                                                                                                        0.0000\n",
            " 73    0.0659                                                                                                        0.0000\n",
            " 74    0.0660                                                                                                        0.0000\n",
            " 75    0.0668            0.9846           0.8630      0.4185                                                         0.0000\n",
            " 76    0.0666                                                                                                        0.0000\n",
            " 77    0.0666                                                                                                        0.0000\n",
            " 78    0.0682                                                                                                        0.0000\n",
            " 79    0.0664                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0665            0.9863           0.8699      0.4196                                                         0.0000\n",
            " 81    0.0693                                                                                                        0.0000\n",
            " 82    0.0681                                                                                                        0.0000\n",
            " 83    0.0665                                                                                                        0.0000\n",
            " 84    0.0670                                                                                                        0.0000\n",
            " 85    0.0672            0.9863           0.8493      0.4149                                                         0.0000\n",
            " 86    0.0677                                                                                                        0.0000\n",
            " 87    0.0674                                                                                                        0.0000\n",
            " 88    0.0675                                                                                                        0.0000\n",
            " 89    0.0662                                                                                                        0.0000\n",
            " 90    0.0666            0.9880           0.8493      0.4166                                                         0.0000\n",
            " 91    0.0669                                                                                                        0.0000\n",
            " 92    0.0671                                                                                                        0.0000\n",
            " 93    0.0677                                                                                                        0.0000\n",
            " 94    0.0663                                                                                                        0.0000\n",
            " 95    0.0666            0.9897           0.8493      0.4173                                                         0.0000\n",
            " 96    0.0664                                                                                                        0.0000\n",
            " 97    0.0661                                                                                                        0.0000\n",
            " 98    0.0663                                                                                                        0.0000\n",
            " 99    0.0673            0.9897           0.8493      0.4172                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.91346157, dtype=float32), 'nll': 0.2849974, 'ece': DeviceArray(0.06474321, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=3 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/3/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.4124            0.6226           0.5068      0.7168                                                         0.0000\n",
            "  1    0.0665                                                                                                        0.0000\n",
            "  2    0.0669                                                                                                        0.0000\n",
            "  3    0.0667                                                                                                        0.0000\n",
            "  4    0.0663                                                                                                        0.0000\n",
            "  5    0.0663            0.8937           0.8014      0.4322                                                         0.0000\n",
            "  6    0.0661                                                                                                        0.0000\n",
            "  7    0.0656                                                                                                        0.0000\n",
            "  8    0.0656                                                                                                        0.0000\n",
            "  9    0.0647                                                                                                        0.0000\n",
            " 10    0.0666            0.9365           0.8562      0.3863                                                         0.0000\n",
            " 11    0.0666                                                                                                        0.0000\n",
            " 12    0.0662                                                                                                        0.0000\n",
            " 13    0.0662                                                                                                        0.0000\n",
            " 14    0.0663                                                                                                        0.0000\n",
            " 15    0.0661            0.9383           0.7945      0.4112                                                         0.0000\n",
            " 16    0.0670                                                                                                        0.0000\n",
            " 17    0.0665                                                                                                        0.0000\n",
            " 18    0.0664                                                                                                        0.0000\n",
            " 19    0.0660                                                                                                        0.0000\n",
            " 20    0.0661            0.9554           0.8699      0.3709                                                         0.0000\n",
            " 21    0.0676                                                                                                        0.0000\n",
            " 22    0.0667                                                                                                        0.0000\n",
            " 23    0.0670                                                                                                        0.0000\n",
            " 24    0.0667                                                                                                        0.0000\n",
            " 25    0.0671            0.9743           0.8699      0.3376                                                         0.0000\n",
            " 26    0.0670                                                                                                        0.0000\n",
            " 27    0.0679                                                                                                        0.0000\n",
            " 28    0.0666                                                                                                        0.0000\n",
            " 29    0.0668                                                                                                        0.0000\n",
            " 30    0.0665            0.9828           0.8630      0.3376                                                         0.0000\n",
            " 31    0.0668                                                                                                        0.0000\n",
            " 32    0.0660                                                                                                        0.0000\n",
            " 33    0.0665                                                                                                        0.0000\n",
            " 34    0.0667                                                                                                        0.0000\n",
            " 35    0.0664            0.9794           0.8219      0.3567                                                         0.0000\n",
            " 36    0.0675                                                                                                        0.0000\n",
            " 37    0.0668                                                                                                        0.0000\n",
            " 38    0.0667                                                                                                        0.0000\n",
            " 39    0.0658                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0661            0.9897           0.8699      0.3342                                                         0.0000\n",
            " 41    0.0664                                                                                                        0.0000\n",
            " 42    0.0670                                                                                                        0.0000\n",
            " 43    0.0667                                                                                                        0.0000\n",
            " 44    0.0673                                                                                                        0.0000\n",
            " 45    0.0752            0.9811           0.8493      0.3801                                                         0.0000\n",
            " 46    0.0681                                                                                                        0.0000\n",
            " 47    0.0678                                                                                                        0.0000\n",
            " 48    0.0679                                                                                                        0.0000\n",
            " 49    0.0678                                                                                                        0.0000\n",
            " 50    0.0680            0.9914           0.8630      0.3377                                                         0.0000\n",
            " 51    0.0697                                                                                                        0.0000\n",
            " 52    0.0679                                                                                                        0.0000\n",
            " 53    0.0671                                                                                                        0.0000\n",
            " 54    0.0676                                                                                                        0.0000\n",
            " 55    0.0674            0.9897           0.8699      0.3422                                                         0.0000\n",
            " 56    0.0671                                                                                                        0.0000\n",
            " 57    0.0663                                                                                                        0.0000\n",
            " 58    0.0694                                                                                                        0.0000\n",
            " 59    0.0674                                                                                                        0.0000\n",
            " 60    0.0674            0.9880           0.8425      0.3531                                                         0.0000\n",
            " 61    0.0663                                                                                                        0.0000\n",
            " 62    0.0662                                                                                                        0.0000\n",
            " 63    0.0662                                                                                                        0.0000\n",
            " 64    0.0663                                                                                                        0.0000\n",
            " 65    0.0663            0.9897           0.8425      0.3558                                                         0.0000\n",
            " 66    0.0667                                                                                                        0.0000\n",
            " 67    0.0666                                                                                                        0.0000\n",
            " 68    0.0664                                                                                                        0.0000\n",
            " 69    0.0667                                                                                                        0.0000\n",
            " 70    0.0668            0.9931           0.8699      0.3384                                                         0.0000\n",
            " 71    0.0667                                                                                                        0.0000\n",
            " 72    0.0664                                                                                                        0.0000\n",
            " 73    0.0663                                                                                                        0.0000\n",
            " 74    0.0667                                                                                                        0.0000\n",
            " 75    0.0666            0.9880           0.8425      0.3535                                                         0.0000\n",
            " 76    0.0666                                                                                                        0.0000\n",
            " 77    0.0663                                                                                                        0.0000\n",
            " 78    0.0663                                                                                                        0.0000\n",
            " 79    0.0663                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0663            0.9914           0.8562      0.3428                                                         0.0000\n",
            " 81    0.0669                                                                                                        0.0000\n",
            " 82    0.0662                                                                                                        0.0000\n",
            " 83    0.0666                                                                                                        0.0000\n",
            " 84    0.0662                                                                                                        0.0000\n",
            " 85    0.0661            0.9914           0.8562      0.3444                                                         0.0000\n",
            " 86    0.0661                                                                                                        0.0000\n",
            " 87    0.0662                                                                                                        0.0000\n",
            " 88    0.0669                                                                                                        0.0000\n",
            " 89    0.0669                                                                                                        0.0000\n",
            " 90    0.0670            0.9914           0.8562      0.3457                                                         0.0000\n",
            " 91    0.0667                                                                                                        0.0000\n",
            " 92    0.0666                                                                                                        0.0000\n",
            " 93    0.0666                                                                                                        0.0000\n",
            " 94    0.0672                                                                                                        0.0000\n",
            " 95    0.0669            0.9914           0.8562      0.3442                                                         0.0000\n",
            " 96    0.0671                                                                                                        0.0000\n",
            " 97    0.0665                                                                                                        0.0000\n",
            " 98    0.0666                                                                                                        0.0000\n",
            " 99    0.0664            0.9914           0.8562      0.3443                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.8942308, dtype=float32), 'nll': 0.28765452, 'ece': DeviceArray(0.06562845, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=4 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/4/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.3828            0.5712           0.5685      0.6758                                                         0.0000\n",
            "  1    0.0665                                                                                                        0.0000\n",
            "  2    0.0665                                                                                                        0.0000\n",
            "  3    0.0662                                                                                                        0.0000\n",
            "  4    0.0658                                                                                                        0.0000\n",
            "  5    0.0658            0.8816           0.7671      0.5209                                                         0.0000\n",
            "  6    0.0669                                                                                                        0.0000\n",
            "  7    0.0664                                                                                                        0.0000\n",
            "  8    0.0663                                                                                                        0.0000\n",
            "  9    0.0665                                                                                                        0.0000\n",
            " 10    0.0664            0.9262           0.8219      0.4611                                                         0.0000\n",
            " 11    0.0668                                                                                                        0.0000\n",
            " 12    0.0663                                                                                                        0.0000\n",
            " 13    0.0662                                                                                                        0.0000\n",
            " 14    0.0666                                                                                                        0.0000\n",
            " 15    0.0665            0.9400           0.8219      0.4257                                                         0.0000\n",
            " 16    0.0663                                                                                                        0.0000\n",
            " 17    0.0663                                                                                                        0.0000\n",
            " 18    0.0664                                                                                                        0.0000\n",
            " 19    0.0663                                                                                                        0.0000\n",
            " 20    0.0664            0.9383           0.8082      0.4357                                                         0.0000\n",
            " 21    0.0687                                                                                                        0.0000\n",
            " 22    0.0663                                                                                                        0.0000\n",
            " 23    0.0666                                                                                                        0.0000\n",
            " 24    0.0667                                                                                                        0.0000\n",
            " 25    0.0660            0.9691           0.8356      0.3943                                                         0.0000\n",
            " 26    0.0686                                                                                                        0.0000\n",
            " 27    0.0667                                                                                                        0.0000\n",
            " 28    0.0669                                                                                                        0.0000\n",
            " 29    0.0669                                                                                                        0.0000\n",
            " 30    0.0667            0.9640           0.8219      0.4291                                                         0.0000\n",
            " 31    0.0663                                                                                                        0.0000\n",
            " 32    0.0662                                                                                                        0.0000\n",
            " 33    0.0664                                                                                                        0.0000\n",
            " 34    0.0668                                                                                                        0.0000\n",
            " 35    0.0666            0.9640           0.8219      0.4389                                                         0.0000\n",
            " 36    0.0667                                                                                                        0.0000\n",
            " 37    0.0661                                                                                                        0.0000\n",
            " 38    0.0661                                                                                                        0.0000\n",
            " 39    0.0661                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0668            0.9846           0.8493      0.3881                                                         0.0000\n",
            " 41    0.0663                                                                                                        0.0000\n",
            " 42    0.0663                                                                                                        0.0000\n",
            " 43    0.0657                                                                                                        0.0000\n",
            " 44    0.0660                                                                                                        0.0000\n",
            " 45    0.0662            0.9880           0.8356      0.4033                                                         0.0000\n",
            " 46    0.0674                                                                                                        0.0000\n",
            " 47    0.0668                                                                                                        0.0000\n",
            " 48    0.0669                                                                                                        0.0000\n",
            " 49    0.0667                                                                                                        0.0000\n",
            " 50    0.0662            0.9880           0.8219      0.4217                                                         0.0000\n",
            " 51    0.0682                                                                                                        0.0000\n",
            " 52    0.0662                                                                                                        0.0000\n",
            " 53    0.0660                                                                                                        0.0000\n",
            " 54    0.0665                                                                                                        0.0000\n",
            " 55    0.0663            0.9897           0.8425      0.3979                                                         0.0000\n",
            " 56    0.0668                                                                                                        0.0000\n",
            " 57    0.0660                                                                                                        0.0000\n",
            " 58    0.0660                                                                                                        0.0000\n",
            " 59    0.0669                                                                                                        0.0000\n",
            " 60    0.0665            0.9914           0.8425      0.3995                                                         0.0000\n",
            " 61    0.0669                                                                                                        0.0000\n",
            " 62    0.0661                                                                                                        0.0000\n",
            " 63    0.0659                                                                                                        0.0000\n",
            " 64    0.0665                                                                                                        0.0000\n",
            " 65    0.0660            0.9914           0.8219      0.4200                                                         0.0000\n",
            " 66    0.0668                                                                                                        0.0000\n",
            " 67    0.0666                                                                                                        0.0000\n",
            " 68    0.0665                                                                                                        0.0000\n",
            " 69    0.0666                                                                                                        0.0000\n",
            " 70    0.0672            0.9880           0.8356      0.4428                                                         0.0000\n",
            " 71    0.0664                                                                                                        0.0000\n",
            " 72    0.0667                                                                                                        0.0000\n",
            " 73    0.0666                                                                                                        0.0000\n",
            " 74    0.0666                                                                                                        0.0000\n",
            " 75    0.0664            0.9914           0.8356      0.4154                                                         0.0000\n",
            " 76    0.0666                                                                                                        0.0000\n",
            " 77    0.0668                                                                                                        0.0000\n",
            " 78    0.0661                                                                                                        0.0000\n",
            " 79    0.0664                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0662            0.9914           0.8425      0.4144                                                         0.0000\n",
            " 81    0.0796                                                                                                        0.0000\n",
            " 82    0.0667                                                                                                        0.0000\n",
            " 83    0.0666                                                                                                        0.0000\n",
            " 84    0.0665                                                                                                        0.0000\n",
            " 85    0.0671            0.9931           0.8219      0.4231                                                         0.0000\n",
            " 86    0.0677                                                                                                        0.0000\n",
            " 87    0.0673                                                                                                        0.0000\n",
            " 88    0.0669                                                                                                        0.0000\n",
            " 89    0.0663                                                                                                        0.0000\n",
            " 90    0.0662            0.9931           0.8356      0.4132                                                         0.0000\n",
            " 91    0.0667                                                                                                        0.0000\n",
            " 92    0.0663                                                                                                        0.0000\n",
            " 93    0.0662                                                                                                        0.0000\n",
            " 94    0.0667                                                                                                        0.0000\n",
            " 95    0.0669            0.9931           0.8356      0.4144                                                         0.0000\n",
            " 96    0.0670                                                                                                        0.0000\n",
            " 97    0.0666                                                                                                        0.0000\n",
            " 98    0.0664                                                                                                        0.0000\n",
            " 99    0.0667            0.9914           0.8425      0.4146                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.8846154, dtype=float32), 'nll': 0.3405714, 'ece': DeviceArray(0.05744761, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=5 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/5/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.4161            0.5918           0.4932      0.7256                                                         0.0000\n",
            "  1    0.0666                                                                                                        0.0000\n",
            "  2    0.0663                                                                                                        0.0000\n",
            "  3    0.0673                                                                                                        0.0000\n",
            "  4    0.0669                                                                                                        0.0000\n",
            "  5    0.0672            0.8199           0.6918      0.6030                                                         0.0000\n",
            "  6    0.0672                                                                                                        0.0000\n",
            "  7    0.0667                                                                                                        0.0000\n",
            "  8    0.0666                                                                                                        0.0000\n",
            "  9    0.0683                                                                                                        0.0000\n",
            " 10    0.0663            0.9245           0.8356      0.4178                                                         0.0000\n",
            " 11    0.0677                                                                                                        0.0000\n",
            " 12    0.0673                                                                                                        0.0000\n",
            " 13    0.0672                                                                                                        0.0000\n",
            " 14    0.0669                                                                                                        0.0000\n",
            " 15    0.0671            0.9383           0.8151      0.3939                                                         0.0000\n",
            " 16    0.0670                                                                                                        0.0000\n",
            " 17    0.0662                                                                                                        0.0000\n",
            " 18    0.0664                                                                                                        0.0000\n",
            " 19    0.0661                                                                                                        0.0000\n",
            " 20    0.0666            0.9571           0.8288      0.3858                                                         0.0000\n",
            " 21    0.0722                                                                                                        0.0000\n",
            " 22    0.0665                                                                                                        0.0000\n",
            " 23    0.0661                                                                                                        0.0000\n",
            " 24    0.0664                                                                                                        0.0000\n",
            " 25    0.0661            0.9640           0.8356      0.3666                                                         0.0000\n",
            " 26    0.0670                                                                                                        0.0000\n",
            " 27    0.0665                                                                                                        0.0000\n",
            " 28    0.0662                                                                                                        0.0000\n",
            " 29    0.0666                                                                                                        0.0000\n",
            " 30    0.0666            0.9691           0.8425      0.3699                                                         0.0000\n",
            " 31    0.0664                                                                                                        0.0000\n",
            " 32    0.0671                                                                                                        0.0000\n",
            " 33    0.0666                                                                                                        0.0000\n",
            " 34    0.0664                                                                                                        0.0000\n",
            " 35    0.0670            0.9588           0.8151      0.3944                                                         0.0000\n",
            " 36    0.0666                                                                                                        0.0000\n",
            " 37    0.0664                                                                                                        0.0000\n",
            " 38    0.0663                                                                                                        0.0000\n",
            " 39    0.0662                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0667            0.9726           0.8356      0.3858                                                         0.0000\n",
            " 41    0.0676                                                                                                        0.0000\n",
            " 42    0.0666                                                                                                        0.0000\n",
            " 43    0.0665                                                                                                        0.0000\n",
            " 44    0.0662                                                                                                        0.0000\n",
            " 45    0.0665            0.9828           0.8562      0.3610                                                         0.0000\n",
            " 46    0.0675                                                                                                        0.0000\n",
            " 47    0.0669                                                                                                        0.0000\n",
            " 48    0.0671                                                                                                        0.0000\n",
            " 49    0.0671                                                                                                        0.0000\n",
            " 50    0.0664            0.9451           0.7808      0.5064                                                         0.0000\n",
            " 51    0.0735                                                                                                        0.0000\n",
            " 52    0.0666                                                                                                        0.0000\n",
            " 53    0.0661                                                                                                        0.0000\n",
            " 54    0.0663                                                                                                        0.0000\n",
            " 55    0.0662            0.9863           0.8493      0.3631                                                         0.0000\n",
            " 56    0.0671                                                                                                        0.0000\n",
            " 57    0.0663                                                                                                        0.0000\n",
            " 58    0.0667                                                                                                        0.0000\n",
            " 59    0.0671                                                                                                        0.0000\n",
            " 60    0.0673            0.9811           0.8288      0.3989                                                         0.0000\n",
            " 61    0.0671                                                                                                        0.0000\n",
            " 62    0.0663                                                                                                        0.0000\n",
            " 63    0.0676                                                                                                        0.0000\n",
            " 64    0.0662                                                                                                        0.0000\n",
            " 65    0.0661            0.9863           0.8562      0.3620                                                         0.0000\n",
            " 66    0.0670                                                                                                        0.0000\n",
            " 67    0.0669                                                                                                        0.0000\n",
            " 68    0.0663                                                                                                        0.0000\n",
            " 69    0.0664                                                                                                        0.0000\n",
            " 70    0.0665            0.9880           0.8630      0.3715                                                         0.0000\n",
            " 71    0.0668                                                                                                        0.0000\n",
            " 72    0.0668                                                                                                        0.0000\n",
            " 73    0.0674                                                                                                        0.0000\n",
            " 74    0.0673                                                                                                        0.0000\n",
            " 75    0.0668            0.9863           0.8425      0.3646                                                         0.0000\n",
            " 76    0.0669                                                                                                        0.0000\n",
            " 77    0.0667                                                                                                        0.0000\n",
            " 78    0.0666                                                                                                        0.0000\n",
            " 79    0.0664                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0665            0.9863           0.8493      0.3667                                                         0.0000\n",
            " 81    0.0688                                                                                                        0.0000\n",
            " 82    0.0675                                                                                                        0.0000\n",
            " 83    0.0665                                                                                                        0.0000\n",
            " 84    0.0663                                                                                                        0.0000\n",
            " 85    0.0663            0.9880           0.8630      0.3726                                                         0.0000\n",
            " 86    0.0672                                                                                                        0.0000\n",
            " 87    0.0658                                                                                                        0.0000\n",
            " 88    0.0681                                                                                                        0.0000\n",
            " 89    0.0664                                                                                                        0.0000\n",
            " 90    0.0669            0.9863           0.8562      0.3701                                                         0.0000\n",
            " 91    0.0666                                                                                                        0.0000\n",
            " 92    0.0663                                                                                                        0.0000\n",
            " 93    0.0666                                                                                                        0.0000\n",
            " 94    0.0664                                                                                                        0.0000\n",
            " 95    0.0668            0.9863           0.8562      0.3704                                                         0.0000\n",
            " 96    0.0672                                                                                                        0.0000\n",
            " 97    0.0665                                                                                                        0.0000\n",
            " 98    0.0668                                                                                                        0.0000\n",
            " 99    0.0668            0.9863           0.8562      0.3701                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.8942308, dtype=float32), 'nll': 0.31608826, 'ece': DeviceArray(0.06756385, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=6 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/6/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.4045            0.5369           0.4795      0.7039                                                         0.0000\n",
            "  1    0.0670                                                                                                        0.0000\n",
            "  2    0.0667                                                                                                        0.0000\n",
            "  3    0.0664                                                                                                        0.0000\n",
            "  4    0.0666                                                                                                        0.0000\n",
            "  5    0.0661            0.8456           0.7397      0.5855                                                         0.0000\n",
            "  6    0.0670                                                                                                        0.0000\n",
            "  7    0.0668                                                                                                        0.0000\n",
            "  8    0.0666                                                                                                        0.0000\n",
            "  9    0.0670                                                                                                        0.0000\n",
            " 10    0.0666            0.8714           0.7329      0.5200                                                         0.0000\n",
            " 11    0.0668                                                                                                        0.0000\n",
            " 12    0.0663                                                                                                        0.0000\n",
            " 13    0.0662                                                                                                        0.0000\n",
            " 14    0.0669                                                                                                        0.0000\n",
            " 15    0.0667            0.8988           0.7534      0.4863                                                         0.0000\n",
            " 16    0.0669                                                                                                        0.0000\n",
            " 17    0.0666                                                                                                        0.0000\n",
            " 18    0.0665                                                                                                        0.0000\n",
            " 19    0.0666                                                                                                        0.0000\n",
            " 20    0.0668            0.9074           0.7740      0.4454                                                         0.0000\n",
            " 21    0.0673                                                                                                        0.0000\n",
            " 22    0.0676                                                                                                        0.0000\n",
            " 23    0.0676                                                                                                        0.0000\n",
            " 24    0.0675                                                                                                        0.0000\n",
            " 25    0.0674            0.9417           0.8288      0.3874                                                         0.0000\n",
            " 26    0.0667                                                                                                        0.0000\n",
            " 27    0.0664                                                                                                        0.0000\n",
            " 28    0.0672                                                                                                        0.0000\n",
            " 29    0.0671                                                                                                        0.0000\n",
            " 30    0.0671            0.9468           0.8356      0.3767                                                         0.0000\n",
            " 31    0.0675                                                                                                        0.0000\n",
            " 32    0.0665                                                                                                        0.0000\n",
            " 33    0.0705                                                                                                        0.0000\n",
            " 34    0.0672                                                                                                        0.0000\n",
            " 35    0.0664            0.9503           0.8151      0.4027                                                         0.0000\n",
            " 36    0.0674                                                                                                        0.0000\n",
            " 37    0.0675                                                                                                        0.0000\n",
            " 38    0.0671                                                                                                        0.0000\n",
            " 39    0.0676                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0675            0.9691           0.8562      0.3576                                                         0.0000\n",
            " 41    0.0669                                                                                                        0.0000\n",
            " 42    0.0664                                                                                                        0.0000\n",
            " 43    0.0666                                                                                                        0.0000\n",
            " 44    0.0665                                                                                                        0.0000\n",
            " 45    0.0666            0.9623           0.8151      0.3743                                                         0.0000\n",
            " 46    0.0672                                                                                                        0.0000\n",
            " 47    0.0669                                                                                                        0.0000\n",
            " 48    0.0672                                                                                                        0.0000\n",
            " 49    0.0668                                                                                                        0.0000\n",
            " 50    0.0675            0.9777           0.8836      0.3518                                                         0.0000\n",
            " 51    0.0672                                                                                                        0.0000\n",
            " 52    0.0667                                                                                                        0.0000\n",
            " 53    0.0672                                                                                                        0.0000\n",
            " 54    0.0672                                                                                                        0.0000\n",
            " 55    0.0667            0.9846           0.8630      0.3476                                                         0.0000\n",
            " 56    0.0798                                                                                                        0.0000\n",
            " 57    0.0668                                                                                                        0.0000\n",
            " 58    0.0668                                                                                                        0.0000\n",
            " 59    0.0666                                                                                                        0.0000\n",
            " 60    0.0665            0.9708           0.8219      0.3674                                                         0.0000\n",
            " 61    0.0670                                                                                                        0.0000\n",
            " 62    0.0669                                                                                                        0.0000\n",
            " 63    0.0669                                                                                                        0.0000\n",
            " 64    0.0671                                                                                                        0.0000\n",
            " 65    0.0676            0.9777           0.8562      0.3500                                                         0.0000\n",
            " 66    0.0672                                                                                                        0.0000\n",
            " 67    0.0669                                                                                                        0.0000\n",
            " 68    0.0663                                                                                                        0.0000\n",
            " 69    0.0662                                                                                                        0.0000\n",
            " 70    0.0661            0.9794           0.8630      0.3507                                                         0.0000\n",
            " 71    0.0668                                                                                                        0.0000\n",
            " 72    0.0659                                                                                                        0.0000\n",
            " 73    0.0659                                                                                                        0.0000\n",
            " 74    0.0664                                                                                                        0.0000\n",
            " 75    0.0661            0.9794           0.8630      0.3540                                                         0.0000\n",
            " 76    0.0675                                                                                                        0.0000\n",
            " 77    0.0665                                                                                                        0.0000\n",
            " 78    0.0668                                                                                                        0.0000\n",
            " 79    0.0668                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0665            0.9828           0.8562      0.3490                                                         0.0000\n",
            " 81    0.0667                                                                                                        0.0000\n",
            " 82    0.0663                                                                                                        0.0000\n",
            " 83    0.0662                                                                                                        0.0000\n",
            " 84    0.0664                                                                                                        0.0000\n",
            " 85    0.0666            0.9794           0.8630      0.3523                                                         0.0000\n",
            " 86    0.0736                                                                                                        0.0000\n",
            " 87    0.0672                                                                                                        0.0000\n",
            " 88    0.0667                                                                                                        0.0000\n",
            " 89    0.0669                                                                                                        0.0000\n",
            " 90    0.0667            0.9794           0.8630      0.3535                                                         0.0000\n",
            " 91    0.0671                                                                                                        0.0000\n",
            " 92    0.0669                                                                                                        0.0000\n",
            " 93    0.0667                                                                                                        0.0000\n",
            " 94    0.0665                                                                                                        0.0000\n",
            " 95    0.0663            0.9794           0.8630      0.3518                                                         0.0000\n",
            " 96    0.0669                                                                                                        0.0000\n",
            " 97    0.0666                                                                                                        0.0000\n",
            " 98    0.0666                                                                                                        0.0000\n",
            " 99    0.0665            0.9794           0.8630      0.3516                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.86538464, dtype=float32), 'nll': 0.30834833, 'ece': DeviceArray(0.06076607, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=7 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/7/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.4218            0.6381           0.5479      0.7011                                                         0.0000\n",
            "  1    0.0667                                                                                                        0.0000\n",
            "  2    0.0664                                                                                                        0.0000\n",
            "  3    0.0666                                                                                                        0.0000\n",
            "  4    0.0670                                                                                                        0.0000\n",
            "  5    0.0661            0.7873           0.6370      0.6138                                                         0.0000\n",
            "  6    0.0669                                                                                                        0.0000\n",
            "  7    0.0667                                                                                                        0.0000\n",
            "  8    0.0664                                                                                                        0.0000\n",
            "  9    0.0665                                                                                                        0.0000\n",
            " 10    0.0663            0.8816           0.8151      0.5085                                                         0.0000\n",
            " 11    0.0668                                                                                                        0.0000\n",
            " 12    0.0669                                                                                                        0.0000\n",
            " 13    0.0665                                                                                                        0.0000\n",
            " 14    0.0665                                                                                                        0.0000\n",
            " 15    0.0666            0.8988           0.8219      0.4566                                                         0.0000\n",
            " 16    0.0683                                                                                                        0.0000\n",
            " 17    0.0688                                                                                                        0.0000\n",
            " 18    0.0688                                                                                                        0.0000\n",
            " 19    0.0678                                                                                                        0.0000\n",
            " 20    0.0675            0.9091           0.7740      0.4629                                                         0.0000\n",
            " 21    0.0680                                                                                                        0.0000\n",
            " 22    0.0680                                                                                                        0.0000\n",
            " 23    0.0673                                                                                                        0.0000\n",
            " 24    0.0716                                                                                                        0.0000\n",
            " 25    0.0715            0.9177           0.8082      0.4208                                                         0.0000\n",
            " 26    0.0716                                                                                                        0.0000\n",
            " 27    0.0675                                                                                                        0.0000\n",
            " 28    0.0681                                                                                                        0.0000\n",
            " 29    0.0681                                                                                                        0.0000\n",
            " 30    0.0679            0.9434           0.8288      0.4025                                                         0.0000\n",
            " 31    0.0668                                                                                                        0.0000\n",
            " 32    0.0667                                                                                                        0.0000\n",
            " 33    0.0670                                                                                                        0.0000\n",
            " 34    0.0665                                                                                                        0.0000\n",
            " 35    0.0651            0.9400           0.8082      0.4240                                                         0.0000\n",
            " 36    0.0665                                                                                                        0.0000\n",
            " 37    0.0666                                                                                                        0.0000\n",
            " 38    0.0668                                                                                                        0.0000\n",
            " 39    0.0669                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0667            0.9365           0.8151      0.4395                                                         0.0000\n",
            " 41    0.0671                                                                                                        0.0000\n",
            " 42    0.0661                                                                                                        0.0000\n",
            " 43    0.0665                                                                                                        0.0000\n",
            " 44    0.0664                                                                                                        0.0000\n",
            " 45    0.0658            0.9640           0.8425      0.3832                                                         0.0000\n",
            " 46    0.0688                                                                                                        0.0000\n",
            " 47    0.0670                                                                                                        0.0000\n",
            " 48    0.0672                                                                                                        0.0000\n",
            " 49    0.0666                                                                                                        0.0000\n",
            " 50    0.0675            0.9708           0.8425      0.3827                                                         0.0000\n",
            " 51    0.0674                                                                                                        0.0000\n",
            " 52    0.0670                                                                                                        0.0000\n",
            " 53    0.0665                                                                                                        0.0000\n",
            " 54    0.0664                                                                                                        0.0000\n",
            " 55    0.0667            0.9777           0.8425      0.3705                                                         0.0000\n",
            " 56    0.0668                                                                                                        0.0000\n",
            " 57    0.0665                                                                                                        0.0000\n",
            " 58    0.0670                                                                                                        0.0000\n",
            " 59    0.0663                                                                                                        0.0000\n",
            " 60    0.0666            0.9828           0.8288      0.3738                                                         0.0000\n",
            " 61    0.0669                                                                                                        0.0000\n",
            " 62    0.0674                                                                                                        0.0000\n",
            " 63    0.0685                                                                                                        0.0000\n",
            " 64    0.0671                                                                                                        0.0000\n",
            " 65    0.0676            0.9760           0.8425      0.3921                                                         0.0000\n",
            " 66    0.0670                                                                                                        0.0000\n",
            " 67    0.0658                                                                                                        0.0000\n",
            " 68    0.0659                                                                                                        0.0000\n",
            " 69    0.0663                                                                                                        0.0000\n",
            " 70    0.0664            0.9846           0.8425      0.3780                                                         0.0000\n",
            " 71    0.0751                                                                                                        0.0000\n",
            " 72    0.0669                                                                                                        0.0000\n",
            " 73    0.0663                                                                                                        0.0000\n",
            " 74    0.0661                                                                                                        0.0000\n",
            " 75    0.0675            0.9794           0.8493      0.3878                                                         0.0000\n",
            " 76    0.0668                                                                                                        0.0000\n",
            " 77    0.0675                                                                                                        0.0000\n",
            " 78    0.0678                                                                                                        0.0000\n",
            " 79    0.0672                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0676            0.9828           0.8356      0.3948                                                         0.0000\n",
            " 81    0.0674                                                                                                        0.0000\n",
            " 82    0.0669                                                                                                        0.0000\n",
            " 83    0.0665                                                                                                        0.0000\n",
            " 84    0.0664                                                                                                        0.0000\n",
            " 85    0.0658            0.9811           0.8493      0.3831                                                         0.0000\n",
            " 86    0.0661                                                                                                        0.0000\n",
            " 87    0.0657                                                                                                        0.0000\n",
            " 88    0.0660                                                                                                        0.0000\n",
            " 89    0.0661                                                                                                        0.0000\n",
            " 90    0.0661            0.9811           0.8493      0.3837                                                         0.0000\n",
            " 91    0.0668                                                                                                        0.0000\n",
            " 92    0.0664                                                                                                        0.0000\n",
            " 93    0.0666                                                                                                        0.0000\n",
            " 94    0.0661                                                                                                        0.0000\n",
            " 95    0.0663            0.9811           0.8493      0.3849                                                         0.0000\n",
            " 96    0.0667                                                                                                        0.0000\n",
            " 97    0.0660                                                                                                        0.0000\n",
            " 98    0.0664                                                                                                        0.0000\n",
            " 99    0.0665            0.9811           0.8493      0.3854                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.9038462, dtype=float32), 'nll': 0.27158225, 'ece': DeviceArray(0.05101467, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=8 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/8/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.5228            0.5729           0.5274      0.6794                                                         0.0000\n",
            "  1    0.0682                                                                                                        0.0000\n",
            "  2    0.0675                                                                                                        0.0000\n",
            "  3    0.0675                                                                                                        0.0000\n",
            "  4    0.0676                                                                                                        0.0000\n",
            "  5    0.0671            0.8954           0.7945      0.4680                                                         0.0000\n",
            "  6    0.0672                                                                                                        0.0000\n",
            "  7    0.0672                                                                                                        0.0000\n",
            "  8    0.0671                                                                                                        0.0000\n",
            "  9    0.0672                                                                                                        0.0000\n",
            " 10    0.0673            0.9280           0.7945      0.4283                                                         0.0000\n",
            " 11    0.0686                                                                                                        0.0000\n",
            " 12    0.0679                                                                                                        0.0000\n",
            " 13    0.0679                                                                                                        0.0000\n",
            " 14    0.0673                                                                                                        0.0000\n",
            " 15    0.0674            0.9520           0.8630      0.3702                                                         0.0000\n",
            " 16    0.0676                                                                                                        0.0000\n",
            " 17    0.0685                                                                                                        0.0000\n",
            " 18    0.0685                                                                                                        0.0000\n",
            " 19    0.0682                                                                                                        0.0000\n",
            " 20    0.0684            0.9314           0.8082      0.4331                                                         0.0000\n",
            " 21    0.0736                                                                                                        0.0000\n",
            " 22    0.0681                                                                                                        0.0000\n",
            " 23    0.0681                                                                                                        0.0000\n",
            " 24    0.0678                                                                                                        0.0000\n",
            " 25    0.0675            0.9691           0.8630      0.3558                                                         0.0000\n",
            " 26    0.0675                                                                                                        0.0000\n",
            " 27    0.0673                                                                                                        0.0000\n",
            " 28    0.0669                                                                                                        0.0000\n",
            " 29    0.0677                                                                                                        0.0000\n",
            " 30    0.0688            0.9726           0.8425      0.3649                                                         0.0000\n",
            " 31    0.0685                                                                                                        0.0000\n",
            " 32    0.0685                                                                                                        0.0000\n",
            " 33    0.0687                                                                                                        0.0000\n",
            " 34    0.0685                                                                                                        0.0000\n",
            " 35    0.0681            0.9760           0.8767      0.3721                                                         0.0000\n",
            " 36    0.0676                                                                                                        0.0000\n",
            " 37    0.0672                                                                                                        0.0000\n",
            " 38    0.0671                                                                                                        0.0000\n",
            " 39    0.0670                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0674            0.9880           0.8562      0.3629                                                         0.0000\n",
            " 41    0.0672                                                                                                        0.0000\n",
            " 42    0.0678                                                                                                        0.0000\n",
            " 43    0.0674                                                                                                        0.0000\n",
            " 44    0.0672                                                                                                        0.0000\n",
            " 45    0.0670            0.9811           0.8767      0.3596                                                         0.0000\n",
            " 46    0.0678                                                                                                        0.0000\n",
            " 47    0.0677                                                                                                        0.0000\n",
            " 48    0.0672                                                                                                        0.0000\n",
            " 49    0.0681                                                                                                        0.0000\n",
            " 50    0.0677            0.9880           0.8425      0.3758                                                         0.0000\n",
            " 51    0.0685                                                                                                        0.0000\n",
            " 52    0.0671                                                                                                        0.0000\n",
            " 53    0.0675                                                                                                        0.0000\n",
            " 54    0.0675                                                                                                        0.0000\n",
            " 55    0.0677            0.9777           0.8356      0.3998                                                         0.0000\n",
            " 56    0.0678                                                                                                        0.0000\n",
            " 57    0.0676                                                                                                        0.0000\n",
            " 58    0.0675                                                                                                        0.0000\n",
            " 59    0.0675                                                                                                        0.0000\n",
            " 60    0.0678            0.9914           0.8562      0.3565                                                         0.0000\n",
            " 61    0.0683                                                                                                        0.0000\n",
            " 62    0.0671                                                                                                        0.0000\n",
            " 63    0.0680                                                                                                        0.0000\n",
            " 64    0.0676                                                                                                        0.0000\n",
            " 65    0.0679            0.9931           0.8493      0.3693                                                         0.0000\n",
            " 66    0.0674                                                                                                        0.0000\n",
            " 67    0.0671                                                                                                        0.0000\n",
            " 68    0.0667                                                                                                        0.0000\n",
            " 69    0.0670                                                                                                        0.0000\n",
            " 70    0.0668            0.9914           0.8425      0.3564                                                         0.0000\n",
            " 71    0.0677                                                                                                        0.0000\n",
            " 72    0.0669                                                                                                        0.0000\n",
            " 73    0.0670                                                                                                        0.0000\n",
            " 74    0.0672                                                                                                        0.0000\n",
            " 75    0.0676            0.9931           0.8425      0.3663                                                         0.0000\n",
            " 76    0.0681                                                                                                        0.0000\n",
            " 77    0.0676                                                                                                        0.0000\n",
            " 78    0.0672                                                                                                        0.0000\n",
            " 79    0.0671                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0678            0.9931           0.8425      0.3663                                                         0.0000\n",
            " 81    0.0710                                                                                                        0.0000\n",
            " 82    0.0678                                                                                                        0.0000\n",
            " 83    0.0676                                                                                                        0.0000\n",
            " 84    0.0675                                                                                                        0.0000\n",
            " 85    0.0671            0.9914           0.8425      0.3612                                                         0.0000\n",
            " 86    0.0680                                                                                                        0.0000\n",
            " 87    0.0675                                                                                                        0.0000\n",
            " 88    0.0674                                                                                                        0.0000\n",
            " 89    0.0679                                                                                                        0.0000\n",
            " 90    0.0680            0.9914           0.8425      0.3640                                                         0.0000\n",
            " 91    0.0673                                                                                                        0.0000\n",
            " 92    0.0675                                                                                                        0.0000\n",
            " 93    0.0676                                                                                                        0.0000\n",
            " 94    0.0670                                                                                                        0.0000\n",
            " 95    0.0671            0.9914           0.8425      0.3620                                                         0.0000\n",
            " 96    0.0681                                                                                                        0.0000\n",
            " 97    0.0675                                                                                                        0.0000\n",
            " 98    0.0677                                                                                                        0.0000\n",
            " 99    0.0677            0.9914           0.8425      0.3622                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.8942308, dtype=float32), 'nll': 0.27770758, 'ece': DeviceArray(0.05169176, dtype=float32)}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=9 --weight_decay=10 --dir=runs/sgd/mirabestc/lenet/9/ --dataset_name=mirabest/confident --model_name=lenet --init_step_size=3e-7 --num_epochs=100 --eval_freq=5 --batch_size=53 --save_freq=5 --optimizer=SGD --train_split=train[:80%] --test_split=train[80%:]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  0    2.3759            0.5403           0.5548      0.6918                                                         0.0000\n",
            "  1    0.0674                                                                                                        0.0000\n",
            "  2    0.0663                                                                                                        0.0000\n",
            "  3    0.0670                                                                                                        0.0000\n",
            "  4    0.0665                                                                                                        0.0000\n",
            "  5    0.0663            0.8799           0.7534      0.4956                                                         0.0000\n",
            "  6    0.0687                                                                                                        0.0000\n",
            "  7    0.0673                                                                                                        0.0000\n",
            "  8    0.0676                                                                                                        0.0000\n",
            "  9    0.0679                                                                                                        0.0000\n",
            " 10    0.0674            0.9057           0.8288      0.4208                                                         0.0000\n",
            " 11    0.0670                                                                                                        0.0000\n",
            " 12    0.0666                                                                                                        0.0000\n",
            " 13    0.0663                                                                                                        0.0000\n",
            " 14    0.0662                                                                                                        0.0000\n",
            " 15    0.0663            0.9417           0.8425      0.3758                                                         0.0000\n",
            " 16    0.0664                                                                                                        0.0000\n",
            " 17    0.0667                                                                                                        0.0000\n",
            " 18    0.0665                                                                                                        0.0000\n",
            " 19    0.0662                                                                                                        0.0000\n",
            " 20    0.0673            0.9503           0.8151      0.3646                                                         0.0000\n",
            " 21    0.0669                                                                                                        0.0000\n",
            " 22    0.0674                                                                                                        0.0000\n",
            " 23    0.0675                                                                                                        0.0000\n",
            " 24    0.0676                                                                                                        0.0000\n",
            " 25    0.0668            0.9537           0.8082      0.3621                                                         0.0000\n",
            " 26    0.0665                                                                                                        0.0000\n",
            " 27    0.0668                                                                                                        0.0000\n",
            " 28    0.0668                                                                                                        0.0000\n",
            " 29    0.0666                                                                                                        0.0000\n",
            " 30    0.0666            0.9777           0.8699      0.3200                                                         0.0000\n",
            " 31    0.0693                                                                                                        0.0000\n",
            " 32    0.0671                                                                                                        0.0000\n",
            " 33    0.0671                                                                                                        0.0000\n",
            " 34    0.0671                                                                                                        0.0000\n",
            " 35    0.0670            0.9674           0.8151      0.3607                                                         0.0000\n",
            " 36    0.0666                                                                                                        0.0000\n",
            " 37    0.0672                                                                                                        0.0000\n",
            " 38    0.0669                                                                                                        0.0000\n",
            " 39    0.0665                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 40    0.0666            0.9846           0.8836      0.3131                                                         0.0000\n",
            " 41    0.0674                                                                                                        0.0000\n",
            " 42    0.0670                                                                                                        0.0000\n",
            " 43    0.0668                                                                                                        0.0000\n",
            " 44    0.0669                                                                                                        0.0000\n",
            " 45    0.0672            0.9657           0.8082      0.3838                                                         0.0000\n",
            " 46    0.0664                                                                                                        0.0000\n",
            " 47    0.0663                                                                                                        0.0000\n",
            " 48    0.0660                                                                                                        0.0000\n",
            " 49    0.0662                                                                                                        0.0000\n",
            " 50    0.0658            0.9914           0.8699      0.3128                                                         0.0000\n",
            " 51    0.0667                                                                                                        0.0000\n",
            " 52    0.0664                                                                                                        0.0000\n",
            " 53    0.0664                                                                                                        0.0000\n",
            " 54    0.0662                                                                                                        0.0000\n",
            " 55    0.0662            0.9880           0.8493      0.3230                                                         0.0000\n",
            " 56    0.0759                                                                                                        0.0000\n",
            " 57    0.0663                                                                                                        0.0000\n",
            " 58    0.0669                                                                                                        0.0000\n",
            " 59    0.0666                                                                                                        0.0000\n",
            " 60    0.0665            0.9931           0.8767      0.3052                                                         0.0000\n",
            " 61    0.0677                                                                                                        0.0000\n",
            " 62    0.0667                                                                                                        0.0000\n",
            " 63    0.0674                                                                                                        0.0000\n",
            " 64    0.0669                                                                                                        0.0000\n",
            " 65    0.0666            0.9931           0.8699      0.3098                                                         0.0000\n",
            " 66    0.0664                                                                                                        0.0000\n",
            " 67    0.0669                                                                                                        0.0000\n",
            " 68    0.0669                                                                                                        0.0000\n",
            " 69    0.0667                                                                                                        0.0000\n",
            " 70    0.0664            0.9931           0.8562      0.3254                                                         0.0000\n",
            " 71    0.0666                                                                                                        0.0000\n",
            " 72    0.0664                                                                                                        0.0000\n",
            " 73    0.0669                                                                                                        0.0000\n",
            " 74    0.0668                                                                                                        0.0000\n",
            " 75    0.0666            0.9931           0.8562      0.3220                                                         0.0000\n",
            " 76    0.0665                                                                                                        0.0000\n",
            " 77    0.0666                                                                                                        0.0000\n",
            " 78    0.0664                                                                                                        0.0000\n",
            " 79    0.0665                                                                                                        0.0000\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            "  i         t    train/accuracy    test/accuracy    test/nll  test/ens_accuracy    test/ens_nll    test/ens_ece          lr\n",
            "---  --------  ----------------  ---------------  ----------  -------------------  --------------  --------------  --------\n",
            " 80    0.0657            0.9931           0.8562      0.3155                                                         0.0000\n",
            " 81    0.0661                                                                                                        0.0000\n",
            " 82    0.0668                                                                                                        0.0000\n",
            " 83    0.0672                                                                                                        0.0000\n",
            " 84    0.0672                                                                                                        0.0000\n",
            " 85    0.0669            0.9931           0.8699      0.3093                                                         0.0000\n",
            " 86    0.0677                                                                                                        0.0000\n",
            " 87    0.0679                                                                                                        0.0000\n",
            " 88    0.0660                                                                                                        0.0000\n",
            " 89    0.0656                                                                                                        0.0000\n",
            " 90    0.0663            0.9931           0.8630      0.3138                                                         0.0000\n",
            " 91    0.0672                                                                                                        0.0000\n",
            " 92    0.0667                                                                                                        0.0000\n",
            " 93    0.0665                                                                                                        0.0000\n",
            " 94    0.0661                                                                                                        0.0000\n",
            " 95    0.0661            0.9931           0.8630      0.3141                                                         0.0000\n",
            " 96    0.0667                                                                                                        0.0000\n",
            " 97    0.0674                                                                                                        0.0000\n",
            " 98    0.0672                                                                                                        0.0000\n",
            " 99    0.0673            0.9931           0.8630      0.3140                                                         0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'accuracy': DeviceArray(0.8846154, dtype=float32), 'nll': 0.35532004, 'ece': DeviceArray(0.07075272, dtype=float32)}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhXkyDWgOrkj",
        "outputId": "3f97c3f2-ec7e-4d6f-a10c-1c26e8abbb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8913463 0.016118323\n",
            "NLL 0.30095124 0.027365157\n",
            "ECE 0.061434068 0.013944539\n"
          ]
        }
      ],
      "source": [
        "accuracies = []\n",
        "nlls = []\n",
        "eces = []\n",
        "softmax = []\n",
        "for i, root in enumerate(glob.glob('/content/runs/sgd/mirabestc/lenet/*/*/')):\n",
        "  data = np.load(root + '/test_set.npy')  \n",
        "  prediction = np.load(root + '/predictions.npy')\n",
        "  metrics = np.load(root + '/metrics.npy', allow_pickle=True)\n",
        "  accuracies.append(metrics.item()['accuracy'])\n",
        "  nlls.append(metrics.item()['nll'])\n",
        "  eces.append(metrics.item()['ece'])\n",
        "  softmax.append(np.squeeze(prediction))\n",
        "print('Accuracy', np.mean(accuracies), np.std(accuracies))\n",
        "print('NLL', np.mean(nlls), np.std(nlls))\n",
        "print('ECE', np.mean(eces), np.std(eces))\n",
        "softmax = np.array(softmax)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_softmax = np.mean(softmax, axis=0)\n",
        "ensemble_accuracy = np.mean(np.argmax(mean_softmax, axis=-1) == data)\n",
        "print('Ensemble accuracy', ensemble_accuracy)"
      ],
      "metadata": {
        "id": "G-GBlS1A0_X3",
        "outputId": "8e1a4adf-ed37-4a1f-a79e-5e7d3bca6ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble accuracy 0.9230769230769231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def uncertainty(softmax):\n",
        "  # Per example softmax with shape(num_examples, num_classes)\n",
        "  predictive_entropy = 0\n",
        "  single_pass_entropy = 0\n",
        "  for i in range(softmax.shape[1]):\n",
        "    # Sum over classes\n",
        "    predictive_entropy += -np.mean(softmax[:,i])*np.log(np.mean(softmax[:,i]))\n",
        "    single_pass_entropy += -softmax[:,i]*np.log(softmax[:,i])\n",
        "  single_pass_entropy = np.mean(single_pass_entropy)\n",
        "  mutual_info = predictive_entropy - single_pass_entropy\n",
        "  return predictive_entropy, single_pass_entropy, mutual_info"
      ],
      "metadata": {
        "id": "StORKbIX5WfY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictive_entropies = [] \n",
        "single_pass_entropies = []\n",
        "mutual_infos = []\n",
        "for i in range(softmax.shape[1]):\n",
        "  predictive_entropy, single_pass_entropy, mutual_info = uncertainty(softmax[:,i,:])\n",
        "  predictive_entropies.append(predictive_entropy)\n",
        "  single_pass_entropies.append(single_pass_entropy)\n",
        "  mutual_infos.append(mutual_info)\n",
        "print('Predictive entropy:', np.mean(predictive_entropies), np.std(predictive_entropies))\n",
        "print('Single pass entropy:', np.mean(single_pass_entropies), np.std(single_pass_entropies))\n",
        "print('Mutual info:', np.mean(mutual_infos), np.std(mutual_infos))"
      ],
      "metadata": {
        "id": "irRgQcsrAAEV",
        "outputId": "66bc7ac4-e78d-415f-c92e-71512a952340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictive entropy: 0.2490204579440055 0.23381561229745645\n",
            "Single pass entropy: 0.22635254 0.2101962\n",
            "Mutual info: 0.022667911052709454 0.0372433065023185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(predictive_entropies)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GZk1S2xLMpJq",
        "outputId": "87924e0f-f837-44c3-f7df-9d41196b2b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(single_pass_entropies)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jB95TfL7M1ax",
        "outputId": "7f832744-9d0d-4a42-e0d6-c1246aba1256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(mutual_infos)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P2lrt1FSM59f",
        "outputId": "f50780d7-b7a0-4f0d-c49b-d20a311f9d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vqm9C_HLzDPm"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Mirabest_ensemble.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}