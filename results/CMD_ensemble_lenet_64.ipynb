{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMD_ensemble_lenet_64.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZwJ7w6dqhmJe0IROQDdhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/bnn_hmc/blob/main/results/CMD_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lyIHOGnKXK_L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nruns = 10\n",
        "model = 'lenet'\n",
        "image_size = 64"
      ],
      "metadata": {
        "id": "R3Rl5M6PXOAu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiLYSWLdZ3qE",
        "outputId": "d8c0e789-b81d-4b99-83a6-3fdc85be367f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 23 17:34:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astro-datasets --upgrade\n",
        "!pip install tensorflow_datasets --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXRxmHDuZ5qS",
        "outputId": "029cfe9e-c31d-4953-bd0e-4894a4236ae5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting astro-datasets\n",
            "  Downloading astro_datasets-0.0.10.tar.gz (12 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (4.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astro-datasets) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astro-datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->astro-datasets) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.47.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->astro-datasets) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->astro-datasets) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (1.9.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (5.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (0.10.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (0.3.5.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (0.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (4.64.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->astro-datasets) (2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets->astro-datasets) (1.56.4)\n",
            "Building wheels for collected packages: astro-datasets\n",
            "  Building wheel for astro-datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for astro-datasets: filename=astro_datasets-0.0.10-py3-none-any.whl size=15992 sha256=e2b4abe1bbb66362aa8bae5e551bb5abc1e0c2967970f2b4e66d2ee319546763\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/b2/9d/97c264f6addbd178fe1c8ff119617e1515cb8c0d0f220605cf\n",
            "Successfully built astro-datasets\n",
            "Installing collected packages: astro-datasets\n",
            "Successfully installed astro-datasets-0.0.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.9.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.7.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.64.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.21.6)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.9.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow_datasets) (3.8.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('bnn_hmc', ignore_errors=True)"
      ],
      "metadata": {
        "id": "04VOUqtHaQ6J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adammoss/bnn_hmc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxJ5slCqaTwk",
        "outputId": "2cbb546c-776e-483d-9e15-d27c0b860a86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bnn_hmc'...\n",
            "remote: Enumerating objects: 479, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 479 (delta 135), reused 93 (delta 58), pack-reused 288\u001b[K\n",
            "Receiving objects: 100% (479/479), 918.00 KiB | 1.90 MiB/s, done.\n",
            "Resolving deltas: 100% (329/329), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install --upgrade https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.65+cuda111-cp37-none-manylinux2010_x86_64.whl\n",
        "!pip install jax==0.2.12\n",
        "!pip install dm-haiku==0.0.5.dev0 optax==0.0.6 chex==0.0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtBhPxWaaVgd",
        "outputId": "9b8baf7c-a25d-4b8b-bd27-217b7b50c2c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaxlib==0.1.65+cuda111\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.65+cuda111-cp37-none-manylinux2010_x86_64.whl (189.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 189.4 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (2.0)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.14+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.14+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.14+cuda11.cudnn805\n",
            "Successfully installed jaxlib-0.1.65+cuda111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jax==0.2.12\n",
            "  Downloading jax-0.2.12.tar.gz (590 kB)\n",
            "\u001b[K     |████████████████████████████████| 590 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.2.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (3.3.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.12-py3-none-any.whl size=682487 sha256=8d28b90d7fda559c20d5cbd0d8c6d14fbdbf9cbeb523eb22188fdd187e80643b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/4d/e5/73eec5070b77f25664c67bd793d4eb97f41bbf9be7afafd15e\n",
            "Successfully built jax\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.14\n",
            "    Uninstalling jax-0.3.14:\n",
            "      Successfully uninstalled jax-0.3.14\n",
            "Successfully installed jax-0.2.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku==0.0.5.dev0\n",
            "  Downloading dm_haiku-0.0.5.dev0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting optax==0.0.6\n",
            "  Downloading optax-0.0.6-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting chex==0.0.6\n",
            "  Downloading chex-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 609 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.8.10)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (1.2.0)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.6) (0.2.12)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax==0.0.6) (0.1.65+cuda111)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.6) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.6) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax==0.0.6) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax==0.0.6) (1.7.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax==0.0.6) (2.0)\n",
            "Installing collected packages: chex, optax, dm-haiku\n",
            "Successfully installed chex-0.0.6 dm-haiku-0.0.5.dev0 optax-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, root in enumerate(glob.glob('/content/runs/*/')):\n",
        "  shutil.rmtree(root, ignore_errors=True)"
      ],
      "metadata": {
        "id": "ygzPE1Xk2nGU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nruns):\n",
        " base_cmd = ['python3', 'bnn_hmc/scripts/run_sgd.py', '--seed=%s' % i, '--weight_decay=10', '--dir=runs/sgd/cmd/%s/' % i, \n",
        " '--dataset_name=cmd', '--model_name=%s' % model, '--scaling=asinh', \n",
        " '--init_step_size=1e-7', '--num_epochs=50', '--save_freq=5',\n",
        " '--builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]}',\n",
        " '--image_size=%s' % image_size, '--eval_freq=5', '--batch_size=100', '--optimizer=SGD']\n",
        " train_cmd = base_cmd + ['--train_split=train[:90%]', '--test_split=train[90%:95%]']\n",
        " eval_cmd = base_cmd + ['--eval_split=train[95%:]']\n",
        " print(' '.join(train_cmd))\n",
        " p = subprocess.run(train_cmd, capture_output=True)\n",
        " print(p.stdout.decode('utf8'))\n",
        " p = subprocess.run(eval_cmd, capture_output=True)\n",
        " print(p.stdout.decode('utf8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2OwrFwv624z",
        "outputId": "a7a037de-c330-4808-b70a-5c050c2f5482"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3 bnn_hmc/scripts/run_sgd.py --seed=0 --weight_decay=10 --dir=runs/sgd/cmd/0/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/IllustrisTNG_Mtot_omegam/cmd/1.0.3...\u001b[0m\n",
            "\u001b[1mDataset cmd downloaded and prepared to /root/tensorflow_datasets/IllustrisTNG_Mtot_omegam/cmd/1.0.3. Subsequent calls will reuse this data.\u001b[0m\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    5.6183        0.1157      -0.0188       0.1170     -0.0177                                     0.0000\n",
            "  1    0.2998                                                                                         0.0000\n",
            "  2    0.2989                                                                                         0.0000\n",
            "  3    0.2990                                                                                         0.0000\n",
            "  4    0.2985                                                                                         0.0000\n",
            "  5    0.2986        0.1158      -0.7363       0.1174     -0.7234                                     0.0000\n",
            "  6    0.2988                                                                                         0.0000\n",
            "  7    0.2992                                                                                         0.0000\n",
            "  8    0.2996                                                                                         0.0000\n",
            "  9    0.2985                                                                                         0.0000\n",
            " 10    0.2992        0.1154      -0.7402       0.1168     -0.7279                                     0.0000\n",
            " 11    0.2988                                                                                         0.0000\n",
            " 12    0.2988                                                                                         0.0000\n",
            " 13    0.2980                                                                                         0.0000\n",
            " 14    0.2981                                                                                         0.0000\n",
            " 15    0.2980        0.1153      -0.7410       0.1167     -0.7290                                     0.0000\n",
            " 16    0.2993                                                                                         0.0000\n",
            " 17    0.2994                                                                                         0.0000\n",
            " 18    0.2990                                                                                         0.0000\n",
            " 19    0.2989                                                                                         0.0000\n",
            " 20    0.2989        0.1160      -0.7351       0.1176     -0.7215                                     0.0000\n",
            " 21    0.2986                                                                                         0.0000\n",
            " 22    0.2986                                                                                         0.0000\n",
            " 23    0.2991                                                                                         0.0000\n",
            " 24    0.2995                                                                                         0.0000\n",
            " 25    0.2986        0.1153      -0.7411       0.1168     -0.7282                                     0.0000\n",
            " 26    0.2992                                                                                         0.0000\n",
            " 27    0.2985                                                                                         0.0000\n",
            " 28    0.2990                                                                                         0.0000\n",
            " 29    0.2989                                                                                         0.0000\n",
            " 30    0.2993        0.1153      -0.7415       0.1167     -0.7290                                     0.0000\n",
            " 31    0.2989                                                                                         0.0000\n",
            " 32    0.2985                                                                                         0.0000\n",
            " 33    0.2985                                                                                         0.0000\n",
            " 34    0.2988                                                                                         0.0000\n",
            " 35    0.2989        0.1153      -0.7415       0.1167     -0.7288                                     0.0000\n",
            " 36    0.2982                                                                                         0.0000\n",
            " 37    0.2981                                                                                         0.0000\n",
            " 38    0.2987                                                                                         0.0000\n",
            " 39    0.2982                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2986        0.1153      -0.7415       0.1167     -0.7290                                     0.0000\n",
            " 41    0.2981                                                                                         0.0000\n",
            " 42    0.2981                                                                                         0.0000\n",
            " 43    0.2987                                                                                         0.0000\n",
            " 44    0.2984                                                                                         0.0000\n",
            " 45    0.2986        0.1153      -0.7415       0.1167     -0.7289                                     0.0000\n",
            " 46    0.2988                                                                                         0.0000\n",
            " 47    0.2985                                                                                         0.0000\n",
            " 48    0.2989                                                                                         0.0000\n",
            " 49    0.2985        0.1153      -0.7415       0.1167     -0.7290                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(-0.71924806, dtype=float32), 'scaled_mse': DeviceArray(0.01388026, dtype=float32), 'scaled_rmse': 0.11781453, 'nll': DeviceArray(-0.71924806, dtype=float32), 'mse': DeviceArray(0.01388026, dtype=float32), 'rmse': 0.11781453}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=1 --weight_decay=10 --dir=runs/sgd/cmd/1/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.3179        0.2813       0.7568       0.2808      0.7566                                     0.0000\n",
            "  1    0.3031                                                                                         0.0000\n",
            "  2    0.2989                                                                                         0.0000\n",
            "  3    0.2990                                                                                         0.0000\n",
            "  4    0.2988                                                                                         0.0000\n",
            "  5    0.2989        0.0808      -1.0904       0.0828     -1.0684                                     0.0000\n",
            "  6    0.3005                                                                                         0.0000\n",
            "  7    0.2991                                                                                         0.0000\n",
            "  8    0.2997                                                                                         0.0000\n",
            "  9    0.2989                                                                                         0.0000\n",
            " 10    0.2990        0.0524      -1.5995       0.0545     -1.5644                                     0.0000\n",
            " 11    0.2987                                                                                         0.0000\n",
            " 12    0.2987                                                                                         0.0000\n",
            " 13    0.2986                                                                                         0.0000\n",
            " 14    0.2991                                                                                         0.0000\n",
            " 15    0.2995        0.0549      -1.5861       0.0604     -1.4770                                     0.0000\n",
            " 16    0.3013                                                                                         0.0000\n",
            " 17    0.3000                                                                                         0.0000\n",
            " 18    0.3000                                                                                         0.0000\n",
            " 19    0.2990                                                                                         0.0000\n",
            " 20    0.2992        0.0473      -1.7565       0.0560     -1.5543                                     0.0000\n",
            " 21    0.3004                                                                                         0.0000\n",
            " 22    0.2992                                                                                         0.0000\n",
            " 23    0.2994                                                                                         0.0000\n",
            " 24    0.2989                                                                                         0.0000\n",
            " 25    0.2996        0.0406      -1.8917       0.0571     -1.4991                                     0.0000\n",
            " 26    0.3003                                                                                         0.0000\n",
            " 27    0.2999                                                                                         0.0000\n",
            " 28    0.2996                                                                                         0.0000\n",
            " 29    0.3030                                                                                         0.0000\n",
            " 30    0.2994        0.0336      -2.0938       0.0578     -1.2941                                     0.0000\n",
            " 31    0.2996                                                                                         0.0000\n",
            " 32    0.2993                                                                                         0.0000\n",
            " 33    0.2994                                                                                         0.0000\n",
            " 34    0.2991                                                                                         0.0000\n",
            " 35    0.2986        0.0279      -2.2840       0.0598     -0.7925                                     0.0000\n",
            " 36    0.3011                                                                                         0.0000\n",
            " 37    0.2994                                                                                         0.0000\n",
            " 38    0.2991                                                                                         0.0000\n",
            " 39    0.2996                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2993        0.0222      -2.5821       0.0618      1.2343                                     0.0000\n",
            " 41    0.3000                                                                                         0.0000\n",
            " 42    0.2994                                                                                         0.0000\n",
            " 43    0.3006                                                                                         0.0000\n",
            " 44    0.3004                                                                                         0.0000\n",
            " 45    0.3004        0.0181      -2.8689       0.0629      5.6379                                     0.0000\n",
            " 46    0.5221                                                                                         0.0000\n",
            " 47    0.2993                                                                                         0.0000\n",
            " 48    0.3022                                                                                         0.0000\n",
            " 49    0.3004        0.0170      -2.9942       0.0629      7.3635                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(6.495254, dtype=float32), 'scaled_mse': DeviceArray(0.00356955, dtype=float32), 'scaled_rmse': 0.059745703, 'nll': DeviceArray(6.495254, dtype=float32), 'mse': DeviceArray(0.00356955, dtype=float32), 'rmse': 0.059745703}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=2 --weight_decay=10 --dir=runs/sgd/cmd/2/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.2618        0.1233       0.4248       0.1242      0.4251                                     0.0000\n",
            "  1    0.3013                                                                                         0.0000\n",
            "  2    0.2991                                                                                         0.0000\n",
            "  3    0.2988                                                                                         0.0000\n",
            "  4    0.2986                                                                                         0.0000\n",
            "  5    0.2988        0.0901      -0.9856       0.0907     -0.9776                                     0.0000\n",
            "  6    0.2995                                                                                         0.0000\n",
            "  7    0.2992                                                                                         0.0000\n",
            "  8    0.2994                                                                                         0.0000\n",
            "  9    0.2987                                                                                         0.0000\n",
            " 10    0.2988        0.0983      -0.7961       0.1012     -0.7789                                     0.0000\n",
            " 11    0.2995                                                                                         0.0000\n",
            " 12    0.2984                                                                                         0.0000\n",
            " 13    0.2982                                                                                         0.0000\n",
            " 14    0.2990                                                                                         0.0000\n",
            " 15    0.2980        0.1152      -0.7158       0.1166     -0.7064                                     0.0000\n",
            " 16    0.2989                                                                                         0.0000\n",
            " 17    0.2990                                                                                         0.0000\n",
            " 18    0.2995                                                                                         0.0000\n",
            " 19    0.2989                                                                                         0.0000\n",
            " 20    0.2989        0.1145      -0.7482       0.1159     -0.7349                                     0.0000\n",
            " 21    0.3001                                                                                         0.0000\n",
            " 22    0.2992                                                                                         0.0000\n",
            " 23    0.2994                                                                                         0.0000\n",
            " 24    0.2989                                                                                         0.0000\n",
            " 25    0.2995        0.1145      -0.7490       0.1163     -0.7330                                     0.0000\n",
            " 26    0.2994                                                                                         0.0000\n",
            " 27    0.2989                                                                                         0.0000\n",
            " 28    0.2986                                                                                         0.0000\n",
            " 29    0.2987                                                                                         0.0000\n",
            " 30    0.2989        0.1152      -0.7421       0.1168     -0.7287                                     0.0000\n",
            " 31    0.2992                                                                                         0.0000\n",
            " 32    0.2988                                                                                         0.0000\n",
            " 33    0.2990                                                                                         0.0000\n",
            " 34    0.2990                                                                                         0.0000\n",
            " 35    0.2990        0.1077      -0.8141       0.1106     -0.7860                                     0.0000\n",
            " 36    0.2989                                                                                         0.0000\n",
            " 37    0.2990                                                                                         0.0000\n",
            " 38    0.2983                                                                                         0.0000\n",
            " 39    0.2994                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.3000        0.0990      -0.8939       0.1024     -0.8541                                     0.0000\n",
            " 41    0.2991                                                                                         0.0000\n",
            " 42    0.2998                                                                                         0.0000\n",
            " 43    0.2998                                                                                         0.0000\n",
            " 44    0.2994                                                                                         0.0000\n",
            " 45    0.2994        0.0980      -0.9033       0.1011     -0.8668                                     0.0000\n",
            " 46    0.4146                                                                                         0.0000\n",
            " 47    0.2992                                                                                         0.0000\n",
            " 48    0.2987                                                                                         0.0000\n",
            " 49    0.2990        0.0976      -0.9067       0.1009     -0.8672                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(-0.9324332, dtype=float32), 'scaled_mse': DeviceArray(0.00897946, dtype=float32), 'scaled_rmse': 0.094760016, 'nll': DeviceArray(-0.9324332, dtype=float32), 'mse': DeviceArray(0.00897946, dtype=float32), 'rmse': 0.094760016}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=3 --weight_decay=10 --dir=runs/sgd/cmd/3/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.3116        0.1157      -0.1004       0.1172     -0.0989                                     0.0000\n",
            "  1    0.2995                                                                                         0.0000\n",
            "  2    0.2981                                                                                         0.0000\n",
            "  3    0.2985                                                                                         0.0000\n",
            "  4    0.2994                                                                                         0.0000\n",
            "  5    0.2985        0.1127      -0.6630       0.1143     -0.6556                                     0.0000\n",
            "  6    0.2990                                                                                         0.0000\n",
            "  7    0.2988                                                                                         0.0000\n",
            "  8    0.2983                                                                                         0.0000\n",
            "  9    0.2995                                                                                         0.0000\n",
            " 10    0.2998        0.0580      -1.4429       0.0626     -1.3555                                     0.0000\n",
            " 11    0.2992                                                                                         0.0000\n",
            " 12    0.3000                                                                                         0.0000\n",
            " 13    0.3037                                                                                         0.0000\n",
            " 14    0.3003                                                                                         0.0000\n",
            " 15    0.2987        0.0613      -1.3721       0.0654     -1.2827                                     0.0000\n",
            " 16    0.2987                                                                                         0.0000\n",
            " 17    0.2987                                                                                         0.0000\n",
            " 18    0.2985                                                                                         0.0000\n",
            " 19    0.2983                                                                                         0.0000\n",
            " 20    0.2984        0.0546      -1.5798       0.0588     -1.5064                                     0.0000\n",
            " 21    0.2980                                                                                         0.0000\n",
            " 22    0.2978                                                                                         0.0000\n",
            " 23    0.2985                                                                                         0.0000\n",
            " 24    0.2986                                                                                         0.0000\n",
            " 25    0.2987        0.0482      -1.7084       0.0582     -1.4674                                     0.0000\n",
            " 26    0.2988                                                                                         0.0000\n",
            " 27    0.2983                                                                                         0.0000\n",
            " 28    0.2983                                                                                         0.0000\n",
            " 29    0.2984                                                                                         0.0000\n",
            " 30    0.2985        0.0446      -1.7758       0.0575     -1.4141                                     0.0000\n",
            " 31    0.2982                                                                                         0.0000\n",
            " 32    0.2984                                                                                         0.0000\n",
            " 33    0.2986                                                                                         0.0000\n",
            " 34    0.2985                                                                                         0.0000\n",
            " 35    0.2983        0.0355      -2.0665       0.0547     -1.4216                                     0.0000\n",
            " 36    0.2990                                                                                         0.0000\n",
            " 37    0.2984                                                                                         0.0000\n",
            " 38    0.2982                                                                                         0.0000\n",
            " 39    0.2988                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2999        0.0307      -2.2364       0.0565     -1.0464                                     0.0000\n",
            " 41    0.2986                                                                                         0.0000\n",
            " 42    0.2982                                                                                         0.0000\n",
            " 43    0.2985                                                                                         0.0000\n",
            " 44    0.2983                                                                                         0.0000\n",
            " 45    0.2984        0.0282      -2.3768       0.0573     -0.3743                                     0.0000\n",
            " 46    0.4093                                                                                         0.0000\n",
            " 47    0.2987                                                                                         0.0000\n",
            " 48    0.2985                                                                                         0.0000\n",
            " 49    0.2984        0.0277      -2.4028       0.0573     -0.1931                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(0.19577473, dtype=float32), 'scaled_mse': DeviceArray(0.00320173, dtype=float32), 'scaled_rmse': 0.056583866, 'nll': DeviceArray(0.19577473, dtype=float32), 'mse': DeviceArray(0.00320173, dtype=float32), 'rmse': 0.056583866}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=4 --weight_decay=10 --dir=runs/sgd/cmd/4/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.3860        0.1159       0.0145       0.1186      0.0166                                     0.0000\n",
            "  1    0.2995                                                                                         0.0000\n",
            "  2    0.2974                                                                                         0.0000\n",
            "  3    0.2975                                                                                         0.0000\n",
            "  4    0.2973                                                                                         0.0000\n",
            "  5    0.2982        2.0783       2.2354       2.0772      2.2351                                     0.0000\n",
            "  6    0.2989                                                                                         0.0000\n",
            "  7    0.2985                                                                                         0.0000\n",
            "  8    0.2987                                                                                         0.0000\n",
            "  9    0.2981                                                                                         0.0000\n",
            " 10    0.2984        0.1153       0.1319       0.1167      0.1327                                     0.0000\n",
            " 11    0.2988                                                                                         0.0000\n",
            " 12    0.2987                                                                                         0.0000\n",
            " 13    0.2986                                                                                         0.0000\n",
            " 14    0.2982                                                                                         0.0000\n",
            " 15    0.2983        0.1154      -0.7408       0.1167     -0.7287                                     0.0000\n",
            " 16    0.2999                                                                                         0.0000\n",
            " 17    0.2981                                                                                         0.0000\n",
            " 18    0.2991                                                                                         0.0000\n",
            " 19    0.2993                                                                                         0.0000\n",
            " 20    0.2984        0.1154      -0.7408       0.1168     -0.7287                                     0.0000\n",
            " 21    0.2986                                                                                         0.0000\n",
            " 22    0.2985                                                                                         0.0000\n",
            " 23    0.2985                                                                                         0.0000\n",
            " 24    0.2983                                                                                         0.0000\n",
            " 25    0.2979        0.1153      -0.7413       0.1168     -0.7285                                     0.0000\n",
            " 26    0.2992                                                                                         0.0000\n",
            " 27    0.2980                                                                                         0.0000\n",
            " 28    0.2981                                                                                         0.0000\n",
            " 29    0.2989                                                                                         0.0000\n",
            " 30    0.2995        0.1153      -0.7415       0.1167     -0.7290                                     0.0000\n",
            " 31    0.2992                                                                                         0.0000\n",
            " 32    0.2981                                                                                         0.0000\n",
            " 33    0.2991                                                                                         0.0000\n",
            " 34    0.2982                                                                                         0.0000\n",
            " 35    0.2981        0.1153      -0.7414       0.1167     -0.7290                                     0.0000\n",
            " 36    0.2981                                                                                         0.0000\n",
            " 37    0.2992                                                                                         0.0000\n",
            " 38    0.2986                                                                                         0.0000\n",
            " 39    0.2994                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2990        0.1153      -0.7412       0.1167     -0.7289                                     0.0000\n",
            " 41    0.3002                                                                                         0.0000\n",
            " 42    0.2999                                                                                         0.0000\n",
            " 43    0.2990                                                                                         0.0000\n",
            " 44    0.2988                                                                                         0.0000\n",
            " 45    0.2989        0.1153      -0.7415       0.1167     -0.7290                                     0.0000\n",
            " 46    0.4179                                                                                         0.0000\n",
            " 47    0.2975                                                                                         0.0000\n",
            " 48    0.2984                                                                                         0.0000\n",
            " 49    0.2977        0.1153      -0.7416       0.1167     -0.7290                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(-0.719226, dtype=float32), 'scaled_mse': DeviceArray(0.01388106, dtype=float32), 'scaled_rmse': 0.11781792, 'nll': DeviceArray(-0.719226, dtype=float32), 'mse': DeviceArray(0.01388106, dtype=float32), 'rmse': 0.11781792}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=5 --weight_decay=10 --dir=runs/sgd/cmd/5/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  ------------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll     test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  ------------  ----------  ---------------  --------------  --------\n",
            "  0    5.5756  6240480.0000      18.3919  6268780.0000     18.3998                                     0.0000\n",
            "  1    0.3009                                                                                         0.0000\n",
            "  2    0.2990                                                                                         0.0000\n",
            "  3    0.2996                                                                                         0.0000\n",
            "  4    0.2995                                                                                         0.0000\n",
            "  5    0.2999           nan          nan          nan         nan                                     0.0000\n",
            "  6    0.3001                                                                                         0.0000\n",
            "  7    0.3003                                                                                         0.0000\n",
            "  8    0.3000                                                                                         0.0000\n",
            "  9    0.3000                                                                                         0.0000\n",
            " 10    0.2998           nan          nan          nan         nan                                     0.0000\n",
            " 11    0.3005                                                                                         0.0000\n",
            " 12    0.3006                                                                                         0.0000\n",
            " 13    0.3005                                                                                         0.0000\n",
            " 14    0.2994                                                                                         0.0000\n",
            " 15    0.2995           nan          nan          nan         nan                                     0.0000\n",
            " 16    0.3001                                                                                         0.0000\n",
            " 17    0.3000                                                                                         0.0000\n",
            " 18    0.3004                                                                                         0.0000\n",
            " 19    0.3003                                                                                         0.0000\n",
            " 20    0.3005           nan          nan          nan         nan                                     0.0000\n",
            " 21    0.3001                                                                                         0.0000\n",
            " 22    0.2996                                                                                         0.0000\n",
            " 23    0.2999                                                                                         0.0000\n",
            " 24    0.2998                                                                                         0.0000\n",
            " 25    0.2999           nan          nan          nan         nan                                     0.0000\n",
            " 26    0.3006                                                                                         0.0000\n",
            " 27    0.2997                                                                                         0.0000\n",
            " 28    0.2997                                                                                         0.0000\n",
            " 29    0.2995                                                                                         0.0000\n",
            " 30    0.2999           nan          nan          nan         nan                                     0.0000\n",
            " 31    0.3004                                                                                         0.0000\n",
            " 32    0.3001                                                                                         0.0000\n",
            " 33    0.3007                                                                                         0.0000\n",
            " 34    0.3000                                                                                         0.0000\n",
            " 35    0.3004           nan          nan          nan         nan                                     0.0000\n",
            " 36    0.3009                                                                                         0.0000\n",
            " 37    0.2997                                                                                         0.0000\n",
            " 38    0.3002                                                                                         0.0000\n",
            " 39    0.3002                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.3001           nan          nan          nan         nan                                     0.0000\n",
            " 41    0.3004                                                                                         0.0000\n",
            " 42    0.2998                                                                                         0.0000\n",
            " 43    0.3001                                                                                         0.0000\n",
            " 44    0.2999                                                                                         0.0000\n",
            " 45    0.2999           nan          nan          nan         nan                                     0.0000\n",
            " 46    0.4167                                                                                         0.0000\n",
            " 47    0.2997                                                                                         0.0000\n",
            " 48    0.2999                                                                                         0.0000\n",
            " 49    0.3012           nan          nan          nan         nan                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(nan, dtype=float32), 'scaled_mse': DeviceArray(nan, dtype=float32), 'scaled_rmse': nan, 'nll': DeviceArray(nan, dtype=float32), 'mse': DeviceArray(nan, dtype=float32), 'rmse': nan}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=6 --weight_decay=10 --dir=runs/sgd/cmd/6/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.3036        0.1159      -0.1005       0.1174     -0.0989                                     0.0000\n",
            "  1    0.2994                                                                                         0.0000\n",
            "  2    0.2991                                                                                         0.0000\n",
            "  3    0.2980                                                                                         0.0000\n",
            "  4    0.2976                                                                                         0.0000\n",
            "  5    0.2978        0.0643      -1.3046       0.0668     -1.2740                                     0.0000\n",
            "  6    0.2985                                                                                         0.0000\n",
            "  7    0.2986                                                                                         0.0000\n",
            "  8    0.2984                                                                                         0.0000\n",
            "  9    0.2985                                                                                         0.0000\n",
            " 10    0.2987        0.0615      -1.4664       0.0656     -1.3982                                     0.0000\n",
            " 11    0.2997                                                                                         0.0000\n",
            " 12    0.2983                                                                                         0.0000\n",
            " 13    0.2980                                                                                         0.0000\n",
            " 14    0.2986                                                                                         0.0000\n",
            " 15    0.2983        0.0574      -1.5293       0.0644     -1.3641                                     0.0000\n",
            " 16    0.2986                                                                                         0.0000\n",
            " 17    0.2990                                                                                         0.0000\n",
            " 18    0.2984                                                                                         0.0000\n",
            " 19    0.2981                                                                                         0.0000\n",
            " 20    0.2981        0.0396      -1.8900       0.0571     -1.4791                                     0.0000\n",
            " 21    0.2986                                                                                         0.0000\n",
            " 22    0.2984                                                                                         0.0000\n",
            " 23    0.2987                                                                                         0.0000\n",
            " 24    0.2989                                                                                         0.0000\n",
            " 25    0.2990        0.0386      -1.9220       0.0654     -1.0749                                     0.0000\n",
            " 26    0.2996                                                                                         0.0000\n",
            " 27    0.2983                                                                                         0.0000\n",
            " 28    0.2983                                                                                         0.0000\n",
            " 29    0.2990                                                                                         0.0000\n",
            " 30    0.2992        0.0270      -2.2801       0.0637     -0.5561                                     0.0000\n",
            " 31    0.2996                                                                                         0.0000\n",
            " 32    0.2983                                                                                         0.0000\n",
            " 33    0.2985                                                                                         0.0000\n",
            " 34    0.2983                                                                                         0.0000\n",
            " 35    0.2988        0.0172      -2.7088       0.0614      1.6327                                     0.0000\n",
            " 36    0.3010                                                                                         0.0000\n",
            " 37    0.3001                                                                                         0.0000\n",
            " 38    0.2984                                                                                         0.0000\n",
            " 39    0.2991                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2983        0.0108      -3.1168       0.0618      6.0770                                     0.0000\n",
            " 41    0.3004                                                                                         0.0000\n",
            " 42    0.2995                                                                                         0.0000\n",
            " 43    0.2991                                                                                         0.0000\n",
            " 44    0.2988                                                                                         0.0000\n",
            " 45    0.2992        0.0063      -3.6209       0.0619     23.1506                                     0.0000\n",
            " 46    0.4124                                                                                         0.0000\n",
            " 47    0.2991                                                                                         0.0000\n",
            " 48    0.2984                                                                                         0.0000\n",
            " 49    0.2984        0.0039      -3.9957       0.0621     41.3346                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(45.29645, dtype=float32), 'scaled_mse': DeviceArray(0.00381126, dtype=float32), 'scaled_rmse': 0.061735436, 'nll': DeviceArray(45.29645, dtype=float32), 'mse': DeviceArray(0.00381126, dtype=float32), 'rmse': 0.061735436}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=7 --weight_decay=10 --dir=runs/sgd/cmd/7/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.3667        0.1186       0.0406       0.1203      0.0406                                     0.0000\n",
            "  1    0.3004                                                                                         0.0000\n",
            "  2    0.2997                                                                                         0.0000\n",
            "  3    0.2990                                                                                         0.0000\n",
            "  4    0.2994                                                                                         0.0000\n",
            "  5    0.2997        0.0981      -0.8397       0.0992     -0.8218                                     0.0000\n",
            "  6    0.3000                                                                                         0.0000\n",
            "  7    0.2998                                                                                         0.0000\n",
            "  8    0.2999                                                                                         0.0000\n",
            "  9    0.2976                                                                                         0.0000\n",
            " 10    0.2980        0.0707      -1.2410       0.0725     -1.2256                                     0.0000\n",
            " 11    0.2980                                                                                         0.0000\n",
            " 12    0.2978                                                                                         0.0000\n",
            " 13    0.2981                                                                                         0.0000\n",
            " 14    0.2974                                                                                         0.0000\n",
            " 15    0.2979        0.0540      -1.5523       0.0581     -1.4937                                     0.0000\n",
            " 16    0.2989                                                                                         0.0000\n",
            " 17    0.2982                                                                                         0.0000\n",
            " 18    0.2983                                                                                         0.0000\n",
            " 19    0.2978                                                                                         0.0000\n",
            " 20    0.2982        0.0505      -1.6537       0.0546     -1.5809                                     0.0000\n",
            " 21    0.2980                                                                                         0.0000\n",
            " 22    0.2979                                                                                         0.0000\n",
            " 23    0.2977                                                                                         0.0000\n",
            " 24    0.2979                                                                                         0.0000\n",
            " 25    0.2981        0.0480      -1.7221       0.0546     -1.5968                                     0.0000\n",
            " 26    0.2984                                                                                         0.0000\n",
            " 27    0.2983                                                                                         0.0000\n",
            " 28    0.2981                                                                                         0.0000\n",
            " 29    0.2978                                                                                         0.0000\n",
            " 30    0.2983        0.0445      -1.7839       0.0557     -1.4443                                     0.0000\n",
            " 31    0.2982                                                                                         0.0000\n",
            " 32    0.2979                                                                                         0.0000\n",
            " 33    0.2979                                                                                         0.0000\n",
            " 34    0.2977                                                                                         0.0000\n",
            " 35    0.2982        0.0415      -1.9134       0.0561     -1.4347                                     0.0000\n",
            " 36    0.2986                                                                                         0.0000\n",
            " 37    0.2981                                                                                         0.0000\n",
            " 38    0.2978                                                                                         0.0000\n",
            " 39    0.2978                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2982        0.0379      -2.0257       0.0574     -1.2420                                     0.0000\n",
            " 41    0.2983                                                                                         0.0000\n",
            " 42    0.2980                                                                                         0.0000\n",
            " 43    0.2983                                                                                         0.0000\n",
            " 44    0.2993                                                                                         0.0000\n",
            " 45    0.3003        0.0363      -2.0839       0.0578     -1.0908                                     0.0000\n",
            " 46    0.4129                                                                                         0.0000\n",
            " 47    0.2974                                                                                         0.0000\n",
            " 48    0.2980                                                                                         0.0000\n",
            " 49    0.2975        0.0360      -2.1023       0.0578     -1.0157                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(-0.87560636, dtype=float32), 'scaled_mse': DeviceArray(0.00325422, dtype=float32), 'scaled_rmse': 0.057045788, 'nll': DeviceArray(-0.87560636, dtype=float32), 'mse': DeviceArray(0.00325422, dtype=float32), 'rmse': 0.057045788}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=8 --weight_decay=10 --dir=runs/sgd/cmd/8/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.3094        0.1155      -0.1406       0.1170     -0.1389                                     0.0000\n",
            "  1    0.2996                                                                                         0.0000\n",
            "  2    0.2984                                                                                         0.0000\n",
            "  3    0.2983                                                                                         0.0000\n",
            "  4    0.2982                                                                                         0.0000\n",
            "  5    0.2981        0.1157      -0.7350       0.1170     -0.7246                                     0.0000\n",
            "  6    0.2990                                                                                         0.0000\n",
            "  7    0.2988                                                                                         0.0000\n",
            "  8    0.2989                                                                                         0.0000\n",
            "  9    0.2981                                                                                         0.0000\n",
            " 10    0.2986        0.1154      -0.7398       0.1168     -0.7283                                     0.0000\n",
            " 11    0.2985                                                                                         0.0000\n",
            " 12    0.2981                                                                                         0.0000\n",
            " 13    0.2980                                                                                         0.0000\n",
            " 14    0.2979                                                                                         0.0000\n",
            " 15    0.2981        0.1153      -0.7412       0.1169     -0.7285                                     0.0000\n",
            " 16    0.2986                                                                                         0.0000\n",
            " 17    0.2998                                                                                         0.0000\n",
            " 18    0.2995                                                                                         0.0000\n",
            " 19    0.2986                                                                                         0.0000\n",
            " 20    0.2979        0.1043      -0.8398       0.1072     -0.8091                                     0.0000\n",
            " 21    0.2996                                                                                         0.0000\n",
            " 22    0.2984                                                                                         0.0000\n",
            " 23    0.2991                                                                                         0.0000\n",
            " 24    0.3042                                                                                         0.0000\n",
            " 25    0.3005        0.0615      -1.3760       0.0657     -1.3068                                     0.0000\n",
            " 26    0.3002                                                                                         0.0000\n",
            " 27    0.2996                                                                                         0.0000\n",
            " 28    0.2996                                                                                         0.0000\n",
            " 29    0.2989                                                                                         0.0000\n",
            " 30    0.2994        0.0514      -1.5994       0.0547     -1.5264                                     0.0000\n",
            " 31    0.2991                                                                                         0.0000\n",
            " 32    0.2988                                                                                         0.0000\n",
            " 33    0.2982                                                                                         0.0000\n",
            " 34    0.2988                                                                                         0.0000\n",
            " 35    0.3001        0.0531      -1.5628       0.0577     -1.4866                                     0.0000\n",
            " 36    0.2986                                                                                         0.0000\n",
            " 37    0.2981                                                                                         0.0000\n",
            " 38    0.2981                                                                                         0.0000\n",
            " 39    0.2981                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2984        0.0479      -1.7033       0.0520     -1.6051                                     0.0000\n",
            " 41    0.2990                                                                                         0.0000\n",
            " 42    0.2982                                                                                         0.0000\n",
            " 43    0.2978                                                                                         0.0000\n",
            " 44    0.2983                                                                                         0.0000\n",
            " 45    0.2987        0.0472      -1.7241       0.0512     -1.6255                                     0.0000\n",
            " 46    0.4201                                                                                         0.0000\n",
            " 47    0.2988                                                                                         0.0000\n",
            " 48    0.2990                                                                                         0.0000\n",
            " 49    0.2987        0.0470      -1.7287       0.0512     -1.6226                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(-1.6482798, dtype=float32), 'scaled_mse': DeviceArray(0.00249889, dtype=float32), 'scaled_rmse': 0.04998894, 'nll': DeviceArray(-1.6482798, dtype=float32), 'mse': DeviceArray(0.00249889, dtype=float32), 'rmse': 0.04998894}\n",
            "\n",
            "python3 bnn_hmc/scripts/run_sgd.py --seed=9 --weight_decay=10 --dir=runs/sgd/cmd/9/ --dataset_name=cmd --model_name=lenet --scaling=asinh --init_step_size=1e-7 --num_epochs=50 --save_freq=5 --builder_kwargs={\"simulation\": \"IllustrisTNG\", \"field\": \"Mtot\", \"parameters\": [\"omegam\"]} --image_size=64 --eval_freq=5 --batch_size=100 --optimizer=SGD --train_split=train[:90%] --test_split=train[90%:95%]\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Starting from random initialization with provided seed\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  0    4.2411        0.1699       0.7135       0.1718      0.7141                                     0.0000\n",
            "  1    0.3205                                                                                         0.0000\n",
            "  2    0.2996                                                                                         0.0000\n",
            "  3    0.2977                                                                                         0.0000\n",
            "  4    0.2978                                                                                         0.0000\n",
            "  5    0.2978        0.1212      -0.6912       0.1223     -0.6825                                     0.0000\n",
            "  6    0.2984                                                                                         0.0000\n",
            "  7    0.2983                                                                                         0.0000\n",
            "  8    0.2985                                                                                         0.0000\n",
            "  9    0.2984                                                                                         0.0000\n",
            " 10    0.2981        0.1154      -0.7406       0.1167     -0.7287                                     0.0000\n",
            " 11    0.2978                                                                                         0.0000\n",
            " 12    0.2974                                                                                         0.0000\n",
            " 13    0.2977                                                                                         0.0000\n",
            " 14    0.2981                                                                                         0.0000\n",
            " 15    0.2977        0.1159      -0.7355       0.1174     -0.7221                                     0.0000\n",
            " 16    0.2990                                                                                         0.0000\n",
            " 17    0.2979                                                                                         0.0000\n",
            " 18    0.2981                                                                                         0.0000\n",
            " 19    0.2977                                                                                         0.0000\n",
            " 20    0.2980        0.1153      -0.7417       0.1169     -0.7274                                     0.0000\n",
            " 21    0.2982                                                                                         0.0000\n",
            " 22    0.2985                                                                                         0.0000\n",
            " 23    0.2979                                                                                         0.0000\n",
            " 24    0.2978                                                                                         0.0000\n",
            " 25    0.2984        0.1152      -0.7416       0.1168     -0.7286                                     0.0000\n",
            " 26    0.2982                                                                                         0.0000\n",
            " 27    0.2981                                                                                         0.0000\n",
            " 28    0.2981                                                                                         0.0000\n",
            " 29    0.2982                                                                                         0.0000\n",
            " 30    0.2985        0.1152      -0.7418       0.1168     -0.7278                                     0.0000\n",
            " 31    0.2975                                                                                         0.0000\n",
            " 32    0.2981                                                                                         0.0000\n",
            " 33    0.2980                                                                                         0.0000\n",
            " 34    0.2983                                                                                         0.0000\n",
            " 35    0.2977        0.1156      -0.7383       0.1174     -0.7232                                     0.0000\n",
            " 36    0.2996                                                                                         0.0000\n",
            " 37    0.2982                                                                                         0.0000\n",
            " 38    0.2980                                                                                         0.0000\n",
            " 39    0.2980                                                                                         0.0000\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            "  i         t    train/rmse    train/nll    test/rmse    test/nll  test/ens_rmse    test/ens_nll          lr\n",
            "---  --------  ------------  -----------  -----------  ----------  ---------------  --------------  --------\n",
            " 40    0.2985        0.1013      -0.8693       0.1031     -0.8528                                     0.0000\n",
            " 41    0.2990                                                                                         0.0000\n",
            " 42    0.2988                                                                                         0.0000\n",
            " 43    0.2985                                                                                         0.0000\n",
            " 44    0.2982                                                                                         0.0000\n",
            " 45    0.2984        0.0948      -0.9350       0.0984     -0.8963                                     0.0000\n",
            " 46    0.4173                                                                                         0.0000\n",
            " 47    0.2971                                                                                         0.0000\n",
            " 48    0.2979                                                                                         0.0000\n",
            " 49    0.2971        0.0937      -0.9478       0.0973     -0.9065                                     0.0000\n",
            "\n",
            "JAX sees the following devices: [GpuDevice(id=0, process_index=0)]\n",
            "TF sees the following devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Continuing the run from the last saved checkpoint\n",
            "{'scaled_nll': DeviceArray(-0.97987866, dtype=float32), 'scaled_mse': DeviceArray(0.00817437, dtype=float32), 'scaled_rmse': 0.09041223, 'nll': DeviceArray(-0.97987866, dtype=float32), 'mse': DeviceArray(0.00817437, dtype=float32), 'rmse': 0.09041223}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "errors = []\n",
        "for i, root in enumerate(glob.glob('/content/runs/sgd/cmd/*/*/')):\n",
        "  metrics = np.load(root + '/metrics.npy', allow_pickle=True)\n",
        "  if not np.isfinite(metrics.item()['scaled_mse']) or metrics.item()['scaled_mse'] > 1:\n",
        "    # Do not include any runs which have diverged\n",
        "    continue\n",
        "  data = np.load(root + '/test_set.npy')  \n",
        "  prediction = np.load(root + '/predictions.npy')\n",
        "  predictions.append(prediction[0,:,0])\n",
        "  errors.append(prediction[0,:,1])\n",
        "  print(metrics)\n",
        "predictions = np.array(predictions)\n",
        "errors = np.array(errors)"
      ],
      "metadata": {
        "id": "BJhFIgDsK12Q",
        "outputId": "b485a5b7-ba51-4ef5-c7df-385d8210cc9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'scaled_nll': array(6.495254, dtype=float32), 'scaled_mse': array(0.00356955, dtype=float32), 'scaled_rmse': 0.059745703, 'nll': array(6.495254, dtype=float32), 'mse': array(0.00356955, dtype=float32), 'rmse': 0.059745703}\n",
            "{'scaled_nll': array(-0.87560636, dtype=float32), 'scaled_mse': array(0.00325422, dtype=float32), 'scaled_rmse': 0.057045788, 'nll': array(-0.87560636, dtype=float32), 'mse': array(0.00325422, dtype=float32), 'rmse': 0.057045788}\n",
            "{'scaled_nll': array(-0.97987866, dtype=float32), 'scaled_mse': array(0.00817437, dtype=float32), 'scaled_rmse': 0.09041223, 'nll': array(-0.97987866, dtype=float32), 'mse': array(0.00817437, dtype=float32), 'rmse': 0.09041223}\n",
            "{'scaled_nll': array(-0.71924806, dtype=float32), 'scaled_mse': array(0.01388026, dtype=float32), 'scaled_rmse': 0.11781453, 'nll': array(-0.71924806, dtype=float32), 'mse': array(0.01388026, dtype=float32), 'rmse': 0.11781453}\n",
            "{'scaled_nll': array(-0.719226, dtype=float32), 'scaled_mse': array(0.01388106, dtype=float32), 'scaled_rmse': 0.11781792, 'nll': array(-0.719226, dtype=float32), 'mse': array(0.01388106, dtype=float32), 'rmse': 0.11781792}\n",
            "{'scaled_nll': array(45.29645, dtype=float32), 'scaled_mse': array(0.00381126, dtype=float32), 'scaled_rmse': 0.061735436, 'nll': array(45.29645, dtype=float32), 'mse': array(0.00381126, dtype=float32), 'rmse': 0.061735436}\n",
            "{'scaled_nll': array(0.19577473, dtype=float32), 'scaled_mse': array(0.00320173, dtype=float32), 'scaled_rmse': 0.056583866, 'nll': array(0.19577473, dtype=float32), 'mse': array(0.00320173, dtype=float32), 'rmse': 0.056583866}\n",
            "{'scaled_nll': array(-0.9324332, dtype=float32), 'scaled_mse': array(0.00897946, dtype=float32), 'scaled_rmse': 0.094760016, 'nll': array(-0.9324332, dtype=float32), 'mse': array(0.00897946, dtype=float32), 'rmse': 0.094760016}\n",
            "{'scaled_nll': array(-1.6482798, dtype=float32), 'scaled_mse': array(0.00249889, dtype=float32), 'scaled_rmse': 0.04998894, 'nll': array(-1.6482798, dtype=float32), 'mse': array(0.00249889, dtype=float32), 'rmse': 0.04998894}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_predictions = np.mean(predictions, axis=0)\n",
        "mean_errors = np.mean(errors, axis=0)\n",
        "total_errors = (mean_errors**2 + np.std(predictions, axis=0)**2)**0.5\n",
        "diffs = mean_predictions - data[0,:,0]"
      ],
      "metadata": {
        "id": "LAiyrSrYtVMI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ensemble MSE', np.mean(diffs**2))\n",
        "print('Ensemble MAE', np.mean(np.abs(diffs)))"
      ],
      "metadata": {
        "id": "IOPjx2QEAiuh",
        "outputId": "fb1a9e5f-eb02-46e5-e554-88ebdf6a0d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble MSE 0.0039499886\n",
            "Ensemble MAE 0.05311388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.errorbar(data[0,::10,0], mean_predictions[::10], total_errors[::10],  ls='none')\n",
        "plt.errorbar(data[0,::10,0], mean_predictions[::10], mean_errors[::10],  ls='none')\n",
        "plt.plot(np.linspace(0,0.5,10), np.linspace(0,0.5,10), linestyle='--', color='black', alpha=0.5)\n",
        "plt.xlabel('Ground truth', fontsize=14)\n",
        "plt.ylabel('Prediction', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h3txA6F5tKAF",
        "outputId": "cd6b0010-c585-403c-82b2-12b0a4940a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAHkCAYAAAB/i1jHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXRUZYL//8+ThOyEhBBIDEtYIhgQFQioKK5sOgRkERFpUXvAmbG759u/7vOd+c4cp8c5p3/dY5+e079f29NBx2n9TbeSBFlaFkXAbkVA2YTGAKKGzYDsJGStquf3R4IGDJCl6t5bVe/XOR6rboqqD1wgH5773Ocx1loBAADAXTFuBwAAAAClDAAAwBMoZQAAAB5AKQMAAPAAShkAAIAHUMoAAAA8IM7tAJ3Vo0cPm5eX53YMAACAa9q2bdtJa21Wa18L+1KWl5enrVu3uh0DAADgmowxB6/0NS5fAgAAeAClDAAAwAMoZQAAAB5AKQMAAPAAShkAAIAHUMoAAAA8gFIGAADgAZQyAAAAD6CUAQAAeAClDAAAwAMoZQAAAB5AKQMAAPAAShkAAIAHUMoAAAA8gFIGAADgAZQyAAAAD6CUAQAAeAClDAAAwAMoZQAAoM1mF2/S7OJNbseISJQyAAAAD6CUAQAAeAClDAAAwAMoZQAAAB5AKQMAAPAAShkAAIAHOFrKjDGTjDH7jDEHjDH/0MrX5xtjThhjdjb/910n8wEAALglzqkPMsbESnpB0nhJRyR9ZIxZYa395LKXLrbWPuNULgAAAC9wcqRstKQD1trPrbUNkl6XNNXBzwcAAPAsJ0tZrqTDLZ4faT52uRnGmF3GmDJjTB9nogEAgGh28uRJtyN4bqL/HyXlWWuHS1or6ZXWXmSMWWCM2WqM2XrixAlHAwIAgMjj9/vl8/lczeBkKTsqqeXIV+/mY1+z1p6y1tY3P31J0sjW3shau8haO8paOyorKyskYQEAQOQKBAJ69913tW7dOklSr169FBfn2FT7VjlZyj6SlG+M6W+MiZf0iKQVLV9gjMlp8bRIUrmD+QAAQBSorq7W//zP/+jdd99VVVWVrLVuR5Lk4N2X1lqfMeYZSW9JipX0srV2jzHmOUlbrbUrJH3fGFMkySfptKT5TuUDAACRr6KiQmVlZaqrq9PUqVN18803yxjjdixJDpYySbLWrpK06rJjz7Z4/I+S/tHJTAAAIDrU1NTo97//vdLS0jRv3jz16tXL7UiXcPfiKQAAQIg1NDQoPj5eycnJmjNnjnJzc5WQkOB2rG/x2t2XAAAAQXP48GG98MIL+stf/iJJGjBggCcLmcRIGQAAiEDWWm3evFlr165Vt27d1L17d7cjXROlDAAARJS6ujotW7ZMe/fu1Q033KCpU6cqMTHR7VjXRCkDACCEZhdvkiQtXnibp94rkn3++efav3+/Jk2apDFjxnjm7sprYU4ZAAAIe9ZaXdzlp6CgQDtSx+g/PrZhU8gkShkAAAhz9fX1WrJkiYqLi7/ewzI+Jc3lVO3H5UsAABC2jh8/rpKSEp0+fVr33XefMjMz3Y7UYZQyAICjmBeFYNm+fbtWrVqlpKQkzZ8/X/369XM7UqdQygAAQFg6ffq0+vbtqxkzZiglJcXtOJ1GKQMAAGHjxIkTqq+vV+/evXXvvfdKkmJiImOKfGT8LAAAuMzs4k1fXypFZNi1a5cWLVqklStXylqrmJiYiClkEiNlAACgHZ499ePmR+879pmNjY1avXq1tm/frn79+mnmzJlhtdRFW1HKAACAK9py08eFCxf06quv6vjx47rzzjt1zz33RNToWEuUMgAAPIS7Uy+VnJysXr166f7771d+fr7bcUIqMqsmAAAIWz6fT2vXrtW5c+dkjNH06dMjvpBJjJQBAAAPOXPmjEpLS/Xll18qPT1dhYWFbkdyDKUMAAB4wr59+7R06VJJ0iOPPKIhQ4a4nMhZlDIAAOC63bt3a8mSJbruuus0a9YsZWRkuB3JcZQyAADguuuvv15333237rjjDsXFRWc9YaI/AABwRdVXR1SxebUaGxuVkJCgu+++u1OFLNwXDKaUAQAARwUCAa1fv14Ht6yRr75WNTU1bkfyhOgcHwQAAK6oqqrSkiVLVFFRoYy+g5Uz7DZ169bN7VieQCkDAACOWbZsmY4ePaqHHnpI5ZsZIWuJUgYAQJhwY9/JYAgEAvL7/erSpYseeOAB+f1+9ezZU9ocvvO/QoFSBgAAQubChQt64403lJiYqJkzZyozM9PtSJ5FKQMAIEK5vY/mwYMHVVZWptraWj3wwAOuZAgnlDIAiDJuf6NG5LPW6oMPPtC6deuUnp6uuXPnKjs72+1YnkcpAwAAQXXhwgVt3LhRN9xwg4qKipSQkOB2pLBAKQMAAEFx4sQJ9ejRQ6mpqVqwYIG6desmY4zbscIGpQwAAHSKtVZbtmzR2rVrNWHCBI0ZM0bp6elB/Yz2XnYPxztVKWUAAEeF4zdLJ4Xbr09dXZ2WL1+u8vJyDR48WMOHD3c7UtiilAEAEELhVrLao7KyUiUlJTp37pwmTJig2267rV2XKyP516Yj2PsSAAB0SENDg6y1+qjLcP1qtwmb+WNe3bicUgYAANqswRfQgeNN2yP169dP3/ve95TcvZfLqa7OqyXscly+BAAA39LaxPrjx4+r7KPjOlfbqHFnzigjI0OxsbFuRYw4lDIAAHBNO3fu1MqVK1XvC6jolp7KyMhwO1LEoZQBACISk8iDZ+XKlfroo4/Uv39/TRidreQEb46Ohfs5Z04ZACAqhcs8Iy/o1auXxo0bp3nz5nm2kEUCRsoAAMC3nD36WfPdlLdp1KhRbseJCpQyAEBUYXTs6nw+n9asWaMj2zeoa8/estaGzVIX4Y5SBgBB1t7tYLyqPT+PSPk5R5r2zrE6ffq0SkpKdOzYMfUYOFw9h4ykkDmIUgYAUSbcJ0MjNM6fP6/i4mLFxMTo0UcfVfmGU25HukQ0/L6llAEAIgKjdR1z8fJkWlqa7rrrLhUUFDRtJr6h7Zd5o6EwOYFSBgDAVURy2Tt79qyWLl2qyZMnKzs7W7fffrvbkRzh1RJJKQMAIArt379fS5cuVSAQUFVVlbKzs92OFPUoZQAARBG/36/169dr48aNysnJ0axZs9S9e3e3Y0GUMgAAosr27du1ceNGFRYWauLEiYqLowp4BWcCAIAo0NDQoPj4eI0YMULp6enKz893O5JjvDqH7HKUMgBAVAqXb9SdFQhYbdiwQTt37tSCBQuUkpISVYUsnFDKACDIouWbfUvR+HMOBzX1fq3dc0oNvj/plltuUXx8vNuRPMkrd9hSygAAEYFieKmKigot/vCYGnwBPTF1qm655Ra3I11idvEm/ajBr+R4Nji/iFIGAMBVhGvZ++CDD5QQF6Mpt2R5rpChdZQyAEDQeOUy0NV8U7IiT01Njfx+v7p27aqHHnpINxz4teLjYjr0XuFaRq/m4u/PZ13OcSUdO1MAAESo2cWbvv7mHU4OHTqk3/72t3rjjTckSUlJSR0uZHAHI2UAEGbCYTQKzrHWatOmTXrnnXfUrVs3TZgwoVPv5/XRpEhGKQMAIEzV1dVp6dKl2rdvnwoKClRUVKTExES3Y6GDKGUAAIQpY4zOnDmjyZMna/To0TLGuB0JnUApAwC0KhInekcCa60+/vhjFRQUKCEhQQsXLlRsbPgtK/HsqR+rjyp0WAMd/Uwvo5QBABAmGnwBbSg/rfONS1VfX6/Ro0dfsZCxDphU0+DX7OJN15wf96PKHzY/cvcGD0oZAABh4NixYyr58Jiq6nya88x4FRYWhuRzvD6aFMkoZQAQZrisGH3Ky8u1ZMkS+QJW00b00tixY92OhBCglAEA4HE9e/ZUfn6+Bviyo/pyZKRjVTkAAEKopsGvmgZ/u3/cV199pXfeeUfWWmVmZmr27NkUsgjHSBkAAC144fLw3i+rtezFFxUfH6/Ro0crLS3NtSzhbLAqwmqOHKUMAACPaGxs1PpPTqm88oJGj8rVjBkz1LVrV7djwSFcvgQAwAOstfrDH/6g8soLGpWXpu985zudKmTPnvqxBqsieAERcoyUAQDgMmutjDG64447lPVxlvr1SFJMDOMm0cbRM26MmWSM2WeMOWCM+YervG6GMcYaY0Y5mQ8AACf5fD6tXLlSGzdulCQNHDhQ/XokuZwq+gxWhSdGFR0bKTPGxEp6QdJ4SUckfWSMWWGt/eSy13WV9ANJW5zKBgBAqFzpm/2ZM2dUUlKiyspK3XHHHc6Ggic5eflytKQD1trPJckY87qkqZI+uex1/ybp55LC53YJAIAkb9y5GA7Ky8u1fPlySdIjjzyiIUOGuJwIXuDk5ctcSYdbPD/SfOxrxpgRkvpYa1c6mAsAAMecOXNGpaWl6t69uxYuXEghw9c8M9HfGBMj6ZeS5rfhtQskLZCkvn37hjYYAABBUF9fr4SEBGVkZGju3Lnq16+f4uI8820YHuDkSNlRSX1aPO/dfOyirpKGSXrXGFMh6VZJK1qb7G+tXWStHWWtHZWVlRXCyAAAdN5np3z61a9+pf3790tqmtBPIcPlnCxlH0nKN8b0N8bES3pE0oqLX7TWnrPW9rDW5llr8yRtllRkrd3qYEYAAIImEAhow+f1Ktldq7S0NGVmZrodCR7mWE231vqMMc9IektSrKSXrbV7jDHPSdpqrV1x9XcAAHhdR/Z4jFRVVVUqKyvT/kMNujmni6Y/9ZS6dOnidix4mKNjp9baVZJWXXbs2Su89m4nMgEAvGN28SZJ0uKFt7mcpPM+/fRTVVZWasoNiRrWqwuFDNfEBW0AAIIkEAjoxIkT6tWrl2655RYNHDhQ5j/+X7djIUxQygAgikXSyJTbLly4oCVLlujIkSP63ve+p65du6pbt24638Yff/FctHr5CFGBUgYAQCcdPHhQZWVlqq2t1QMPPKDU1FS3IyEMUcoAIEQYhWq/cNsRwFqrjRs3at26derevbsee+wx9erVy+1YCFOUMgCeRKFBODDG6OzZsxo6dKimTJmihISEDr/XN4UU0YpSBgAImittvh1pjhw5ori4OGVnZ+uBBx6QMUbGGLdjIcxRygAgRMLtUhyuzVqrzZs3a+3aterfv7/mzZunmBgn12FHJKOUAQDQBnV1dVq2bJn27t2rIUOGaNq0aW5HQoShlAEAcA3na30qLi7WuXPnNHHiRN16661crkTQUcoAIIpxibVtUhJilZubq+nTp6tPnz5ux0GEopQBANCK+vp6rVu3TlkNfiXHx2rmzJluR0KEo5QBAHCZk1UNWr9okU6fPq2bz9RrUK9ktyMhCnDLCAAAzay1+uRotZZsPa6GhgY9/vjjFDI4hpEyAGgFi9dGpy1btmjD3tPq3T1RCxcuVGpqqva4HQpRg5EyAGFjdvGmr8uSl3g1l5vC7dfEWitJGj58uG4blK4pN2UFd/9Kq7D69YA7GCkDgFa05a5EvslGhl27dmnXrl2aM2eOkpOTNaJfmtuREKUoZQCAqNToD2jj/rM60fCG+vXrp/r6eiUnM38M7qGUAfAk1s9CKJ2tadRbu0/qZHWjpj9+h+699162S4LrKGUA0EEXi+Nzmc+7nMR72nP51+mbKay1WvuXU6qu9+vBm7J0//33O/r5wJVQygAAUcHn80mSjDG6t6C74uNi1DXRmW+DyaprLqqM/OLKKGUA0ElcavW+M2fOqLS0VDk5ORogKTM13u1IwLdwAR0AENH27dun4uJinT59WoMGDXI7DnBFjJQBACKSP2C1+bOz+vK115STk6OHH35YGRkZ2rPU7WRA6yhlAICIVF3v156j1Zows1ATJ05UXBzf8uBtXL4EAESUyspKWWvVLSlOj96aowcffJBChrBAKQMARIRAwGrLZ2dVXFys3bt3S5JSHbq7EggGfrcCAFwRzLtWq6qqtGLnVzp6pl6Tpo7QDTfcoP1vdvptAUdRygAAYa2iokJlZWU6fq5B9xVkqqioyO1IQIdQygAAYa2xsVFJSUmaWdiL9ccQ1phTBgAIOxcuXNCePXskSfn5+fqbv/kbChnCHiNlAICwcujQIZWVlamurk55eXlKSUlhM3FEBEoZgLDBdkbRzVqrDz74QOvWrVN6erqefPJJpaSkuB0LCBpKGYCQmV28SZK0eOFtLifpvEj6uYQja61KSkpUXl6ugoICFRUVKTEx0e1YQFBRygAAnmeMUZ8+fZSXl6fRo0fLGON2pKj1XObzkqTFLueIRFyEBwB4krVWmzdv1qeffipJuv322zVmzJioLWSzizeppsHvdgyEEKUMAOA5dXV1Kikp0Zo1a76+yxKIdFy+BAB4yonzDXqnuFjnzp3ThAkTdNttzONDdGCkDADgGacvNOqNbcfl9/s1f/583X777VF7uRLRh5EyAIDrrLUyxighzuimvl015+mnlZyc7HYswFGMlAHwtNnFm75ejgKR6fjx43rppZd06tQpGWM0vE9XChmiEiNlABAmLpbTZ13OEUx7v6zW3pdeUkJCgmpqatyOA7iKUgYgZFiBH1fS6A/oz/vOaG/lBY0p7K0ZM2YoNTVVx9wOBriIUgYAcNzOQ1XaV3lBhf3TNG/ePPauBEQpA4A2YdQvOOrq6iRJt/RN03XpCcrNSLykkA1WhUvJAPdRygB4GmUoMvh8Pq1Zs0aff/657vQFFB8Xo9wM9q5sryf1ExVkprHFUYSilAGISGwg7h2nT59WaWmpKisrNXbsWMVuCY91x7x2Y8Wzp36sGvn1C/3S7SgIES7iA3AUS1xEl/LychUXF+vs2bOaM2eOxo8fr9iY8ChlgNMYKQMiHCNGcIu1Vps2bVKPHj00a9Yspaenux0J8DRKGRAmKFcIF2frAqqVX0nxsZo9e7YSExMVGxvrdizA8yhlABAmvrnpwbsOnPLpj+V16pp1RhNv7KGUlBS3IwFhg1IGwFFO3U3JXZvO8gestnx+Tp9/XqueqbEaM7Cb25GAsEMpAwB0SlVVlZZv/0qV5+p193VddP+gBFUmdnE7FhB2KGUAQo75cJEtJiZGdY0BjR+aqfu6N17z9c9lPi8pPC7HAk5iSQwAncISF9EpEAho27Zt8vv9SklJ0SNjsnV9NvPHWrNPeaoRC+U67bnM57VPeW7HaBdGygAA7VJdXa0lS5boiy++UGJiooYOHaoY1h4DOo1SBgBRqKbBr9nFm9q9Wn1FRYXKyspUX1+vqVOnaujQoSHJF80uXt6Nhq2U9ilPv8h8Pip+rm1BKQMAtMm2bdv05ptvKjMzU/PmzVOvXr3cjgREFEoZAKBNcnNzddNNN2ny5MlKSEhwO07IcSMCnMZEfwDAFVWerdf69eslSdnZ2Zo2bVpUFDLADYyUAQC+xVqrHQfPa/NnZ5Wfu1u33367EhO5gxDeFu7z8ShlAIKKNcnCX21trZYtW6YPDpzVgKwkLVy4kEIGOIBSBgBRaLAqWp0zZa3V7373O504cUJ35GdoeJ/UsC1k4T5q4lX8gyt0KGUAAFlrJUnGGN1zzz1KTU3VuVffdjkVEF0oZQA6hY2/w1+DL6CysjL1799fo0aN0pAhQyRJ51zOBUQbShkQJig/CIWTVQ1as/ukklSu3r17ux0H15AcH8vlwwhGKQMQchRK77HWas/Rar2//4wSusRo/vz56tu3r9uxgKhGKQOAKPNc5vOav/8Zvbv3hPp0T9T9QzMpZOgUJ26qiIYbNyhlABBF6urqJEk9usar6Jaeyk1PYDPxCMbekuHF0VJmjJkk6VeSYiW9ZK392WVff1rS30nyS6qWtMBa+4mTGQEgUn388cdatWqVLtjBkqQ+3cNzqQugs7w66uZYKTPGxEp6QdJ4SUckfWSMWXFZ6fqDtfa3za8vkvRLSZOcyggAkaixsVGrV6/W9u3blZeXp/hzaVKD26kAXM7JvS9HSzpgrf3cWtsg6XVJU1u+wFp7vsXTFEnWwXxAu8wu3vT16vXh+P4d4cVMuLpTp07ppZde0vbt2zVu3Dh95zvfUZfEFLdjAWiFk5cvcyUdbvH8iKQxl7/IGPN3kn4oKV7Svc5EA4DItHfvXlVVVWnu3LnKz893Ow7giouXK1vbxcJLPDfR31r7gqQXjDGPSvpnSY9f/hpjzAJJCyRxxxAAz3H7G4DP59OpU6fUq1cv3X777brpppuUmprqShYv8+q8ItYhi15OXr48KqlPi+e9m49dyeuSprX2BWvtImvtKGvtqKysrCBGBIDwdubMGb388st65ZVXVF9fL2MMhQwIE+0eKTPGjJF0n6SeuqzUWWu/f5Uf+pGkfGNMfzWVsUckPXrZe+dbaz9tfvqgpE8FAGiTvXv3atmyZZKkadOmKSEhwbHPvjjq9GLldMc+E+GPHQou1a5SZoz5kaR/l3RA0pe6dCL+VSflW2t9xphnJL2lpiUxXrbW7jHGPCdpq7V2haRnjDH3S2qUdEatXLoEAFwqEAho7dq12rRpk6677jrNmjVLGRkZbse6oovfhPf81OUggMe0d6TsB5K+b639dUc+zFq7StKqy4492+LxDzryvgCuzOktjtzaUuniXaHR+K9uY4yqqqo0ZswYjR8/XnFxnpsujAgXjX/uQqG9f3LTdFmpAgC449NPP1X37t2VmZmp6dOnKyYmuNOEvToRvrMu/rxwdeF4/sO9HLa3lL2mpsVcfxOCLACANggErD784pwO//73uvHGGzVjxoygFzJ8IxzLSTho769rewvX4oW3ac9PY9uZyl3tLWWHJf2rMWaspF1qmvv1NWvtL4MVDIh2bl0GDLaaBr+kpgm96LwL9T69/ZdT+vJsvSZPG6lJk9j0BGgvr46otbeUfVdNe1Le3vxfS1ZN2yIBAELgVHWDlu/4So0+q/sKMjVlyhS3I3kKI1oId+0qZdba/qEKAnhRNE8eR8eF6u7CtKQ49c5I1Kj+3dQ9pUuH3yccL+uEs+T4WPYaRZt0eBKCMSbVGMMGakA7sX8k2qO6ulorVqxQfX29usTGaMKwHp0qZIgurAMWXjqyeOzfSfrfatrLUsaYI5J+bq1l8j8ABNHBgwdVVlam2tpaDRs2zO04V3XxG//5n7iboz0oK9HnSpe49ylPklTobJxvae/isf9H0j9K+oW+mX18p6SfGWPSrLU/C3I+AIg61lpt3LhR69atU/fu3TV37lxlZ2drj9vBAIRUe0fKnpa0wFr7Wotj64wxn0r6qSRKGSLKJ5Xn3Y6AKLR+/Xq99957GjZsmKZMmeLodkmAU+u4OTlSefGzvD51pL2lrKea9rC83IeSenU+DgAvi5RlOrzKWitjjAoLC5Wenq4RI0bIGON2rKjHZU44pb2lbL+aNhF/7rLjj0raF5REQJigoCBYrLXavHmzKioq9MgjjygtLU0jR450O1bYo0wh3JZJaW8p+4mkEmPMOEkbm4+NlXSXpFlBzAUAUaGurk7Lly9XeXm5hgwZosbGRsXHx7sdK6pd/Eb+zT+8ECm8XtTbu07ZG8aYMZL+l6S/aj5cLmm0tXZHsMMBXnRxTsKzLudA+Pvyyy9VWlqqc+fOaeLEibr11lvbdLky3P717xSvf8MFrqXdS2JYa7dJeiwEWQAgagQCAZWVlcnv9+uJJ55Qnz593I4ERK0n9RNJ0m53Y1y7lBljultrT198fLXXXnwdADgtXOb41dfXKy4uTrGxsXr44YeVlpam5ORkt2NFlWgZUevoiGq43KkYidoyUnbCGJNjrf1K0kk17XF5OdN8nH074AmRsD3SxY28ETmOHz+ukpISDRkyROPHj1d2drbbkYLu4iKc1Ex4QVu/BxTkpIU4Sdu0pZTdK+l0i8etlTIAaNVgVUiSDmugu0FcZK3Vzp07tXLlSiUlJSk/P9/tSHDQc5nP60eVP6So4pquWcqstX9q8fjdkKYBgAjT6Ato+fLl2rlzpwYMGKDp06crNTW1U+/p1AhwOI80A+Govdss+SVdvJTZ8nimpK+stVy+BIAWztX5tGfPHt19990aN26cYmJi3I4EtAml3HntvfvySvdqJ0hq6GQWAEE2u3iTftTgV3I8/15y2tGjRyVJPVLj9YPv/6DTo2MAIl+bSpkx5ofND62kp40x1S2+HKumTcn3BjkbAISdxsZGrVmzRtu2bdPo87Xq1yOJQgagTdo6Uva95v8bSd+V1PK2sAZJFWrarBwAotapU6dUWlqqY8eO6Y477lCvzWvdjoQOuHjZbs9PXQ6CqNOmUmat7S9JxpgNkqZba8+ENBXgES83LygoTQzae4bLelpon8++qtGKRYsUExOjuXPnKj8/X3s+/InbseABixfepj0/dX4KAXPC2s4rv1btnVM2Sa3MKzPGJEoKWGuZVwYgKgWsVVZWlmbNmqVu3bq5HQdAGGpvKSuR9CdJv7zs+NOS7pY0LQiZACAsnK/16URVgwb2TFZ+rxQVPfkkd1eiw9jTFO0tZWMl/VMrx9dK+j+djwMA4WHfvn0q+fCYYmOM+nZPVJe4mG8Vsmj8JntxD8HX9W/uBgHCUHtLWbIkXyvHA5K6dj4OAHib3+/X+vXrtXHjRqUlxWnijT3UJY7RsWC5uE1TobsxAFe0t5TtkjRH0r9cdvxRSX8JSiKgE9hAF6HkD1i98sorOnTokAoLC9U7dq3iYq+0fKN3Jg8jPPD7Be0tZc9JWm6MGSRpffOx+yTNkvRQMIMBgNfExhgNHDhQhYWFuvHGG7Xn4//b7UgAIki7Spm1dpUxZoqkf5b0/zQf3iGpyFq7OtjhAMBtgUBAf/rTn+Q7U6frMhJ11113uR0pqKJx3hvgVe0dKZO1do2kNSHIAnjOYFW4HQEuulDv06uvvqqKigr1PtVUyhBabAmGaNbuUgYA0eDI6Tqt3XNKGfFHNW3aNHVZ9Y7bkcJCQU5a04NT7uYAwtE1S5kx5rykAdbak8aYKjXtf9kqa21aMMMBgBsOHTqkFTu+UnpyF/31X/+1evbsqT2r3E4VHtiiCOi4toyUfU9SVfPjZ0KYBQBcZa2VMUZ9+vTR3pH/rIx+Q9SzZ0+3YwGIEtcsZdbaV1p7DESrb/auRKqPSacAACAASURBVCQ5dOiQVq1apTlz5qhbt27qMfBGtyMBiDLMKQMQ1ay1+uCDD7Ru3Tqlp6ervr6+zT/24p2LFHUAwdCWOWUBXWUeWUvWWm6bARAUThSe2tpaLVu2TPv27VNBQYGKioqUmNh0hyULeQJwWltGyh7WN6Wsl5oWkF0q6eLS6bepaSPyy1f5BwBPe/fdd3XgwAFNnjxZo0ePljFXXp0/UlE+Ae9oy5yysouPjTErJP2jtfbFFi952RjzoZqK2W+CHxEAgsdaq7q6OiUlJenee+/VTTfdpOuuu65D78WdhgCCqb276N4raUMrxzdIurvTaQB8bbAqWLw2yOrq6lRaWqrf/e538vl8SkhI6HAhA4Bga+9E/5OSZkr62WXHZ0o6EZREABAClZWVKi0t1dmzZ3X//fcrNpYpsHAO21mhLdpbyp6V9N/GmHv0zZyyWyXdL+mpYAYDgGCw1mrbtm1as2aNkpOTNX/+fPXt29ftWBGvLSWEogJcqr0bkr9qjNkn6fuSipoPl0saa63dEuxwANBZgUBAW7duVV5enh566CGlpKQE/TMoFwCCoSMbkm+RNDcEWQAgaE5VN6hrYpxiY2M1b948JScnR+XdlQDCR3sn+ssY08sY8yNjzG+MMT2aj401xvQPfjwAaL+dO3eq7KPj+uDAWUlSSkoKhQyA57VrpMwYM1LSOklfSBoq6Rdqmvw/XtL1kh4NdkAAHffsqR+rjyp0WAPdjuKIRn9Ay5cv144dO5TdLUGj+3dzO1LUYv2zS/HrgbZo7+XLX0j6lbX2X4wxVS2OvyXpieDFAoD2OVfTqNW7TiousFN33XWXesStVUwMo2MAwkd7L1+OlNTapuSValrtHwBcERtjZCXNnTtX99xzD4UMQNhp70hZraSMVo4PkfRV5+MAQNv5fD5t375dhYWFSk2M0yNjsjVo0CDHc3BpqmP4dQMu1d5StlzSvxhjZjU/t8aYPEk/l7QkiLkARLlrbWF0+vRplZaWqrKyUllZWZLEZH4AYa29pexHklapafX+ZEnvq+my5UZJ/xzcaABwqYvrgf2kvFzLli1TTEyMHn30UfXv3197XM4GAJ3V3lLmU9Mel+MkjVDTnLTt1tp3gpwLAFp14tMdWlz5lXJzczVr1iylp6e7HQkAgqLNpcwYEyvpnKSbrLXrJa0PWSoAuILkzBzdessAjR8/nv0rAUSUNpcya63fGHNQUnwI8wDAt1ScrNWpP/9ZUheldM/WpElMEAcQedp7+fLfJP3MGPOYtfZkKAIBwfDsqR83P3rf1RzonEAgoE0Hzmr7wfO6aXC5Av4CxcS2e3c4AAgL7V2n7EeS7pB01BjzmTFmV8v/QpAPQJQ6f/68XnnlFW0/eF5Dc1P11FNPUcgARLT2/g1XJslK4r5zACHj8/n0X//1X6qtrdX9QzM1ODtFcXEUMgCRrU1/yxljkiU9L2mapC5q2v/ye1zCBBBM1loZYxQXF6cJEyaoZ8+eeuaNeyRJi13OBgCh1tbLl/8qab6klZJek3S/pP8MUSYAEeK5zOe1T3ltem11dbVeffVV7d69W5I0dOjQrxeFBYBo0NbrAdMlPWWtfV2SjDG/l7TRGBNrrfWHLB2AqFBRUaGysjLV1dXp5ptvdjsOALiiraWsj6T3Lj6x1n5ojPFJuk7S4VAEAxD5rLV6//33tX79emVmZmrevHnq1auX27EAwBVtLWWxkhouO+Zrx48HgG/54osvtG7dOg0bNkxTpkxRQkKC25HgsotbaTGHENGoraXKSPofY0x9i2OJkl40xtRcPGCtLQpmOACR57nM5+VrqNMSSQMGDND8+fPVr18/z28mTlmA2/g9GPnaWspeaeXY/wQzCBAM3ywaCy+y1urkZ7v11f7tqpw5RDk5OcrLy7vqj1m8kNX7AUSHNpUya+0ToQ4CILLVNfq1ePFiHftki9Jy8pSRkeF2JADwFOaEAQi5yiq/SvceV7LZr5yht6p7/6FKTEx0OxYAeAqlDEDILF54m/b8NFb7TvhkZfXkk0/q2d69Hfls5t+EJy5XI5pRygCERH19vc6ePStJGtc/XrkDs9W7k4WMb9gAIpmjpcwYM0nSr9S0xMZL1tqfXfb1H0r6rpqW2zgh6Ulr7UEnMwLovJNVDVq/aJF8Pp/uC1jFGKPELrFuxwp7jP4Bka2t2yx1mjEmVtILkiZLKpA0xxhTcNnLdkgaZa0drqbNz//dqXwAOs9aqz1Hq7Vk63E1NDRoxowZio3x9lIXwJU8l/n810UYcIJjpUzSaEkHrLWfW2sbJL0uaWrLF1hrN1hrL657tlmSM5NPAHSaz+fTsmXL9O7e08pJT9DTTz+tvn37uh0LAMKGk5cvc3XplkxHJI25yuufkrS6tS8YYxZIWiCJv/QBj4iNjVVtba1GD+imkf3SlJKS4moe5p8BCDdOjpS1mTHmMUmjJLU6bmytXWStHWWtHZWVleVsOACX2HfsgqrqfDLGaM6cOSrs300xXLIEgHZzcqTsqJo2Nr+od/OxSxhj7pf0T5LustbWX/51AN7Q2Nio1atX6509p3RTn666VfL8VkmdwcgbgFBzspR9JCnfGNNfTWXsEUmPtnyBMeYWScWSJllrv3IwG+B5Xrrz7tSpUyopKdHx48c1Mi9No/t3czsSEPH4h0Hkc6yUWWt9xphnJL2lpiUxXrbW7jHGPCdpq7V2hZouV6ZKKm3+F/chNjkHvKXybL1WLFqkmJgYzZ07Vw2l77gdCQAigqPrlFlrV0laddmxZ1s8vt/JPADaLzO1iwYPHqz77rtP3bp10542/Jh9ytMvMp/3xCgfmnhp5BVAE1b0B3BNZ86c0Z/+9Cfl+QOKj4vR9OnT3Y4Ulbh8BUQ2ShmAq9q7d6+WLVsmSep2oVE90xIu+TojLgAQHJ5cEgOA+/x+v9566y29/vrr6t69uxYuXPitQgYACB5GygC0auXKldq+fbtGjx6tCRMmKC4uTl+6HQoAIhilDMAlrLUyxmjs2LEaOHCghg4d6nYkwBXM4YPTKGUAJEmBQEAbNmzQmTNnNGPGDGVmZiozM9PtWAAQNShlAFRVVaUlS5aooqJCI0eOVCAQUGxsrNuxEEKMAgHeQykDotwXX3yhsrIyNTQ06KGHHtJNN93kdiQAiEqUMiDCXW3h1oaGBpWVlSk5OVnz589XVlaW4/kAAE0oZUAUqqmpUVJSkuLj4/XYY48pMzNT8fHxQXlv1i0DgI5hnTIgyhw8eFD/+Z//qY0bN0qScnJyglbIAAAdx0gZECWstdq4caPWr1+vjIwMDRo0KCjvy4RxAAgOShkQBXwNdfrDH/6gTz/9VEOHDlVRUZESEpxbnT85PpbyBgDXQCkDwkRnSk199VlVnK/Qgw8+qFGjRskYE8RkAIBgoJQBHrVPeZKkwg7+eGutKs/Wq1tynFK6Z+t/zZuo5OTkoOUDAAQXE/2BCFRXV6eSkhK9se24jp+vlyQKGQB4HCNlQISprKxUSUmJzp07p7H56erZlTsrASAcMFIGRJBt27bppZdekt/v1xNPPKGb+6YxfwwAwgQjZUAEsdaqf//+mj59upKTk7XH7UAAgDajlAFh7vjx4zp79qwGDx6skSNHauTIkYyOAUAYopQBHeSF7YR27NihVatWKS0tTfn5+YqJCe2MBC/8nAEgUlHKgDDU0NCgVatWaefOnRowYICmT58e8kIGAAgtShkQZhoaGvTSSy/pxIkTuvvuuzVu3DgKGQBEAEoZ4FHJ8bGtHo+Pj9fgwYM1ceJEDRw40OFU3sWlVQDhjlIGhAGfz6e3335bt9xyi3JycnTfffe5HanNKEsA0DaUMsDjTp8+rZKSEh07dkwZGRnKyclxOxIAIAQoZYCHffZVjVYUFysmJkaPPvqorr/+ercjXVNnNk4HgGhGKQM86osTNVqz+6RGDMvSzJkzlZ6e7nYkAEAIUcoAj7HWyhijfplJuvP6DD38xBOKjW190j8AIHJQygCHXW3i+759+7Ru3To9/vjjiokxGt6nK4UMAKIEpQzwAL/fr/Xr12vjxo3KyclRY2Oj25EAAA6jlAEuO3/+vEpLS3X48GEVFhZq4sSJiouL01G3gwEAHEUpA1y2du1aHT9+XDNnztSwYcPcjgMAcAmlDLiKfcqTJBUG+X1tIKCamholJydr8uTJuuuuu9SjR48gfwoAIJywYR7gsMa6C6rYvFqvvfaaAoGAkpOTKWQAAEbKACd98cUX+uzPyxXwNWjkyJlht5E4C8MCQOhQyoCreFI/kSTt7uT7WGv13nvvacOGDYrtEq+8Wyfp5ptv7nQ+AEDkoJQB7fT1OmPtGDVqbGzUxx9/rGHDhml3jyzFxnUJVTwAQJiilAEhdPToUfXs2VPx8fF66qmnlJSUpJJFmx3NkBwfGxWXHaPh5wggslHKgBCw1uqDDz7QunXrNHbsWN13331KTk52O5YrKEsA0DaUMiDIamtrtWzZMu3bt08FBQUaO3as25EAAGGAUgYEUWVlpRYvXqyqqipNnjxZo0ePljHG7VgAgDBAKQOCKD4+XgkJCZo1a5Zyc3M79V5X27gcABB5wmuRJMCD6urqtGXLFllrlZmZqaeffrrThQwAEH0YKQM6obKyUqWlpTp79qz69eun7OxsLlcCADqEUgZ0gLVWW7du1Zo1a5ScnKz58+crOzvb7VgAgDBGKQM64NhfNunNY1UaNGiQHnroIaWkpLT5x7JEBACgNZQyoANSe/bRvXdn68477+RyJQAgKChlQBvt3LlTtbW1kqSuvfpo3DhGvAAAwUMpA67B+n1avny5duzYoQEDBsjaQYyOAQCCjiUxgKvw1ZzT6e1rtHPnTo0bN06PPfYYhQwAEBKMlAFXUFdXpzPb10gmRnPnztWgQYPcjgQAiGCUMuAy1loZY5SYmKibbr9XKd2zw7aQsSsAAIQPLl8CLZw+fVovvvii9u/fL0lKzx2oLkltX+4CAICOYqQMaFZeXq5ly5YpJiaGeWMAAMdRyhD1/H6/1q5dq82bNys3N1ezZs1Senq627EAAFGGUoaI1J65VHv37tXmzZs1ZswYTZgwQbGxsaENBwBAKyhliFrV1dVKTU1VQUGBnnrqKfXp08ftSACAKEYpQ9QJBAJav369PvroIy1YsECZmZntKmTsXQkACAVKGaLK+fPntWTJEh08eFAjR45UWlraVV9PAQMAOIVShqjx2Wef6Y033lBjY6OmT5+u4cOHux0JAICvUcoQNcrLy5WSkqKHH35YPXr0cDsOAACXoJQholy86/Ki6upq1dbWKisrS5MmTVIgEFB8fLxL6QAAuDJW9EfEunCyUr/97W9VVlYma63i4uIoZAAAz6KUIeJYa3Xi052q2LxKCQkJmj59Oiv0AwA8j8uXiCj+xgYd2b5eVV8dUbfrBmjBggVKSEhwOxYAANdEKUNEiYmNk7VW1914uzL63RDWhYzlOAAgulDKEPastdq6dasKCgpkYmLUb8wkLlcCAMKOo3PKjDGTjDH7jDEHjDH/0MrXxxljthtjfMaYmU5mQ3iqra3V4sWLtXLlSm3fvl2SKGQAgLDkWCkzxsRKekHSZEkFkuYYYwoue9khSfMl/cGpXAhfX375pRYtWqT9+/dr0qRJuuOOO9yOBABAhzl5+XK0pAPW2s8lyRjzuqSpkj65+AJrbUXz1wIO5kIY2r9/vxYvXqzU1FQ9+eST6t27t9uRAADoFCdLWa6kwy2eH5E0piNvZIxZIGmBJPXt27fzyRB2evfureHDh2v8+PFKTk52Ow4AAJ0WluuUWWsXWWtHWWtHZWVluR0HDjl27JiWLl0qv9+v5ORkTZ06lUIGAIgYTo6UHZXUp8Xz3s3HgKuy1mrHjh1atWqVkpKSdPbsWWVmZrodCwCAoHKylH0kKd8Y019NZewRSY86+PkIQw0NDVq5cqU+/vhjDRgwQDNmzFBKSorbsQAACDrHSpm11meMeUbSW5JiJb1srd1jjHlO0lZr7QpjTKGkpZIyJE0xxvyrtXaoUxnhPUuWLNH+/ft1zz336M4771RMTFhecQcA4JocXTzWWrtK0qrLjj3b4vFHarqsiSgXCAQUExOje+65R2PGjNGAAQPcjgQAQEixoj88pbGxUWvWrJEkTZkyRdnZ2S4nAgDAGZQyeMapU6dUWlqqY8eO6c4775S1ltX5O4n9MwEgfFDK4Al79uzRihUrFBMTo7lz5yo/P9/tSAAAOIpSBtfV1NRoxYoVysrK0qxZs9StWze3IwEA4DhKGVxTXV2tlJQUJScna/78+erZs6diY2PdjgUAgCtYXwCu2Lt3r379619r27ZtkqScnBwKGQAgqjFSBkf5/X6988472rRpk6677joNHDjQ7UgAAHgCpQyOOXfunMrKynT48GGNHj1aEyZMUFwcvwUBAJAoZXDQiRMn9NVXX2nmzJkaNmyY23EAAPAUShlCKhAI6NChQ8rLy9OgQYP093//90pKSnI7FgAAnsNEf4RMVVWVXn31Vb3yyis6efKkJFHIAAC4AkbKEBKff/65lixZooaGBk2bNk09evRwOxIAAJ5GKUPQ/fnPf9aGDRvUo0cPPf744+rZs6fbkQAA8DxKGYIuJiZGN954o/7qr/5K8fHxbscBACAsUMoQFAcPHpTP59PAgQM1duxYSWIzcQAA2oFShk6x1mrjxo1av369rrvuOg0YMIAyBgBAB1DK0GE1NTVatmyZ9u/fr6FDh6qoqIhCBgBAB1HK0CHV1dV68cUXVV1drQceeECFhYWeKmSLF97mdgQAANqFUoYOSUlJ0dChQzV06FDl5ua6HQcAgLDH4rFos7q6Or3xxhs6efKkjDGaMGEChQwAgCBhpAxtUllZqZKSEp07d04DBw5kMVgAAIKMUoarstZq27ZtWr16tVJSUvTEE0+oT58+bse6IuaSAQDCFaUMV7Vz5069+eabGjRokKZPn67k5GS3IwEAEJEoZWhVIBD4emX+QCCgESNGeOruSgAAIg0T/fEtO3bsUHFxserq6hQXF6eRI0dSyAAACDFGyvC1hoYGrVq1Sjt37lT//v3l9/vdjgQAQNSglEGSdOLECZWWlurEiRO6++67NW7cOMXEMJAKAIBTKGWQJL311lu6cOGCHnvsMQ0cONDtOAAARB1KWRTz+XxqbGxUUlKSioqKJElpaWkupwIAIDpRyqLU6dOnVVJSotTUVM2dO5cyBgCAyyhlUeiTTz7R8uXLFRMTo3vvvZc7KwEA8ABKWRTx+/16++23tWXLFuXm5mrWrFlKT093OxYAABClLKrU19ervLxct956q8aPH6/Y2Fi3IwEAgGaUsihQUVGhPn36KDk5WX/7t3+rxMREtyMBAIDLsBBVBPP7/Vq7dq1+97vf6cMPP5QkChkAAB7FSFmEOn/+vMrKynTo0CEVFhaqsLDQ7UgAAOAqKGUR6IsvvlBpaal8Pp9mzJihG2+80e1IAADgGihlESgpKUkZGRl66KGH1KNHD7fjAACANmBOWYSorq7Wli1bJEnZ2dn67ne/SyEDACCMMFIWAb744gstWbJE9fX1uv7665WRkcGCsAAAhBlKWRiz1uq9997Thg0blJmZqe985zvKyMhwOxYAAOgASlkYKysr0549e3TjjTdqypQpio+PdzsSAADoIEpZGCsoKNCAAQM0YsQILlcCABDmKGVhxFqrTZs2KT4+XqNGjdLQoUPdjgQAAIKEuy/DRG1trV5//XW9/fbbOnjwoKy1bkcCAABBxEhZGDh69KhKS0tVVVWlyZMna/To0VyuBAAgwlDKPO78+fP67//+b6WmpurJJ59Ubm6u25EAAEAIUMo8KhAIKCYmRmlpaSoqKlJ+fr6SkpLcjgUAAEKEOWUedOzYMf3mN79RRUWFJGn48OEUMgAAIhwjZR5irdX27du1evVqJSUlKTY21u1IAADAIZQyj2hoaNCbb76pXbt2aeDAgZo+fbpSUlLcjgUAABxCKfOIXbt2affu3br33nt15513cnclAABRhlLmsqqqKnXt2lUjR45Ubm6ucnJy3I4EAABcwER/lzQ2Nmr58uX6zW9+o/Pnz8sYQyEDACCKMVLmgpMnT6q0tFTHjx/XuHHjlJqa6nYkAADgMkqZw/7yl79oxYoViouL02OPPaZBgwa5HQkAAHgApcxhe/fuVXZ2tmbOnKm0tDS34wAAAI+glDngzJkzCgQCyszMVFFRkWJjY1mDDAAAXIKJ/iFWXl6u4uJi/fGPf5QkxcfHU8gAAMC3MFIWIn6/X2vXrtXmzZuVm5uradOmuR0JAAB4GKUsBKqrq/X666/ryJEjGjNmjMaPH6+4OH6pAQDAldEUQiAxMVFxcXGaNWuWhg4d6nYcAAAQBphTFiSBQEDvv/++6urqFBcXp8cff5xCBgAA2oyRsiCoqqpSWVmZDh48qOTkZI0YMYK9KwEAQLtQyjrps88+0xtvvKHGxkZNnz5dw4cPdzsSAAAIQ5SyTti5c6eWL1+urKwszZo1S1lZWW5HAgAAYYpS1gkDBgxQYWGh7r//fsXHx7sdBwAAhDFHJ/obYyYZY/YZYw4YY/6hla8nGGMWN399izEmz8l8bVFRUaFly5bJWqu0tDQ98MADFDIAANBpjpUyY0yspBckTZZUIGmOMabgspc9JemMtXaQpP+Q9HOn8l2LtVbvvfeeXnnlFR0+fFjV1dVuRwIAABHEycuXoyUdsNZ+LknGmNclTZX0SYvXTJX0k+bHZZJ+bYwx1lrrYM5vqamp0dKlS/Xpp59q2LBhmjJlihISEtyMBAAAIoyTpSxX0uEWz49IGnOl11hrfcaYc5IyJZ10JGErrLV67bXX9OWXX+rBBx/UqFGjWO4CAAAEXVhO9DfGLJC0QJL69u0b6s/SxIkTFRsbq5ycnJB+FgAAiF5OTvQ/KqlPi+e9m4+1+hpjTJykbpJOXf5G1tpF1tpR1tpRTixD0bt3bwoZAAAIKSdL2UeS8o0x/Y0x8ZIekbTisteskPR48+OZkta7PZ8MAADACY5dvmyeI/aMpLckxUp62Vq7xxjznKSt1toVkv5L0v9njDkg6bSaihsAAEDEc3ROmbV2laRVlx17tsXjOkmznMwEAADgBY4uHgsAAIDWUcoAAAA8gFIGAADgAZQyAAAAD6CUAQAAeAClDAAAwAMoZQAAAB5AKQMAAPAAShkAAIAHUMoAAAA8gFIGAADgAZQyAAAAD6CUAQAAeAClDAAAwAMoZQAAAB5grLVuZ+gUY8wJSQdD/DE9JJ0M8Weg/Tgv3sM58SbOi/dwTrzJifPSz1qb1doXwr6UOcEYs9VaO8rtHLgU58V7OCfexHnxHs6JN7l9Xrh8CQAA4AGUMgAAAA+glLXNIrcDoFWcF+/hnHgT58V7OCfe5Op5YU4ZAACABzBSBgAA4AGUshaMMZOMMfuMMQeMMf/QytcTjDGLm7++xRiT53zK6NOG8zLOGLPdGOMzxsx0I2O0acM5+aEx5hNjzC5jzDpjTD83ckabNpyXp40xu40xO40x7xtjCtzIGU2udU5avG6GMcYaY7gjM8Ta8OdkvjHmRPOfk53GmO86lY1S1swYEyvpBUmTJRVImtPKX1hPSTpjrR0k6T8k/dzZlNGnjeflkKT5kv7gbLro1MZzskPSKGvtcEllkv7d2ZTRp43n5Q/W2huttTer6Zz80uGYUaWN50TGmK6SfiBpi7MJo09bz4mkxdbam5v/e8mpfJSyb4yWdMBa+7m1tkHS65KmXvaaqZJeaX5cJuk+Y4xxMGM0uuZ5sdZWWGt3SQq4ETAKteWcbLDW1jQ/3Sypt8MZo1Fbzsv5Fk9TJDGpOLTa8n1Fkv5NTf/Ir3MyXJRq6zlxBaXsG7mSDrd4fqT5WKuvsdb6JJ2TlOlIuujVlvMCZ7X3nDwlaXVIE0Fq43kxxvydMeYzNY2Ufd+hbNHqmufEGDNCUh9r7Uong0Wxtv79NaN5+kWZMaaPM9EoZQBCyBjzmKRRkp53OwuaWGtfsNYOlPS/Jf2z23mimTEmRk2XkP8vt7PgEn+UlNc8/WKtvrlCFnKUsm8cldSyDfduPtbqa4wxcZK6STrlSLro1ZbzAme16ZwYY+6X9E+Siqy19Q5li2bt/bPyuqRpIU2Ea52TrpKGSXrXGFMh6VZJK5jsH1LX/HNirT3V4u+slySNdCgbpayFjyTlG2P6G2PiJT0iacVlr1kh6fHmxzMlrbcs9BZqbTkvcNY1z4kx5hZJxWoqZF+5kDEateW85Ld4+qCkTx3MF42uek6steestT2stXnW2jw1zb8sstZudSduVGjLn5OcFk+LJJU7FS7OqQ/yOmutzxjzjKS3JMVKetlau8cY85ykrdbaFZL+6/9v7/5Cs6rjOI6/P4QWtJtMkm5KKKMcksasoH/eiBApBd2sCBaVkbrsj1D0TyMKykVF07oQE1bWsL/0hxKMXVSSZMKQSTXmqC7CUVFsTub028U5s8PTs+3s39mZfV5w2Hme8/v9zvdweJ59n9/5/c4BWiR1An+QnEybQnnOi6SlwAfAOcBKSU9HRO00hn1ay/lZ2QzUALvSuTA/R8SqaQv6fyDneVmX9mAeB/7k3x+ZNgVynhMrUM5zcr+kVcAgyf/6hqLi8x39zczMzErAly/NzMzMSsBJmZmZmVkJOCkzMzMzKwEnZWZmZmYl4KTMzMzMrASclJmZjULSXEkhaVkJYglJt053HGY2+ZyUmVlhJM2T9JKknyQdk3RE0jeSGiXVTHd8EyGpTVLzJLa3SdLByWrPzMrPN481s0JImg98DfwNPAm0A/1ALXA3ySPLdg5Td3ZEDBQS6BSTNCsijk93HGZWPu4pM7OivAacBOoi4p2I6IiIwxHxSUTcDLw9VDC9RLdW0vuS+oDn0vfvldQpaSD9ITynYQAAAxRJREFUe092B9Uu7UnqlrShosxqSbsk9UnqSh+cnq2zVNL+tDfvAHDVSAcmaQdwA7A2bT8kzZe0LF2/UdI+SQPAimq9YJIaJPUOrQMbgdpMew2Z4nNGit/MZiYnZWY25SSdC6wAtkREX7UyVZ4juxH4DFgEbJF0C9AMvEzyEOdXgK2SVo4jpKeAj4DLgVZgu6QL0lhrgE+BLqAOeBRoGqW99cBe4A3g/HT5JbP9eeAJ4FLg2xzxtQIvAj9k2mvNE7+ZzVxOysysCBcDIkkyTpH0q6TedHm9ok5rRGyLiK6IOAxsAFoiojkifoyIV4G3gEfGEU9LRLwZEZ0kl1IHgevTbbcBs4E7I+JgRHwBPDtSYxHxFzAAHI2I39LlRKbIpojYnR5Lz2jBRUQ/0AsMZtrrzxm/mc1QTsrMbDpdBywG9gFnVWz7ruL1ZSRj0rK+AhaOY7/tQysRMQj0AOdl9tMeEb2Z8nvHsY+symOZqJHiN7MZygP9zawInUCQXL47Je0BQ9LRKnWqXuasIirWVbF9VpU6lQPtg6n9kVp5LCfJF+dwio7fzArgD7GZTbmI+B3YDaybwK0vDgHXVLx3LdCRed1DMv4KSG7BkX09hv0sknR25r2rc9QbAM7IuY8eYJ6kbGK2eALtmdlpwEmZmRVlDcl3zn5J9ZIWSrpEUj3JgPUTI1dnM3BHOitzgaRG4HbghUyZL0lmQNZJWgLsAI6NMc6dJGO0tkuqlbQceDxHvW7gynTW5VxJI32/tgFzgMckXSTpLqDyhrDdwIWSrkjbO3OMx2FmM4yTMjMrRER0AUuAz4FngAPA98BDwFbggVHqfwg0Ag+S9I6tB9ZExMeZYg+TzJpsA94FtgFHxhhnL3ATsCCNr4l8kwmaSHq3Okh6woadDRkRh4D7gNUk48OWk972I+M9ktmne9L26sdyHGY28+i/s9DNzMzMrGjuKTMzMzMrASdlZmZmZiXgpMzMzMysBJyUmZmZmZWAkzIzMzOzEnBSZmZmZlYCTsrMzMzMSsBJmZmZmVkJOCkzMzMzK4F/ALQGNdHuHn2MAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cjOInpOZ1V-q"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}
