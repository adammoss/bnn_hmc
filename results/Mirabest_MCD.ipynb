{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/bnn_hmc/blob/main/results/Mirabest_MCD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import astro_datasets\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "0Qzhlk1lAcYm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_iter = 200\n",
        "dropout = 0.1"
      ],
      "metadata": {
        "id": "fV0em6JQAGyU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astro-datasets --upgrade"
      ],
      "metadata": {
        "id": "UCaVOb8qDuss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7575690-7d04-41a7-8cf4-01d48b8548e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: astro-datasets in /usr/local/lib/python3.7/dist-packages (0.0.9)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (4.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (1.3.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from astro-datasets) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astro-datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->astro-datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->astro-datasets) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (0.26.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->astro-datasets) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->astro-datasets) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->astro-datasets) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->astro-datasets) (3.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (1.9.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (4.64.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (0.10.2)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (0.6.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->astro-datasets) (0.3.5.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->astro-datasets) (1.56.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets --upgrade"
      ],
      "metadata": {
        "id": "RxQoEJrn1bMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff86ce9f-0ac3-475b-88e1-575603041d5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.21.6)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.6.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.64.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.1.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow_datasets) (3.8.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset, splitting into training, validation and testing"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3QjJ8hJkDc3P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "dataset_train, info_train = tfds.load(name='mirabest/confident', split='train[:80%]', batch_size=50, as_supervised=True, with_info=True)\n",
        "dataset_valid, info_valid = tfds.load(name='mirabest/confident', split='train[80%:]', batch_size=50, as_supervised=True, with_info=True) \n",
        "dataset_test, info_test = tfds.load(name='mirabest/confident', split='test', batch_size=50, as_supervised=True, with_info=True) "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PxcCbkYaDc3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HlQNxJJLkCko"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define MCD layer"
      ],
      "metadata": {
        "id": "XaopgRkWW1sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MonteCarloDropout(tf.keras.layers.Dropout):\n",
        "     def call(self, inputs):\n",
        "         return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "UeBngvEAW2Ev"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BBxP_9PqDc3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(6, kernel_size=5, strides=1, padding = 'same', input_shape=(150, 150, 1)),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2,2)),\n",
        "    MonteCarloDropout(dropout),\n",
        "    tf.keras.layers.Conv2D(16, kernel_size=5, strides=1, padding = 'same'),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2,2)),\n",
        "    MonteCarloDropout(dropout),\n",
        "    tf.keras.layers.Conv2D(120, kernel_size=5, strides=1, padding = 'same'),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2,2)),\n",
        "    MonteCarloDropout(dropout),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(84),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    MonteCarloDropout(dropout),\n",
        "    tf.keras.layers.Dense(2, activation='softmax'),\n",
        "    ])"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Njap0BGqDc3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "r47JZ-5iDXuf",
        "outputId": "b8f64742-1168-4b9a-9680-33616594c56b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 150, 150, 6)       156       \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 150, 150, 6)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " monte_carlo_dropout (MonteC  (None, 74, 74, 6)        0         \n",
            " arloDropout)                                                    \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 74, 74, 16)        2416      \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 74, 74, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " monte_carlo_dropout_1 (Mont  (None, 36, 36, 16)       0         \n",
            " eCarloDropout)                                                  \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 36, 36, 120)       48120     \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 36, 36, 120)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 120)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " monte_carlo_dropout_2 (Mont  (None, 17, 17, 120)      0         \n",
            " eCarloDropout)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 34680)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                2913204   \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 84)                0         \n",
            "                                                                 \n",
            " monte_carlo_dropout_3 (Mont  (None, 84)               0         \n",
            " eCarloDropout)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,964,066\n",
            "Trainable params: 2,964,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "yVQ_MlmaDc3U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "loss=tf.keras.losses.SparseCategoricalCrossentropy()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6yASCNz9Dc3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimiser and learning rate scheduler"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "o05piryBDc3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.95, patience=3)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tRKUeZ8MDc3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "poiLvWqlDc3W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "model.compile(optimizer=opt,\n",
        "              loss=loss,\n",
        "              metrics='accuracy')\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7fT8Wre_Dc3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save best weights"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b0qDJiw4Dc3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "checkpoint_path = \"mirabest/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                  save_weights_only=False,\n",
        "                                                  monitor='val_loss',\n",
        "                                                  mode='min',\n",
        "                                                  verbose=1,\n",
        "                                                  save_best_only=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "u_ycRk-vDc3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JzEdGL4YDc3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.7499 - accuracy: 0.5077\n",
            "Epoch 1: val_loss improved from inf to 1.10516, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 6s 274ms/step - loss: 1.7499 - accuracy: 0.5077 - val_loss: 1.1052 - val_accuracy: 0.5274 - lr: 5.0000e-05\n",
            "Epoch 2/100\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.8319 - accuracy: 0.6480\n",
            "Epoch 2: val_loss improved from 1.10516 to 0.73141, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 0.8127 - accuracy: 0.6449 - val_loss: 0.7314 - val_accuracy: 0.6301 - lr: 5.0000e-05\n",
            "Epoch 3/100\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.5650 - accuracy: 0.7400\n",
            "Epoch 3: val_loss improved from 0.73141 to 0.70089, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 3s 293ms/step - loss: 0.5401 - accuracy: 0.7410 - val_loss: 0.7009 - val_accuracy: 0.6438 - lr: 5.0000e-05\n",
            "Epoch 4/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.4949 - accuracy: 0.7714\n",
            "Epoch 4: val_loss improved from 0.70089 to 0.63264, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 1s 131ms/step - loss: 0.4654 - accuracy: 0.7770 - val_loss: 0.6326 - val_accuracy: 0.6644 - lr: 5.0000e-05\n",
            "Epoch 5/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.4076 - accuracy: 0.8143\n",
            "Epoch 5: val_loss did not improve from 0.63264\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4053 - accuracy: 0.8027 - val_loss: 0.6345 - val_accuracy: 0.6781 - lr: 5.0000e-05\n",
            "Epoch 6/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.3853 - accuracy: 0.8229\n",
            "Epoch 6: val_loss improved from 0.63264 to 0.61929, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 2s 196ms/step - loss: 0.3748 - accuracy: 0.8233 - val_loss: 0.6193 - val_accuracy: 0.6986 - lr: 5.0000e-05\n",
            "Epoch 7/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.3707 - accuracy: 0.8400\n",
            "Epoch 7: val_loss improved from 0.61929 to 0.57477, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 2s 172ms/step - loss: 0.3640 - accuracy: 0.8456 - val_loss: 0.5748 - val_accuracy: 0.7534 - lr: 5.0000e-05\n",
            "Epoch 8/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.3117 - accuracy: 0.8686\n",
            "Epoch 8: val_loss did not improve from 0.57477\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3204 - accuracy: 0.8611 - val_loss: 0.6115 - val_accuracy: 0.7192 - lr: 5.0000e-05\n",
            "Epoch 9/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.3344 - accuracy: 0.8629\n",
            "Epoch 9: val_loss improved from 0.57477 to 0.55147, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 2s 144ms/step - loss: 0.3227 - accuracy: 0.8662 - val_loss: 0.5515 - val_accuracy: 0.7603 - lr: 5.0000e-05\n",
            "Epoch 10/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2860 - accuracy: 0.8600\n",
            "Epoch 10: val_loss improved from 0.55147 to 0.53405, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 2s 203ms/step - loss: 0.2882 - accuracy: 0.8628 - val_loss: 0.5341 - val_accuracy: 0.7877 - lr: 5.0000e-05\n",
            "Epoch 11/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.3137 - accuracy: 0.8286\n",
            "Epoch 11: val_loss did not improve from 0.53405\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2837 - accuracy: 0.8611 - val_loss: 0.6118 - val_accuracy: 0.7260 - lr: 5.0000e-05\n",
            "Epoch 12/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.3144 - accuracy: 0.8686\n",
            "Epoch 12: val_loss did not improve from 0.53405\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2865 - accuracy: 0.8782 - val_loss: 0.6379 - val_accuracy: 0.7740 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2719 - accuracy: 0.8829\n",
            "Epoch 13: val_loss did not improve from 0.53405\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2686 - accuracy: 0.8919 - val_loss: 0.6078 - val_accuracy: 0.7740 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2468 - accuracy: 0.8971\n",
            "Epoch 14: val_loss improved from 0.53405 to 0.52227, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 4s 320ms/step - loss: 0.2348 - accuracy: 0.9074 - val_loss: 0.5223 - val_accuracy: 0.8082 - lr: 4.7500e-05\n",
            "Epoch 15/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2480 - accuracy: 0.9029\n",
            "Epoch 15: val_loss did not improve from 0.52227\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2363 - accuracy: 0.9074 - val_loss: 0.6281 - val_accuracy: 0.7192 - lr: 4.7500e-05\n",
            "Epoch 16/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1860 - accuracy: 0.9257\n",
            "Epoch 16: val_loss did not improve from 0.52227\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1942 - accuracy: 0.9177 - val_loss: 0.6796 - val_accuracy: 0.7123 - lr: 4.7500e-05\n",
            "Epoch 17/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2594 - accuracy: 0.8829\n",
            "Epoch 17: val_loss did not improve from 0.52227\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2297 - accuracy: 0.9005 - val_loss: 0.5685 - val_accuracy: 0.7534 - lr: 4.7500e-05\n",
            "Epoch 18/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2106 - accuracy: 0.9114\n",
            "Epoch 18: val_loss did not improve from 0.52227\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1863 - accuracy: 0.9245 - val_loss: 0.5988 - val_accuracy: 0.7466 - lr: 4.5125e-05\n",
            "Epoch 19/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2137 - accuracy: 0.9057\n",
            "Epoch 19: val_loss did not improve from 0.52227\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2021 - accuracy: 0.9091 - val_loss: 0.6031 - val_accuracy: 0.7808 - lr: 4.5125e-05\n",
            "Epoch 20/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2027 - accuracy: 0.9171\n",
            "Epoch 20: val_loss improved from 0.52227 to 0.47869, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 2s 160ms/step - loss: 0.1810 - accuracy: 0.9297 - val_loss: 0.4787 - val_accuracy: 0.8151 - lr: 4.5125e-05\n",
            "Epoch 21/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.2022 - accuracy: 0.9257\n",
            "Epoch 21: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2008 - accuracy: 0.9211 - val_loss: 0.6559 - val_accuracy: 0.7808 - lr: 4.5125e-05\n",
            "Epoch 22/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1882 - accuracy: 0.9257\n",
            "Epoch 22: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1791 - accuracy: 0.9314 - val_loss: 0.5641 - val_accuracy: 0.8014 - lr: 4.5125e-05\n",
            "Epoch 23/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1983 - accuracy: 0.9086\n",
            "Epoch 23: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1675 - accuracy: 0.9262 - val_loss: 0.6007 - val_accuracy: 0.8014 - lr: 4.5125e-05\n",
            "Epoch 24/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1890 - accuracy: 0.9229\n",
            "Epoch 24: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1664 - accuracy: 0.9383 - val_loss: 0.5921 - val_accuracy: 0.8082 - lr: 4.2869e-05\n",
            "Epoch 25/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1787 - accuracy: 0.9171\n",
            "Epoch 25: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9297 - val_loss: 0.5078 - val_accuracy: 0.8219 - lr: 4.2869e-05\n",
            "Epoch 26/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1254 - accuracy: 0.9657\n",
            "Epoch 26: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1358 - accuracy: 0.9554 - val_loss: 0.7065 - val_accuracy: 0.7671 - lr: 4.2869e-05\n",
            "Epoch 27/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1596 - accuracy: 0.9314\n",
            "Epoch 27: val_loss did not improve from 0.47869\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1565 - accuracy: 0.9331 - val_loss: 0.5405 - val_accuracy: 0.8082 - lr: 4.0725e-05\n",
            "Epoch 28/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1398 - accuracy: 0.9457\n",
            "Epoch 28: val_loss improved from 0.47869 to 0.46519, saving model to mirabest/cp.ckpt\n",
            "12/12 [==============================] - 3s 258ms/step - loss: 0.1249 - accuracy: 0.9554 - val_loss: 0.4652 - val_accuracy: 0.8151 - lr: 4.0725e-05\n",
            "Epoch 29/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1499 - accuracy: 0.9314\n",
            "Epoch 29: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1342 - accuracy: 0.9417 - val_loss: 0.5338 - val_accuracy: 0.8151 - lr: 4.0725e-05\n",
            "Epoch 30/100\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.1302 - accuracy: 0.9418\n",
            "Epoch 30: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1377 - accuracy: 0.9365 - val_loss: 0.6683 - val_accuracy: 0.7808 - lr: 4.0725e-05\n",
            "Epoch 31/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1474 - accuracy: 0.9457\n",
            "Epoch 31: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1437 - accuracy: 0.9417 - val_loss: 0.6721 - val_accuracy: 0.7329 - lr: 4.0725e-05\n",
            "Epoch 32/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1475 - accuracy: 0.9486\n",
            "Epoch 32: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1362 - accuracy: 0.9520 - val_loss: 0.6306 - val_accuracy: 0.7945 - lr: 3.8689e-05\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9485\n",
            "Epoch 33: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1224 - accuracy: 0.9485 - val_loss: 0.7042 - val_accuracy: 0.7945 - lr: 3.8689e-05\n",
            "Epoch 34/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1264 - accuracy: 0.9600\n",
            "Epoch 34: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1328 - accuracy: 0.9571 - val_loss: 0.5413 - val_accuracy: 0.8288 - lr: 3.8689e-05\n",
            "Epoch 35/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1418 - accuracy: 0.9457\n",
            "Epoch 35: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9485 - val_loss: 0.5936 - val_accuracy: 0.8219 - lr: 3.6755e-05\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9520\n",
            "Epoch 36: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1224 - accuracy: 0.9520 - val_loss: 0.6275 - val_accuracy: 0.8014 - lr: 3.6755e-05\n",
            "Epoch 37/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1224 - accuracy: 0.9543\n",
            "Epoch 37: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1229 - accuracy: 0.9554 - val_loss: 0.5234 - val_accuracy: 0.8425 - lr: 3.6755e-05\n",
            "Epoch 38/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1189 - accuracy: 0.9600\n",
            "Epoch 38: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1088 - accuracy: 0.9588 - val_loss: 0.6018 - val_accuracy: 0.7877 - lr: 3.4917e-05\n",
            "Epoch 39/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1541 - accuracy: 0.9371\n",
            "Epoch 39: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1229 - accuracy: 0.9485 - val_loss: 0.6791 - val_accuracy: 0.7671 - lr: 3.4917e-05\n",
            "Epoch 40/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1187 - accuracy: 0.9571\n",
            "Epoch 40: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1022 - accuracy: 0.9674 - val_loss: 0.5713 - val_accuracy: 0.8151 - lr: 3.4917e-05\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9760\n",
            "Epoch 41: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0982 - accuracy: 0.9760 - val_loss: 0.6320 - val_accuracy: 0.8014 - lr: 3.3171e-05\n",
            "Epoch 42/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0699 - accuracy: 0.9886\n",
            "Epoch 42: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9760 - val_loss: 0.5200 - val_accuracy: 0.8425 - lr: 3.3171e-05\n",
            "Epoch 43/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0929 - accuracy: 0.9657\n",
            "Epoch 43: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0970 - accuracy: 0.9657 - val_loss: 0.6103 - val_accuracy: 0.7945 - lr: 3.3171e-05\n",
            "Epoch 44/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1270 - accuracy: 0.9457\n",
            "Epoch 44: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1091 - accuracy: 0.9571 - val_loss: 0.5967 - val_accuracy: 0.8014 - lr: 3.1512e-05\n",
            "Epoch 45/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1269 - accuracy: 0.9486\n",
            "Epoch 45: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1031 - accuracy: 0.9605 - val_loss: 0.5284 - val_accuracy: 0.8219 - lr: 3.1512e-05\n",
            "Epoch 46/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1023 - accuracy: 0.9743\n",
            "Epoch 46: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0975 - accuracy: 0.9691 - val_loss: 0.5203 - val_accuracy: 0.8288 - lr: 3.1512e-05\n",
            "Epoch 47/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0931 - accuracy: 0.9657\n",
            "Epoch 47: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 0.9743 - val_loss: 0.4656 - val_accuracy: 0.8356 - lr: 2.9937e-05\n",
            "Epoch 48/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1135 - accuracy: 0.9543\n",
            "Epoch 48: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0893 - accuracy: 0.9708 - val_loss: 0.5408 - val_accuracy: 0.8493 - lr: 2.9937e-05\n",
            "Epoch 49/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.1028 - accuracy: 0.9714\n",
            "Epoch 49: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 0.6632 - val_accuracy: 0.7945 - lr: 2.9937e-05\n",
            "Epoch 50/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0936 - accuracy: 0.9600\n",
            "Epoch 50: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0837 - accuracy: 0.9674 - val_loss: 0.6121 - val_accuracy: 0.8151 - lr: 2.8440e-05\n",
            "Epoch 51/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0788 - accuracy: 0.9714\n",
            "Epoch 51: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0793 - accuracy: 0.9691 - val_loss: 0.5854 - val_accuracy: 0.8219 - lr: 2.8440e-05\n",
            "Epoch 52/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0896 - accuracy: 0.9714\n",
            "Epoch 52: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0841 - accuracy: 0.9691 - val_loss: 0.5917 - val_accuracy: 0.8014 - lr: 2.8440e-05\n",
            "Epoch 53/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0835 - accuracy: 0.9743\n",
            "Epoch 53: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.6525 - val_accuracy: 0.8151 - lr: 2.7018e-05\n",
            "Epoch 54/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0890 - accuracy: 0.9686\n",
            "Epoch 54: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0741 - accuracy: 0.9777 - val_loss: 0.5937 - val_accuracy: 0.8219 - lr: 2.7018e-05\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9726\n",
            "Epoch 55: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0787 - accuracy: 0.9726 - val_loss: 0.6095 - val_accuracy: 0.8288 - lr: 2.7018e-05\n",
            "Epoch 56/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0947 - accuracy: 0.9629\n",
            "Epoch 56: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0756 - accuracy: 0.9743 - val_loss: 0.5349 - val_accuracy: 0.8767 - lr: 2.5667e-05\n",
            "Epoch 57/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9600\n",
            "Epoch 57: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0750 - accuracy: 0.9674 - val_loss: 0.6195 - val_accuracy: 0.8219 - lr: 2.5667e-05\n",
            "Epoch 58/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0756 - accuracy: 0.9800\n",
            "Epoch 58: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0597 - accuracy: 0.9880 - val_loss: 0.6928 - val_accuracy: 0.8219 - lr: 2.5667e-05\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9846\n",
            "Epoch 59: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0670 - accuracy: 0.9846 - val_loss: 0.7200 - val_accuracy: 0.8082 - lr: 2.4384e-05\n",
            "Epoch 60/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0788 - accuracy: 0.9743\n",
            "Epoch 60: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0740 - accuracy: 0.9777 - val_loss: 0.6773 - val_accuracy: 0.8014 - lr: 2.4384e-05\n",
            "Epoch 61/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0833 - accuracy: 0.9686\n",
            "Epoch 61: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0676 - accuracy: 0.9794 - val_loss: 0.7436 - val_accuracy: 0.8219 - lr: 2.4384e-05\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9777\n",
            "Epoch 62: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0714 - accuracy: 0.9777 - val_loss: 0.6032 - val_accuracy: 0.8425 - lr: 2.3165e-05\n",
            "Epoch 63/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0723 - accuracy: 0.9743\n",
            "Epoch 63: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 0.6608 - val_accuracy: 0.8219 - lr: 2.3165e-05\n",
            "Epoch 64/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0640 - accuracy: 0.9771\n",
            "Epoch 64: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0525 - accuracy: 0.9846 - val_loss: 0.5879 - val_accuracy: 0.8425 - lr: 2.3165e-05\n",
            "Epoch 65/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0632 - accuracy: 0.9771\n",
            "Epoch 65: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0675 - accuracy: 0.9743 - val_loss: 0.7377 - val_accuracy: 0.8219 - lr: 2.2006e-05\n",
            "Epoch 66/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0675 - accuracy: 0.9743\n",
            "Epoch 66: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0575 - accuracy: 0.9811 - val_loss: 0.5405 - val_accuracy: 0.8630 - lr: 2.2006e-05\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9880\n",
            "Epoch 67: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.5440 - val_accuracy: 0.8767 - lr: 2.2006e-05\n",
            "Epoch 68/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0591 - accuracy: 0.9714\n",
            "Epoch 68: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0567 - accuracy: 0.9794 - val_loss: 0.6881 - val_accuracy: 0.8288 - lr: 2.0906e-05\n",
            "Epoch 69/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0842 - accuracy: 0.9657\n",
            "Epoch 69: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0708 - accuracy: 0.9708 - val_loss: 0.5191 - val_accuracy: 0.8425 - lr: 2.0906e-05\n",
            "Epoch 70/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0521 - accuracy: 0.9829\n",
            "Epoch 70: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0492 - accuracy: 0.9846 - val_loss: 0.7472 - val_accuracy: 0.8151 - lr: 2.0906e-05\n",
            "Epoch 71/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0551 - accuracy: 0.9857\n",
            "Epoch 71: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0574 - accuracy: 0.9828 - val_loss: 0.6520 - val_accuracy: 0.8288 - lr: 1.9861e-05\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9914\n",
            "Epoch 72: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0464 - accuracy: 0.9914 - val_loss: 0.6341 - val_accuracy: 0.8219 - lr: 1.9861e-05\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9794\n",
            "Epoch 73: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0515 - accuracy: 0.9794 - val_loss: 0.7345 - val_accuracy: 0.8288 - lr: 1.9861e-05\n",
            "Epoch 74/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0695 - accuracy: 0.9771\n",
            "Epoch 74: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0636 - accuracy: 0.9794 - val_loss: 0.8066 - val_accuracy: 0.8151 - lr: 1.8868e-05\n",
            "Epoch 75/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0532 - accuracy: 0.9943\n",
            "Epoch 75: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0503 - accuracy: 0.9914 - val_loss: 0.7045 - val_accuracy: 0.8151 - lr: 1.8868e-05\n",
            "Epoch 76/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9771\n",
            "Epoch 76: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0576 - accuracy: 0.9743 - val_loss: 0.7417 - val_accuracy: 0.7945 - lr: 1.8868e-05\n",
            "Epoch 77/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0506 - accuracy: 0.9829\n",
            "Epoch 77: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0485 - accuracy: 0.9811 - val_loss: 0.6656 - val_accuracy: 0.8082 - lr: 1.7924e-05\n",
            "Epoch 78/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0551 - accuracy: 0.9886\n",
            "Epoch 78: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0478 - accuracy: 0.9880 - val_loss: 0.7897 - val_accuracy: 0.7877 - lr: 1.7924e-05\n",
            "Epoch 79/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0469 - accuracy: 0.9829\n",
            "Epoch 79: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0416 - accuracy: 0.9880 - val_loss: 0.7907 - val_accuracy: 0.8151 - lr: 1.7924e-05\n",
            "Epoch 80/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0756 - accuracy: 0.9657\n",
            "Epoch 80: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0629 - accuracy: 0.9760 - val_loss: 0.7098 - val_accuracy: 0.8288 - lr: 1.7028e-05\n",
            "Epoch 81/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0473 - accuracy: 0.9914\n",
            "Epoch 81: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0441 - accuracy: 0.9949 - val_loss: 0.8611 - val_accuracy: 0.8151 - lr: 1.7028e-05\n",
            "Epoch 82/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9857\n",
            "Epoch 82: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 0.5834 - val_accuracy: 0.7945 - lr: 1.7028e-05\n",
            "Epoch 83/100\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0493 - accuracy: 0.9836\n",
            "Epoch 83: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.6881 - val_accuracy: 0.8356 - lr: 1.6177e-05\n",
            "Epoch 84/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0568 - accuracy: 0.9857\n",
            "Epoch 84: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0441 - accuracy: 0.9914 - val_loss: 0.6298 - val_accuracy: 0.8493 - lr: 1.6177e-05\n",
            "Epoch 85/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0498 - accuracy: 0.9857\n",
            "Epoch 85: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0497 - accuracy: 0.9880 - val_loss: 0.6366 - val_accuracy: 0.8356 - lr: 1.6177e-05\n",
            "Epoch 86/100\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0396 - accuracy: 0.9873\n",
            "Epoch 86: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.7132 - val_accuracy: 0.7808 - lr: 1.5368e-05\n",
            "Epoch 87/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0483 - accuracy: 0.9829\n",
            "Epoch 87: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.6412 - val_accuracy: 0.8219 - lr: 1.5368e-05\n",
            "Epoch 88/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0614 - accuracy: 0.9771\n",
            "Epoch 88: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9828 - val_loss: 0.6468 - val_accuracy: 0.8151 - lr: 1.5368e-05\n",
            "Epoch 89/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0392 - accuracy: 0.9886\n",
            "Epoch 89: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.7090 - val_accuracy: 0.8219 - lr: 1.4599e-05\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9828\n",
            "Epoch 90: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 0.9828 - val_loss: 0.6893 - val_accuracy: 0.8288 - lr: 1.4599e-05\n",
            "Epoch 91/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0431 - accuracy: 0.9829\n",
            "Epoch 91: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0424 - accuracy: 0.9846 - val_loss: 0.8257 - val_accuracy: 0.8493 - lr: 1.4599e-05\n",
            "Epoch 92/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0568 - accuracy: 0.9714\n",
            "Epoch 92: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0511 - accuracy: 0.9760 - val_loss: 0.6330 - val_accuracy: 0.8562 - lr: 1.3869e-05\n",
            "Epoch 93/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0325 - accuracy: 0.9971\n",
            "Epoch 93: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0297 - accuracy: 0.9966 - val_loss: 0.6458 - val_accuracy: 0.8630 - lr: 1.3869e-05\n",
            "Epoch 94/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0425 - accuracy: 0.9800\n",
            "Epoch 94: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0411 - accuracy: 0.9828 - val_loss: 0.7309 - val_accuracy: 0.8493 - lr: 1.3869e-05\n",
            "Epoch 95/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0411 - accuracy: 0.9886\n",
            "Epoch 95: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0398 - accuracy: 0.9897 - val_loss: 0.6425 - val_accuracy: 0.8493 - lr: 1.3176e-05\n",
            "Epoch 96/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0372 - accuracy: 0.9914\n",
            "Epoch 96: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0383 - accuracy: 0.9897 - val_loss: 0.7250 - val_accuracy: 0.8630 - lr: 1.3176e-05\n",
            "Epoch 97/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9857\n",
            "Epoch 97: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.7177 - val_accuracy: 0.8356 - lr: 1.3176e-05\n",
            "Epoch 98/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0301 - accuracy: 0.9914\n",
            "Epoch 98: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0401 - accuracy: 0.9914 - val_loss: 0.6800 - val_accuracy: 0.8562 - lr: 1.2517e-05\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9880\n",
            "Epoch 99: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.7286 - val_accuracy: 0.8356 - lr: 1.2517e-05\n",
            "Epoch 100/100\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0579 - accuracy: 0.9800\n",
            "Epoch 100: val_loss did not improve from 0.46519\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 0.9846 - val_loss: 0.6825 - val_accuracy: 0.8425 - lr: 1.2517e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe3103a7ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(dataset_train, epochs=100, callbacks=[reduce_lr, cp_callback], validation_data=dataset_valid)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tOeSoxd0Dc3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e20a9d5-58d4-44d8-8163-32899985e15c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test model"
      ],
      "metadata": {
        "id": "JnC3v4hG4iEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('mirabest/cp.ckpt')"
      ],
      "metadata": {
        "id": "IxWv_8E_4hq2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = []\n",
        "accuracies = []\n",
        "for _ in range(samples_iter):\n",
        "  correct, n = 0, 0\n",
        "  s = []\n",
        "  for (x, y) in dataset_test:\n",
        "    yhat = new_model.predict(x)\n",
        "    correct += np.sum(np.argmax(yhat, axis=-1) == y)\n",
        "    n += len(y)\n",
        "    s.append(yhat)\n",
        "  s = np.concatenate(s)\n",
        "  softmax.append(s)\n",
        "  accuracies.append(correct / n)\n",
        "  print('Accuracy:',correct / n)\n",
        "softmax = np.array(softmax)"
      ],
      "metadata": {
        "id": "4z8JNVya_IzG",
        "outputId": "7aa03241-218d-4d39-82ab-6bcc3624e228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8846153846153846\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8557692307692307\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8557692307692307\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.7596153846153846\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8365384615384616\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7596153846153846\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.75\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7596153846153846\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.7403846153846154\n",
            "Accuracy: 0.7596153846153846\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7692307692307693\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8557692307692307\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.7788461538461539\n",
            "Accuracy: 0.8076923076923077\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.7596153846153846\n",
            "Accuracy: 0.7884615384615384\n",
            "Accuracy: 0.8269230769230769\n",
            "Accuracy: 0.8557692307692307\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.7980769230769231\n",
            "Accuracy: 0.8173076923076923\n",
            "Accuracy: 0.8461538461538461\n",
            "Accuracy: 0.7884615384615384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy', np.mean(accuracies), np.std(accuracies))"
      ],
      "metadata": {
        "id": "02AZa6Np_6MX",
        "outputId": "9c21014f-5f5b-4650-b1a3-f38d0515646f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8057211538461538 0.023102900042735217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def uncertainty(softmax):\n",
        "  # Per example softmax with shape(num_examples, num_classes)\n",
        "  predictive_entropy = 0\n",
        "  single_pass_entropy = 0\n",
        "  for i in range(softmax.shape[1]):\n",
        "    # Sum over classes\n",
        "    predictive_entropy += -np.mean(softmax[:,i])*np.log(np.mean(softmax[:,i]))\n",
        "    single_pass_entropy += -softmax[:,i]*np.log(softmax[:,i])\n",
        "  single_pass_entropy = np.mean(single_pass_entropy)\n",
        "  mutual_info = predictive_entropy - single_pass_entropy\n",
        "  return predictive_entropy, single_pass_entropy, mutual_info"
      ],
      "metadata": {
        "id": "AFxGXi4JDnS3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictive_entropies = [] \n",
        "single_pass_entropies = []\n",
        "mutual_infos = []\n",
        "for i in range(softmax.shape[1]):\n",
        "  predictive_entropy, single_pass_entropy, mutual_info = uncertainty(softmax[:,i,:])\n",
        "  predictive_entropies.append(predictive_entropy)\n",
        "  single_pass_entropies.append(single_pass_entropy)\n",
        "  mutual_infos.append(mutual_info)\n",
        "print('Predictive entropy:', np.mean(predictive_entropies), np.std(predictive_entropies))\n",
        "print('Single pass entropy:', np.mean(single_pass_entropies), np.std(single_pass_entropies))\n",
        "print('Mutual info:', np.mean(mutual_infos), np.std(mutual_infos))"
      ],
      "metadata": {
        "id": "xGzYD6acDnVi",
        "outputId": "e1f85594-7fc6-4ca8-8974-580eb7915ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictive entropy: 0.30058785614498074 0.22516945937230232\n",
            "Single pass entropy: 0.22893868 0.17530042\n",
            "Mutual info: 0.07164919167428689 0.06090488705126512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(predictive_entropies)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SBnp5eiNDnYR",
        "outputId": "56863414-54e8-4f33-838a-7ed8493d4d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(single_pass_entropies)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8bPVRpEyDnan",
        "outputId": "6ed54c89-bb3a-4d94-ab08-7f60a14ff968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(mutual_infos)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4IYJt9ocDndX",
        "outputId": "6fcaba5f-866a-4355-fd76-b6484878eae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Mirabest_MCD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}